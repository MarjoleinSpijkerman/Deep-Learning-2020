{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKV2SqVUGzRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMbQAL4OkCZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    #network that makes 3 * 256 * 256 images from images of the same size\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(6, 30, 3)\n",
        "        self.conv2 = nn.Conv2d(30, 30, 4)\n",
        "        \n",
        "        self.fc1 = nn.Linear(30 * 14 * 14, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 120)\n",
        "        self.fc4 = nn.Linear(120, 30 * 14 * 14)\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose2d(60, 30, 4)\n",
        "        self.deconv2 = nn.ConvTranspose2d(60, 3, 3)\n",
        "\n",
        "        self.do = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, masked_imgs, masks):\n",
        "        avg_masks = F.avg_pool2d(masks, 3, 1, 1)\n",
        "        x = torch.cat([masked_imgs, avg_masks], dim=1)\n",
        "\n",
        "        conv_img_1 = F.relu(self.conv1(x))\n",
        "        x, max_pool_1_idx = F.max_pool2d(conv_img_1, 2, return_indices=True)\n",
        "        conv_img_2 = F.relu(self.conv2(x))\n",
        "        x, max_pool_2_idx = F.max_pool2d(conv_img_2, 2, return_indices=True)\n",
        "        \n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.do(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "\n",
        "        x = self.do(x)\n",
        "\n",
        "        x = x.view(-1, 30, 14, 14)\n",
        "\n",
        "        x = F.max_unpool2d(x, max_pool_2_idx, 2)\n",
        "        x = torch.cat([x, conv_img_2], dim=1)\n",
        "        x = F.relu(self.deconv1(x))\n",
        "\n",
        "        x = self.do(x)\n",
        "\n",
        "        x = F.max_unpool2d(x, max_pool_1_idx, 2)\n",
        "        x = torch.cat([x, conv_img_1], dim=1)\n",
        "        x = torch.sigmoid(self.deconv2(x))\n",
        "\n",
        "        x = masks * masked_imgs + (1 - masks) * x\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6UYfNKfg7c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    #network that takes 3 * 256 * 256 images and gives a value between 0 and 1\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 20, 3)\n",
        "        self.conv2 = nn.Conv2d(20, 20, 3)\n",
        "        self.conv3 = nn.Conv2d(20, 20, 3)\n",
        "        self.conv4 = nn.Conv2d(20, 20, 3)\n",
        "\n",
        "        self.fc1 = nn.Linear(20 * 13 * 13, 200)\n",
        "        self.fc2 = nn.Linear(200, 80)\n",
        "        self.fc3 = nn.Linear(80, 1)\n",
        "\n",
        "        self.do1 = nn.Dropout(0.5)\n",
        "        self.do2 = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        \n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.do1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.do2(x)\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMBnBcEI-fG7",
        "colab_type": "code",
        "outputId": "109aab8c-b568-47d8-86a4-9b00cf3f1169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# connect to google drive\n",
        "offline_use = False\n",
        "\n",
        "if offline_use:\n",
        "  directory = os.path.dirname(os.path.abspath(__file__))\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  directory = '/content/drive/My Drive/'\n",
        "\n",
        "directory = os.path.join(directory, 'gan_data')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS4OvOWTDd68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_img_directory = os.path.join(directory, 'real_img')\n",
        "fake_img_directory = os.path.join(directory, 'fake_img')\n",
        "os.makedirs(real_img_directory, exist_ok=True)\n",
        "os.makedirs(fake_img_directory, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S22bTZ6Tp83W",
        "colab_type": "code",
        "outputId": "fbee0c75-fd9f-48c8-a3bd-af25d782697f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def read_img_file_names():\n",
        "  if os.path.isdir(real_img_directory):\n",
        "    real_photo_paths = [os.path.join(path, name) for path, subdirs, files in os.walk(real_img_directory) for name in files]\n",
        "    if real_photo_paths == []:\n",
        "      print('No real photos found.')\n",
        "  else:\n",
        "    print('No real photos directory found.')\n",
        "    real_photo_paths = []\n",
        "\n",
        "  if os.path.isdir(fake_img_directory):\n",
        "    fake_photo_paths = [os.path.join(path, name) for path, subdirs, files in os.walk(fake_img_directory) for name in files]\n",
        "    if fake_photo_paths == []:\n",
        "      print('No fake photos found.')\n",
        "  else:\n",
        "    print('No fake photos directory found.')\n",
        "    fake_photo_paths = []\n",
        "\n",
        "  return real_photo_paths, fake_photo_paths\n",
        "\n",
        "real_img_list, fake_img_list = read_img_file_names()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No fake photos found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7YJGy39hEes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(training_photos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfpCj_KffX50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_directory = os.path.join(directory, 'mask')\n",
        "\n",
        "mask_paths = []\n",
        "filtered_paths = []\n",
        "\n",
        "n_subfolders = 1\n",
        "\n",
        "if os.path.isdir(mask_directory):\n",
        "  for i in range(n_subfolders):\n",
        "    folder_path_2 = os.path.join(mask_directory, str(i))\n",
        "    if not os.path.isdir(folder_path_2):\n",
        "      continue\n",
        "    for folder in os.listdir(folder_path_2):\n",
        "      folder_path = os.path.join(folder_path_2, folder)\n",
        "\n",
        "      if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "      mask_path = \"\"\n",
        "      filtered_path = \"\"\n",
        "\n",
        "      for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        if not os.path.isfile(file_path):\n",
        "          continue\n",
        "\n",
        "        if \"mask\" in file_name:\n",
        "          mask_path = file_path\n",
        "        elif \"combined\" in file_name:\n",
        "          filtered_path = file_path\n",
        "\n",
        "      # if mask_path == \"\":\n",
        "      #   print(\"No mask found in folder: {}\".format(folder_path))\n",
        "      # if filtered_path == \"\":\n",
        "      #   print(\"No filtered image found in folder: {}\".format(folder_path))\n",
        "\n",
        "      if mask_path != \"\" and filtered_path != \"\":\n",
        "        mask_paths.append(mask_path)\n",
        "        filtered_paths.append(filtered_path)\n",
        "\n",
        "  if mask_paths == []:\n",
        "    print('No masks found.')\n",
        "else:\n",
        "  print('No mask directory found.')\n",
        "\n",
        "masks_df = pd.DataFrame({'mask_path': mask_paths, 'filtered_path': filtered_paths})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IipbCZv9tmRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "import cv2\n",
        "import pickle\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def load_img(file_path):\n",
        "  extension = ''.join(pathlib.Path(file_path).suffixes)\n",
        "\n",
        "  if extension == '.pickle':\n",
        "    # load pickle\n",
        "    with open(file_path, 'rb') as pickle_file:\n",
        "      img = np.array(pickle.load(pickle_file))\n",
        "  elif extension == '.npy':\n",
        "    # load npy\n",
        "    img = np.load(file_path)\n",
        "  elif extension in ['.jpg', '.png', '.bmp']:\n",
        "    # load img\n",
        "    img = cv2.imread(file_path)\n",
        "    img.resize(64, 64, 3)\n",
        "    img = np.array(img)\n",
        "  else:\n",
        "    # unknown extension\n",
        "    print('Image file has an unknown extension: {}'.format(file_path))\n",
        "\n",
        "  # cv2_imshow(img)\n",
        "\n",
        "  transposed_img = torchvision.transforms.ToTensor()(img).numpy()\n",
        "\n",
        "  return transposed_img\n",
        "\n",
        "def load_imgs(file_paths):\n",
        "  x = [load_img(file_path) for file_path in file_paths]\n",
        "  # torchvision.utils.make_grid(torch.Tensor(x))\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgCp6L0i3Lee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "idx_img = 0\n",
        "def save_img(directory, img):\n",
        "  global idx_img\n",
        "  file_path = os.path.join(directory, 'z{}.png'.format(idx_img))\n",
        "  save_image(img, file_path)\n",
        "  idx_img += 1\n",
        "  return file_path\n",
        "\n",
        "def save_imgs(directory, imgs_tensor):\n",
        "  file_paths = []\n",
        "  # torchvision.utils.make_grid(imgs_tensor)\n",
        "  for img_tensor in imgs_tensor:\n",
        "    img_tensor = img_tensor.detach()\n",
        "    file_path = save_img(directory, img_tensor)\n",
        "    file_paths.append(file_path)\n",
        "  return file_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "415hXgs65172",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classifier(classifier_network, training_imgs, targets, loss_function, classifier_optimizer):\n",
        "  training_imgs = torch.tensor(training_imgs).float().cuda()\n",
        "  targets = torch.tensor(targets).float().cuda()\n",
        "\n",
        "  # print('training')\n",
        "  # torchvision.utils.make_grid(training_imgs)\n",
        "\n",
        "  out = cla.forward(training_imgs)\n",
        "  loss = loss_function(out, targets)\n",
        "  loss.backward()\n",
        "  classifier_optimizer.step()\n",
        "\n",
        "  print('Classifier loss: {}'.format(loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO9PKVTT62tK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_generator(generator_network, classifier_network, masks, masked_imgs, loss_function, generator_optimizer):\n",
        "  # print('masked')\n",
        "  # torchvision.utils.make_grid(torch.Tensor(masked_imgs))\n",
        "\n",
        "  masks = torch.tensor(masks).float().cuda()\n",
        "  masked_imgs = torch.tensor(masked_imgs).float().cuda()\n",
        "  targets = torch.ones([len(masks), 1]).float().cuda()\n",
        "\n",
        "  generated_imgs = generator_network.forward(masked_imgs, masks)\n",
        "  classifications = classifier_network.forward(generated_imgs)\n",
        "\n",
        "  # print('generated imgs')\n",
        "  # torchvision.utils.make_grid(torch.Tensor(generated_imgs.cpu()))\n",
        "\n",
        "  loss = loss_function(classifications, targets)\n",
        "  loss.backward()\n",
        "  generator_optimizer.step()\n",
        "\n",
        "  print('Generator loss: {}'.format(loss))\n",
        "\n",
        "  return generated_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJxsR3YH3NZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 1900\n",
        "n_repetitions = 10\n",
        "n_img_sample = 50\n",
        "n_mask_sample = 50\n",
        "\n",
        "lr = 0.001\n",
        "beta1 = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjWogjgKEABr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(fake_img_list)\n",
        "fake_img_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9juqzgohLUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv2d') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('ConvTranspose') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.001)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
        "    # elif classname.find('BatchNorm') != -1:\n",
        "    #     nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "    #     nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrdp_VJNVU_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6aGCqf5r942",
        "colab_type": "code",
        "outputId": "655d9bd5-4993-425c-b2b3-6681dda94f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# gen = Generator().float().cuda()\n",
        "# cla = Classifier().float().cuda()\n",
        "\n",
        "# gen.apply(weights_init)\n",
        "# cla.apply(weights_init)\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "# cla_optimizer = torch.optim.SGD(cla.parameters(), lr=0.002)\n",
        "# gen_optimizer = torch.optim.SGD(gen.parameters(), lr=0.002)\n",
        "\n",
        "cla_optimizer = torch.optim.Adam(cla.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=0.98)\n",
        "gen_optimizer = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=0.98)\n",
        "\n",
        "for i_epoch in range(n_epochs):\n",
        "  print('Running epoch {} out of {}'.format(i_epoch + 1, n_epochs))\n",
        "  \n",
        "  sample_real_imgs_fn = random.sample(real_img_list, min(len(real_img_list), n_img_sample))\n",
        "  sample_fake_imgs_fn = random.sample(fake_img_list, min(len(fake_img_list), n_img_sample))\n",
        "  sample_masks_fn_df = masks_df.sample(n = n_mask_sample, replace=True)\n",
        "\n",
        "  real_imgs = load_imgs(sample_real_imgs_fn)\n",
        "  fake_imgs = load_imgs(sample_fake_imgs_fn)\n",
        "  masks = load_imgs(sample_masks_fn_df['mask_path'])\n",
        "  masked_imgs = load_imgs(sample_masks_fn_df['filtered_path'])\n",
        "\n",
        "  for i_repetition in range(n_repetitions):\n",
        "    if len(real_imgs) > 0:\n",
        "      shuffle(real_imgs)\n",
        "      train_classifier(cla, real_imgs, [[1] for i in range(len(real_imgs))], loss_function, cla_optimizer)\n",
        "    if len(fake_imgs) > 0:\n",
        "      shuffle(fake_imgs)\n",
        "      train_classifier(cla, fake_imgs, [[0] for i in range(len(fake_imgs))], loss_function, cla_optimizer)\n",
        "    generated_imgs = train_generator(gen, cla, masks, masked_imgs, loss_function, gen_optimizer)\n",
        "    fake_img_list += save_imgs(fake_img_directory, generated_imgs)\n",
        "\n",
        "  n_img_sample = 200"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Classifier loss: 0.025787517428398132\n",
            "Generator loss: 4.30033969678334e-06\n",
            "Classifier loss: 0.10351395606994629\n",
            "Classifier loss: 0.05170556902885437\n",
            "Generator loss: 0.04000495374202728\n",
            "Classifier loss: 0.05208441615104675\n",
            "Classifier loss: 0.049865782260894775\n",
            "Generator loss: 0.010923806577920914\n",
            "Classifier loss: 0.06948782503604889\n",
            "Classifier loss: 0.027047041803598404\n",
            "Generator loss: 3.00409652709277e-07\n",
            "Classifier loss: 0.06400252133607864\n",
            "Classifier loss: 0.027450930327177048\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.03434578329324722\n",
            "Classifier loss: 0.02774358168244362\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07278061658143997\n",
            "Classifier loss: 0.028069550171494484\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.048233989626169205\n",
            "Classifier loss: 0.025001730769872665\n",
            "Generator loss: 1.6689307713591006e-08\n",
            "Running epoch 75 out of 1900\n",
            "Classifier loss: 0.09458958357572556\n",
            "Classifier loss: 0.5375844240188599\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07625427097082138\n",
            "Classifier loss: 0.0378250926733017\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.058084886521101\n",
            "Classifier loss: 0.0557594858109951\n",
            "Generator loss: 2.050410330411978e-07\n",
            "Classifier loss: 0.08922689408063889\n",
            "Classifier loss: 0.5409764051437378\n",
            "Generator loss: 0.019295964390039444\n",
            "Classifier loss: 0.06400039792060852\n",
            "Classifier loss: 0.03484925255179405\n",
            "Generator loss: 0.058034639805555344\n",
            "Classifier loss: 0.07025033980607986\n",
            "Classifier loss: 0.5309770703315735\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07229498028755188\n",
            "Classifier loss: 0.0355025976896286\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06939303129911423\n",
            "Classifier loss: 0.031777236610651016\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05721518397331238\n",
            "Classifier loss: 0.12364263087511063\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0628056600689888\n",
            "Classifier loss: 0.05028301104903221\n",
            "Generator loss: 0.0\n",
            "Running epoch 76 out of 1900\n",
            "Classifier loss: 0.082976795732975\n",
            "Classifier loss: 0.054345469921827316\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09780843555927277\n",
            "Classifier loss: 0.058846455067396164\n",
            "Generator loss: 0.0017644512699916959\n",
            "Classifier loss: 0.06913008540868759\n",
            "Classifier loss: 0.07692524790763855\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07290129363536835\n",
            "Classifier loss: 0.05932985991239548\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08240894228219986\n",
            "Classifier loss: 0.03577553108334541\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07843632251024246\n",
            "Classifier loss: 0.035902779549360275\n",
            "Generator loss: 0.021907664835453033\n",
            "Classifier loss: 0.08421386778354645\n",
            "Classifier loss: 0.06898364424705505\n",
            "Generator loss: 2.288831382202261e-07\n",
            "Classifier loss: 0.07328416407108307\n",
            "Classifier loss: 0.03500410541892052\n",
            "Generator loss: 3.933600237360224e-05\n",
            "Classifier loss: 0.08377668261528015\n",
            "Classifier loss: 0.030407419428229332\n",
            "Generator loss: 0.003701458452269435\n",
            "Classifier loss: 0.07701054215431213\n",
            "Classifier loss: 0.5527940988540649\n",
            "Generator loss: 0.04611916467547417\n",
            "Running epoch 77 out of 1900\n",
            "Classifier loss: 0.20750224590301514\n",
            "Classifier loss: 0.02616839110851288\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.21835173666477203\n",
            "Classifier loss: 0.05045796185731888\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2535625100135803\n",
            "Classifier loss: 0.04138288274407387\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.16930443048477173\n",
            "Classifier loss: 0.03173484653234482\n",
            "Generator loss: 6.19889277686525e-08\n",
            "Classifier loss: 0.1738695502281189\n",
            "Classifier loss: 0.03287124261260033\n",
            "Generator loss: 0.04069916158914566\n",
            "Classifier loss: 0.16555924713611603\n",
            "Classifier loss: 0.043697189539670944\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1351163238286972\n",
            "Classifier loss: 0.03285877779126167\n",
            "Generator loss: 0.03438275679945946\n",
            "Classifier loss: 0.13101854920387268\n",
            "Classifier loss: 0.035081107169389725\n",
            "Generator loss: 2.458245717207319e-06\n",
            "Classifier loss: 0.115332692861557\n",
            "Classifier loss: 0.07317923754453659\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1044427677989006\n",
            "Classifier loss: 0.050841715186834335\n",
            "Generator loss: 3.3047540455299895e-06\n",
            "Running epoch 78 out of 1900\n",
            "Classifier loss: 0.10362158715724945\n",
            "Classifier loss: 0.05416342243552208\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13097093999385834\n",
            "Classifier loss: 0.039965324103832245\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1363215446472168\n",
            "Classifier loss: 0.03939199447631836\n",
            "Generator loss: 1.1920931797249068e-08\n",
            "Classifier loss: 0.11050565540790558\n",
            "Classifier loss: 0.0408698171377182\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08479925990104675\n",
            "Classifier loss: 0.5487009882926941\n",
            "Generator loss: 0.024422921240329742\n",
            "Classifier loss: 0.07683580368757248\n",
            "Classifier loss: 0.06014782190322876\n",
            "Generator loss: 0.0004423029604367912\n",
            "Classifier loss: 0.09189970046281815\n",
            "Classifier loss: 0.04664355516433716\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06007742881774902\n",
            "Classifier loss: 0.04978180676698685\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06859628856182098\n",
            "Classifier loss: 0.5701918005943298\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07345863431692123\n",
            "Classifier loss: 0.5409382581710815\n",
            "Generator loss: 0.0\n",
            "Running epoch 79 out of 1900\n",
            "Classifier loss: 0.1622040569782257\n",
            "Classifier loss: 0.04828742891550064\n",
            "Generator loss: 1.163190245279111e-05\n",
            "Classifier loss: 0.12205823510885239\n",
            "Classifier loss: 0.046570003032684326\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1595984250307083\n",
            "Classifier loss: 0.048409443348646164\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13910304009914398\n",
            "Classifier loss: 0.05404510721564293\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.132008895277977\n",
            "Classifier loss: 0.050364769995212555\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.12813526391983032\n",
            "Classifier loss: 0.04660969600081444\n",
            "Generator loss: 0.027896711602807045\n",
            "Classifier loss: 0.131283238530159\n",
            "Classifier loss: 0.06539338827133179\n",
            "Generator loss: 2.3841870699925494e-08\n",
            "Classifier loss: 0.09775728732347488\n",
            "Classifier loss: 0.05696813762187958\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10056421905755997\n",
            "Classifier loss: 0.08282288163900375\n",
            "Generator loss: 7.152558545442389e-09\n",
            "Classifier loss: 0.11482419818639755\n",
            "Classifier loss: 0.0647469088435173\n",
            "Generator loss: 0.0\n",
            "Running epoch 80 out of 1900\n",
            "Classifier loss: 0.274531751871109\n",
            "Classifier loss: 0.09679771214723587\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2727208137512207\n",
            "Classifier loss: 0.0849517434835434\n",
            "Generator loss: 6.651988542216714e-07\n",
            "Classifier loss: 0.27097615599632263\n",
            "Classifier loss: 0.5682674050331116\n",
            "Generator loss: 7.152558545442389e-09\n",
            "Classifier loss: 0.15294358134269714\n",
            "Classifier loss: 0.5897338390350342\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.20950481295585632\n",
            "Classifier loss: 0.0914490669965744\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14063045382499695\n",
            "Classifier loss: 1.057275414466858\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.14758777618408203\n",
            "Classifier loss: 1.0745456218719482\n",
            "Generator loss: 0.0037982873618602753\n",
            "Classifier loss: 0.1673572063446045\n",
            "Classifier loss: 0.5551235675811768\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1392282396554947\n",
            "Classifier loss: 0.5552335977554321\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11805888265371323\n",
            "Classifier loss: 1.0600892305374146\n",
            "Generator loss: 0.0002989726490341127\n",
            "Running epoch 81 out of 1900\n",
            "Classifier loss: 0.0827033594250679\n",
            "Classifier loss: 0.0984303280711174\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.055117033421993256\n",
            "Classifier loss: 0.637310266494751\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07737140357494354\n",
            "Classifier loss: 0.06519600749015808\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.04076121374964714\n",
            "Classifier loss: 0.07275442779064178\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0652662143111229\n",
            "Classifier loss: 0.0589173398911953\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0903463363647461\n",
            "Classifier loss: 0.07164555788040161\n",
            "Generator loss: 0.02033805288374424\n",
            "Classifier loss: 0.05549445375800133\n",
            "Classifier loss: 0.12000487744808197\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.061617638915777206\n",
            "Classifier loss: 0.06015021353960037\n",
            "Generator loss: 1.2058078027621377e-05\n",
            "Classifier loss: 0.0666094571352005\n",
            "Classifier loss: 0.5543784499168396\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07864584028720856\n",
            "Classifier loss: 0.55633145570755\n",
            "Generator loss: 0.0\n",
            "Running epoch 82 out of 1900\n",
            "Classifier loss: 0.09549807012081146\n",
            "Classifier loss: 0.5492646098136902\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14389504492282867\n",
            "Classifier loss: 0.5755929946899414\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.17509791254997253\n",
            "Classifier loss: 0.12285067141056061\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09019654989242554\n",
            "Classifier loss: 0.05889318510890007\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08649591356515884\n",
            "Classifier loss: 0.06590761244297028\n",
            "Generator loss: 2.758258233370725e-05\n",
            "Classifier loss: 0.11454802006483078\n",
            "Classifier loss: 0.08743852376937866\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09391923993825912\n",
            "Classifier loss: 0.05158683657646179\n",
            "Generator loss: 0.0017647019121795893\n",
            "Classifier loss: 0.11550254374742508\n",
            "Classifier loss: 0.04464631900191307\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10273271054029465\n",
            "Classifier loss: 0.04671404883265495\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10487660020589828\n",
            "Classifier loss: 0.5385035276412964\n",
            "Generator loss: 8.122583676595241e-05\n",
            "Running epoch 83 out of 1900\n",
            "Classifier loss: 0.11591283231973648\n",
            "Classifier loss: 0.04581417143344879\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11690651625394821\n",
            "Classifier loss: 0.04441101476550102\n",
            "Generator loss: 0.011461497284471989\n",
            "Classifier loss: 0.09100905805826187\n",
            "Classifier loss: 0.0395083911716938\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.0888374000787735\n",
            "Classifier loss: 0.037566278129816055\n",
            "Generator loss: 0.0003584959777072072\n",
            "Classifier loss: 0.062027476727962494\n",
            "Classifier loss: 0.055362213402986526\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07916955649852753\n",
            "Classifier loss: 0.03666388615965843\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10334953665733337\n",
            "Classifier loss: 0.03711503744125366\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05940580368041992\n",
            "Classifier loss: 0.03495948761701584\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06306862831115723\n",
            "Classifier loss: 0.03411439061164856\n",
            "Generator loss: 0.03554987534880638\n",
            "Classifier loss: 0.07444063574075699\n",
            "Classifier loss: 0.0327899232506752\n",
            "Generator loss: 0.0\n",
            "Running epoch 84 out of 1900\n",
            "Classifier loss: 0.1265527755022049\n",
            "Classifier loss: 0.03391565382480621\n",
            "Generator loss: 0.016252823173999786\n",
            "Classifier loss: 0.09618683904409409\n",
            "Classifier loss: 0.028675014153122902\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11439831554889679\n",
            "Classifier loss: 0.028647178784012794\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1399136632680893\n",
            "Classifier loss: 0.037429530173540115\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09722843021154404\n",
            "Classifier loss: 0.10944508016109467\n",
            "Generator loss: 2.646619805091177e-06\n",
            "Classifier loss: 0.07922755181789398\n",
            "Classifier loss: 0.04218384250998497\n",
            "Generator loss: 0.033503398299217224\n",
            "Classifier loss: 0.07015886902809143\n",
            "Classifier loss: 0.06096743047237396\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07262397557497025\n",
            "Classifier loss: 0.02628912404179573\n",
            "Generator loss: 0.0030804211273789406\n",
            "Classifier loss: 0.0738806501030922\n",
            "Classifier loss: 0.02159317396581173\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07115308195352554\n",
            "Classifier loss: 0.026034075766801834\n",
            "Generator loss: 0.0\n",
            "Running epoch 85 out of 1900\n",
            "Classifier loss: 0.16573470830917358\n",
            "Classifier loss: 0.5553823113441467\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11792196333408356\n",
            "Classifier loss: 0.04477626830339432\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14288343489170074\n",
            "Classifier loss: 0.5241604447364807\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13973121345043182\n",
            "Classifier loss: 0.09694687277078629\n",
            "Generator loss: 0.025768671184778214\n",
            "Classifier loss: 0.132257878780365\n",
            "Classifier loss: 0.03235474228858948\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1456121951341629\n",
            "Classifier loss: 0.04523896053433418\n",
            "Generator loss: 0.05199218541383743\n",
            "Classifier loss: 0.12184514105319977\n",
            "Classifier loss: 0.023097118362784386\n",
            "Generator loss: 0.009749957360327244\n",
            "Classifier loss: 0.11837417632341385\n",
            "Classifier loss: 0.03086954727768898\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1254512071609497\n",
            "Classifier loss: 0.01841912791132927\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11856988817453384\n",
            "Classifier loss: 0.02481120079755783\n",
            "Generator loss: 3.8147007330735505e-08\n",
            "Running epoch 86 out of 1900\n",
            "Classifier loss: 0.16503246128559113\n",
            "Classifier loss: 0.1393747329711914\n",
            "Generator loss: 0.00010301250586053357\n",
            "Classifier loss: 0.11538993567228317\n",
            "Classifier loss: 0.02194240503013134\n",
            "Generator loss: 8.18538865132723e-06\n",
            "Classifier loss: 0.11219130456447601\n",
            "Classifier loss: 0.6181291341781616\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.1495397686958313\n",
            "Classifier loss: 0.02665809728205204\n",
            "Generator loss: 1.6689307713591006e-08\n",
            "Classifier loss: 0.13189895451068878\n",
            "Classifier loss: 0.028237275779247284\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11644332855939865\n",
            "Classifier loss: 0.029910704120993614\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1215883418917656\n",
            "Classifier loss: 0.025906113907694817\n",
            "Generator loss: 2.141113554898766e-06\n",
            "Classifier loss: 0.12431833893060684\n",
            "Classifier loss: 0.024872824549674988\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.10149934887886047\n",
            "Classifier loss: 0.02067864127457142\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08274556696414948\n",
            "Classifier loss: 0.025002984330058098\n",
            "Generator loss: 0.0\n",
            "Running epoch 87 out of 1900\n",
            "Classifier loss: 0.04556906595826149\n",
            "Classifier loss: 0.5279792547225952\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07991170138120651\n",
            "Classifier loss: 0.039399974048137665\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07766073942184448\n",
            "Classifier loss: 0.02659507468342781\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05356995388865471\n",
            "Classifier loss: 0.024707341566681862\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.01748526468873024\n",
            "Classifier loss: 0.024545015767216682\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.02541663870215416\n",
            "Classifier loss: 0.043877974152565\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.030950026586651802\n",
            "Classifier loss: 0.02883564867079258\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.04739265888929367\n",
            "Classifier loss: 0.051121849566698074\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0424983873963356\n",
            "Classifier loss: 0.07168084383010864\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.04494122415781021\n",
            "Classifier loss: 0.040822554379701614\n",
            "Generator loss: 0.0\n",
            "Running epoch 88 out of 1900\n",
            "Classifier loss: 0.09054471552371979\n",
            "Classifier loss: 0.6054214835166931\n",
            "Generator loss: 0.0006715620402246714\n",
            "Classifier loss: 0.05648237466812134\n",
            "Classifier loss: 0.030157312750816345\n",
            "Generator loss: 0.0425892136991024\n",
            "Classifier loss: 0.15544193983078003\n",
            "Classifier loss: 0.021260324865579605\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10309646278619766\n",
            "Classifier loss: 0.022133998572826385\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06495266407728195\n",
            "Classifier loss: 0.02314513549208641\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09539587050676346\n",
            "Classifier loss: 0.022850262001156807\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09319443255662918\n",
            "Classifier loss: 0.020653896033763885\n",
            "Generator loss: 0.033670175820589066\n",
            "Classifier loss: 0.06464018672704697\n",
            "Classifier loss: 0.02381744422018528\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07552223652601242\n",
            "Classifier loss: 0.04376578330993652\n",
            "Generator loss: 5.245215461968655e-08\n",
            "Classifier loss: 0.05604146048426628\n",
            "Classifier loss: 0.05350284278392792\n",
            "Generator loss: 0.0\n",
            "Running epoch 89 out of 1900\n",
            "Classifier loss: 0.21154768764972687\n",
            "Classifier loss: 0.5710617303848267\n",
            "Generator loss: 0.004283164162188768\n",
            "Classifier loss: 0.17009280622005463\n",
            "Classifier loss: 0.5293368697166443\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1668390929698944\n",
            "Classifier loss: 0.024296307936310768\n",
            "Generator loss: 2.517858774808701e-06\n",
            "Classifier loss: 0.2076248824596405\n",
            "Classifier loss: 0.021830324083566666\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1412000209093094\n",
            "Classifier loss: 0.02339480258524418\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13894754648208618\n",
            "Classifier loss: 0.5204356908798218\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.16250409185886383\n",
            "Classifier loss: 0.530506432056427\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.17099641263484955\n",
            "Classifier loss: 0.5247440338134766\n",
            "Generator loss: 4.3869496835213795e-07\n",
            "Classifier loss: 0.15423114597797394\n",
            "Classifier loss: 0.050399284809827805\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.17908252775669098\n",
            "Classifier loss: 0.09890110045671463\n",
            "Generator loss: 0.0\n",
            "Running epoch 90 out of 1900\n",
            "Classifier loss: 0.09094423055648804\n",
            "Classifier loss: 0.5346888303756714\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1325387805700302\n",
            "Classifier loss: 0.0709284320473671\n",
            "Generator loss: 4.5695938752032816e-05\n",
            "Classifier loss: 0.10289199650287628\n",
            "Classifier loss: 0.03231045976281166\n",
            "Generator loss: 2.2008602172718383e-05\n",
            "Classifier loss: 0.09826276451349258\n",
            "Classifier loss: 0.033894557505846024\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11628194898366928\n",
            "Classifier loss: 0.04390012100338936\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07710335403680801\n",
            "Classifier loss: 0.04917579144239426\n",
            "Generator loss: 3.337862608532305e-08\n",
            "Classifier loss: 0.13959768414497375\n",
            "Classifier loss: 0.0444735549390316\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11353446543216705\n",
            "Classifier loss: 0.046637166291475296\n",
            "Generator loss: 0.005783881526440382\n",
            "Classifier loss: 0.12618136405944824\n",
            "Classifier loss: 0.05666228011250496\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.12184339016675949\n",
            "Classifier loss: 0.5534051656723022\n",
            "Generator loss: 0.057111404836177826\n",
            "Running epoch 91 out of 1900\n",
            "Classifier loss: 0.0558415986597538\n",
            "Classifier loss: 0.06081466004252434\n",
            "Generator loss: 0.00037779592094011605\n",
            "Classifier loss: 0.06924185901880264\n",
            "Classifier loss: 0.05734965205192566\n",
            "Generator loss: 4.7683719195390495e-09\n",
            "Classifier loss: 0.08272294700145721\n",
            "Classifier loss: 0.04562690481543541\n",
            "Generator loss: 0.033032771199941635\n",
            "Classifier loss: 0.05667082220315933\n",
            "Classifier loss: 0.05379856377840042\n",
            "Generator loss: 0.03661096841096878\n",
            "Classifier loss: 0.057237595319747925\n",
            "Classifier loss: 0.06975583732128143\n",
            "Generator loss: 1.9073494783583556e-08\n",
            "Classifier loss: 0.06689217686653137\n",
            "Classifier loss: 0.03854203596711159\n",
            "Generator loss: 0.06144232675433159\n",
            "Classifier loss: 0.07976831495761871\n",
            "Classifier loss: 0.041674867272377014\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05533758923411369\n",
            "Classifier loss: 0.04054844379425049\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0657695010304451\n",
            "Classifier loss: 0.044540900737047195\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07203035801649094\n",
            "Classifier loss: 0.0427420511841774\n",
            "Generator loss: 0.0\n",
            "Running epoch 92 out of 1900\n",
            "Classifier loss: 0.05221875384449959\n",
            "Classifier loss: 0.04076596722006798\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07477128505706787\n",
            "Classifier loss: 0.050690364092588425\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05818873643875122\n",
            "Classifier loss: 0.059643905609846115\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.047382473945617676\n",
            "Classifier loss: 0.04451572895050049\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.055649373680353165\n",
            "Classifier loss: 0.043092336505651474\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05254637449979782\n",
            "Classifier loss: 0.11314092576503754\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05402250960469246\n",
            "Classifier loss: 0.06405365467071533\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05553385242819786\n",
            "Classifier loss: 0.04707707464694977\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06635922938585281\n",
            "Classifier loss: 0.06000575050711632\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05628545209765434\n",
            "Classifier loss: 0.04262692853808403\n",
            "Generator loss: 0.0\n",
            "Running epoch 93 out of 1900\n",
            "Classifier loss: 0.08941096067428589\n",
            "Classifier loss: 0.538130521774292\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08458338677883148\n",
            "Classifier loss: 0.5336766839027405\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09163810312747955\n",
            "Classifier loss: 0.5340421795845032\n",
            "Generator loss: 0.0019413663540035486\n",
            "Classifier loss: 0.07819851487874985\n",
            "Classifier loss: 0.5292186141014099\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08497930318117142\n",
            "Classifier loss: 0.5400586128234863\n",
            "Generator loss: 0.0032393576111644506\n",
            "Classifier loss: 0.1003689169883728\n",
            "Classifier loss: 0.5398263335227966\n",
            "Generator loss: 0.02065156027674675\n",
            "Classifier loss: 0.08689334988594055\n",
            "Classifier loss: 0.5361009836196899\n",
            "Generator loss: 0.0001020850904751569\n",
            "Classifier loss: 0.07425262033939362\n",
            "Classifier loss: 0.5340455174446106\n",
            "Generator loss: 1.1920931797249068e-08\n",
            "Classifier loss: 0.10754861682653427\n",
            "Classifier loss: 0.053614310920238495\n",
            "Generator loss: 5.278091521176975e-06\n",
            "Classifier loss: 0.07866346836090088\n",
            "Classifier loss: 0.5295991897583008\n",
            "Generator loss: 0.0\n",
            "Running epoch 94 out of 1900\n",
            "Classifier loss: 0.04588942602276802\n",
            "Classifier loss: 0.5421350598335266\n",
            "Generator loss: 0.017602501437067986\n",
            "Classifier loss: 0.03276538476347923\n",
            "Classifier loss: 0.04893074929714203\n",
            "Generator loss: 0.035030171275138855\n",
            "Classifier loss: 0.03857344016432762\n",
            "Classifier loss: 0.036932993680238724\n",
            "Generator loss: 0.03470245376229286\n",
            "Classifier loss: 0.07987261563539505\n",
            "Classifier loss: 0.5419545769691467\n",
            "Generator loss: 8.344667179471799e-08\n",
            "Classifier loss: 0.06030240282416344\n",
            "Classifier loss: 0.033206842839717865\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.003289364743977785\n",
            "Classifier loss: 0.03859313949942589\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.01455708034336567\n",
            "Classifier loss: 0.5337778329849243\n",
            "Generator loss: 0.04263179376721382\n",
            "Classifier loss: 0.015830950811505318\n",
            "Classifier loss: 0.04025700315833092\n",
            "Generator loss: 0.004767484497278929\n",
            "Classifier loss: 0.014032505452632904\n",
            "Classifier loss: 0.5394063591957092\n",
            "Generator loss: 0.0024647978134453297\n",
            "Classifier loss: 0.02261205203831196\n",
            "Classifier loss: 0.04589715972542763\n",
            "Generator loss: 0.00032254267716780305\n",
            "Running epoch 95 out of 1900\n",
            "Classifier loss: 0.15294994413852692\n",
            "Classifier loss: 0.025942429900169373\n",
            "Generator loss: 0.000578929902985692\n",
            "Classifier loss: 0.24858440458774567\n",
            "Classifier loss: 0.030772032216191292\n",
            "Generator loss: 0.020599480718374252\n",
            "Classifier loss: 0.14185680449008942\n",
            "Classifier loss: 0.030858296900987625\n",
            "Generator loss: 4.7683719195390495e-09\n",
            "Classifier loss: 0.11831765621900558\n",
            "Classifier loss: 0.026507113128900528\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14466148614883423\n",
            "Classifier loss: 0.08514879643917084\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13134703040122986\n",
            "Classifier loss: 0.04206763207912445\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.09073319286108017\n",
            "Classifier loss: 0.02618752233684063\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1080162525177002\n",
            "Classifier loss: 0.056436486542224884\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10082174837589264\n",
            "Classifier loss: 0.027217159047722816\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10480836778879166\n",
            "Classifier loss: 0.032998502254486084\n",
            "Generator loss: 0.0\n",
            "Running epoch 96 out of 1900\n",
            "Classifier loss: 0.07377344369888306\n",
            "Classifier loss: 0.04198432341217995\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06324318051338196\n",
            "Classifier loss: 0.04087468609213829\n",
            "Generator loss: 0.0001858919276855886\n",
            "Classifier loss: 0.06615635752677917\n",
            "Classifier loss: 0.04010907933115959\n",
            "Generator loss: 0.09475188702344894\n",
            "Classifier loss: 0.06852135807275772\n",
            "Classifier loss: 0.046124789863824844\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.054663386195898056\n",
            "Classifier loss: 0.06112376227974892\n",
            "Generator loss: 0.020741654559969902\n",
            "Classifier loss: 0.07408619672060013\n",
            "Classifier loss: 0.040890004485845566\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06333350390195847\n",
            "Classifier loss: 0.031627457588911057\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0596596784889698\n",
            "Classifier loss: 0.036337364464998245\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0633947104215622\n",
            "Classifier loss: 0.04394686594605446\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06195349618792534\n",
            "Classifier loss: 0.03976628556847572\n",
            "Generator loss: 0.0\n",
            "Running epoch 97 out of 1900\n",
            "Classifier loss: 0.13164770603179932\n",
            "Classifier loss: 0.03450540453195572\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06185930222272873\n",
            "Classifier loss: 0.04006918519735336\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.059920534491539\n",
            "Classifier loss: 0.1014012023806572\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07757105678319931\n",
            "Classifier loss: 0.02557116001844406\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0764012485742569\n",
            "Classifier loss: 0.026609817519783974\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07945992052555084\n",
            "Classifier loss: 0.019666258245706558\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.04978088662028313\n",
            "Classifier loss: 0.022959602996706963\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08261647820472717\n",
            "Classifier loss: 0.019794076681137085\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10746575891971588\n",
            "Classifier loss: 0.019502652809023857\n",
            "Generator loss: 4.86379803987802e-07\n",
            "Classifier loss: 0.0703044906258583\n",
            "Classifier loss: 0.01868542842566967\n",
            "Generator loss: 0.0\n",
            "Running epoch 98 out of 1900\n",
            "Classifier loss: 0.07182076573371887\n",
            "Classifier loss: 0.021470678970217705\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.020830446854233742\n",
            "Classifier loss: 0.018876060843467712\n",
            "Generator loss: 0.035096269100904465\n",
            "Classifier loss: 0.024581467732787132\n",
            "Classifier loss: 0.018390778452157974\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.04200168699026108\n",
            "Classifier loss: 0.015060362406075\n",
            "Generator loss: 0.047994572669267654\n",
            "Classifier loss: 0.04530561715364456\n",
            "Classifier loss: 0.06631620973348618\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.020895255729556084\n",
            "Classifier loss: 0.01749265380203724\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.03502299264073372\n",
            "Classifier loss: 0.01594345085322857\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.022274119779467583\n",
            "Classifier loss: 0.014277609996497631\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.04585404694080353\n",
            "Classifier loss: 0.01610674150288105\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.015767954289913177\n",
            "Classifier loss: 0.015648944303393364\n",
            "Generator loss: 0.0\n",
            "Running epoch 99 out of 1900\n",
            "Classifier loss: 0.1543869972229004\n",
            "Classifier loss: 0.563774049282074\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.162130206823349\n",
            "Classifier loss: 0.06206484138965607\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19604501128196716\n",
            "Classifier loss: 0.014963751658797264\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.16520412266254425\n",
            "Classifier loss: 0.04775996133685112\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.16280849277973175\n",
            "Classifier loss: 0.017758671194314957\n",
            "Generator loss: 8.583086952285157e-08\n",
            "Classifier loss: 0.16244718432426453\n",
            "Classifier loss: 0.030757244676351547\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1471645087003708\n",
            "Classifier loss: 0.016372475773096085\n",
            "Generator loss: 0.021044423803687096\n",
            "Classifier loss: 0.1563749462366104\n",
            "Classifier loss: 0.02027152292430401\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14222955703735352\n",
            "Classifier loss: 0.019649388268589973\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14562562108039856\n",
            "Classifier loss: 0.027227608487010002\n",
            "Generator loss: 0.0\n",
            "Running epoch 100 out of 1900\n",
            "Classifier loss: 0.10250569880008698\n",
            "Classifier loss: 0.0233490988612175\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09229786694049835\n",
            "Classifier loss: 0.027051858603954315\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0738944336771965\n",
            "Classifier loss: 0.02301339991390705\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09556138515472412\n",
            "Classifier loss: 0.02532387711107731\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05833054333925247\n",
            "Classifier loss: 0.057156361639499664\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08792585134506226\n",
            "Classifier loss: 0.03148394078016281\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0919400230050087\n",
            "Classifier loss: 0.06643527746200562\n",
            "Generator loss: 6.938100796105573e-07\n",
            "Classifier loss: 0.07082156836986542\n",
            "Classifier loss: 0.02188287116587162\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08822912722826004\n",
            "Classifier loss: 0.023629168048501015\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07733412832021713\n",
            "Classifier loss: 0.032076314091682434\n",
            "Generator loss: 0.0002116382383974269\n",
            "Running epoch 101 out of 1900\n",
            "Classifier loss: 0.11412061750888824\n",
            "Classifier loss: 0.029285840690135956\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09563559293746948\n",
            "Classifier loss: 0.570923924446106\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07451920211315155\n",
            "Classifier loss: 0.026893865317106247\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08250832557678223\n",
            "Classifier loss: 0.10175053030252457\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06124013662338257\n",
            "Classifier loss: 0.032859813421964645\n",
            "Generator loss: 2.2794056349084713e-06\n",
            "Classifier loss: 0.08374340087175369\n",
            "Classifier loss: 0.028820110484957695\n",
            "Generator loss: 0.006532971281558275\n",
            "Classifier loss: 0.07696700841188431\n",
            "Classifier loss: 0.028272563591599464\n",
            "Generator loss: 0.033676959574222565\n",
            "Classifier loss: 0.0685734674334526\n",
            "Classifier loss: 0.026095425710082054\n",
            "Generator loss: 0.048595551401376724\n",
            "Classifier loss: 0.06242658570408821\n",
            "Classifier loss: 0.03427721560001373\n",
            "Generator loss: 3.424447641009465e-05\n",
            "Classifier loss: 0.07483707368373871\n",
            "Classifier loss: 0.041716016829013824\n",
            "Generator loss: 0.0\n",
            "Running epoch 102 out of 1900\n",
            "Classifier loss: 0.0450592041015625\n",
            "Classifier loss: 0.052410490810871124\n",
            "Generator loss: 0.025550154969096184\n",
            "Classifier loss: 0.08212150633335114\n",
            "Classifier loss: 0.03240397199988365\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06564828753471375\n",
            "Classifier loss: 0.077656589448452\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08797071129083633\n",
            "Classifier loss: 0.0325387641787529\n",
            "Generator loss: 0.0013088436098769307\n",
            "Classifier loss: 0.06160755455493927\n",
            "Classifier loss: 0.03449483588337898\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.042979076504707336\n",
            "Classifier loss: 0.05803566798567772\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.055612437427043915\n",
            "Classifier loss: 0.034104038029909134\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0385652519762516\n",
            "Classifier loss: 0.06448793411254883\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.04484536498785019\n",
            "Classifier loss: 0.053908850997686386\n",
            "Generator loss: 0.021435773000121117\n",
            "Classifier loss: 0.051141157746315\n",
            "Classifier loss: 0.07468652725219727\n",
            "Generator loss: 0.0\n",
            "Running epoch 103 out of 1900\n",
            "Classifier loss: 0.10728868842124939\n",
            "Classifier loss: 0.03613491356372833\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10159531980752945\n",
            "Classifier loss: 0.028748217970132828\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10085739195346832\n",
            "Classifier loss: 0.05931636318564415\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06277945637702942\n",
            "Classifier loss: 0.09669540077447891\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1617407202720642\n",
            "Classifier loss: 0.5255781412124634\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.034024227410554886\n",
            "Classifier loss: 0.047933705151081085\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13372662663459778\n",
            "Classifier loss: 0.06931991130113602\n",
            "Generator loss: 0.012346395291388035\n",
            "Classifier loss: 0.04566365107893944\n",
            "Classifier loss: 0.030072230845689774\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06050197407603264\n",
            "Classifier loss: 0.03511496260762215\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07271555066108704\n",
            "Classifier loss: 0.5247554779052734\n",
            "Generator loss: 0.0\n",
            "Running epoch 104 out of 1900\n",
            "Classifier loss: 0.06027587875723839\n",
            "Classifier loss: 0.5990784764289856\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.044067978858947754\n",
            "Classifier loss: 1.1035081148147583\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05272499471902847\n",
            "Classifier loss: 0.20939350128173828\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.024074144661426544\n",
            "Classifier loss: 1.0301498174667358\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.04517710953950882\n",
            "Classifier loss: 1.5186203718185425\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.03630327805876732\n",
            "Classifier loss: 1.0340713262557983\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.020024633035063744\n",
            "Classifier loss: 0.5216765999794006\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.055553775280714035\n",
            "Classifier loss: 0.5526716709136963\n",
            "Generator loss: 1.1920931797249068e-08\n",
            "Classifier loss: 0.0380207858979702\n",
            "Classifier loss: 0.5209932923316956\n",
            "Generator loss: 1.287464499455382e-07\n",
            "Classifier loss: 0.08433336764574051\n",
            "Classifier loss: 0.5208805203437805\n",
            "Generator loss: 0.0\n",
            "Running epoch 105 out of 1900\n",
            "Classifier loss: 0.13985896110534668\n",
            "Classifier loss: 2.065972089767456\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2488400787115097\n",
            "Classifier loss: 2.2468903064727783\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14728280901908875\n",
            "Classifier loss: 0.5380262732505798\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10997180640697479\n",
            "Classifier loss: 0.5219261646270752\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.15004906058311462\n",
            "Classifier loss: 1.5232551097869873\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13086161017417908\n",
            "Classifier loss: 0.08052972704172134\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10377606004476547\n",
            "Classifier loss: 0.564992368221283\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08314933627843857\n",
            "Classifier loss: 0.03656703233718872\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.24973347783088684\n",
            "Classifier loss: 1.026289701461792\n",
            "Generator loss: 2.25516105274437e-05\n",
            "Classifier loss: 0.13031141459941864\n",
            "Classifier loss: 1.0623188018798828\n",
            "Generator loss: 0.0\n",
            "Running epoch 106 out of 1900\n",
            "Classifier loss: 0.08281643688678741\n",
            "Classifier loss: 1.072228193283081\n",
            "Generator loss: 0.00263254065066576\n",
            "Classifier loss: 0.06391844153404236\n",
            "Classifier loss: 1.5504398345947266\n",
            "Generator loss: 0.008496066555380821\n",
            "Classifier loss: 0.1360933929681778\n",
            "Classifier loss: 1.5759148597717285\n",
            "Generator loss: 0.04961448535323143\n",
            "Classifier loss: 0.14754338562488556\n",
            "Classifier loss: 1.1610275506973267\n",
            "Generator loss: 1.72677609953098e-05\n",
            "Classifier loss: 0.12908631563186646\n",
            "Classifier loss: 0.5916168093681335\n",
            "Generator loss: 0.13490092754364014\n",
            "Classifier loss: 0.10379362106323242\n",
            "Classifier loss: 0.6030617356300354\n",
            "Generator loss: 0.003818835597485304\n",
            "Classifier loss: 0.13824759423732758\n",
            "Classifier loss: 0.591094970703125\n",
            "Generator loss: 0.05315345525741577\n",
            "Classifier loss: 0.07659780234098434\n",
            "Classifier loss: 1.5203701257705688\n",
            "Generator loss: 0.07225300371646881\n",
            "Classifier loss: 0.13638989627361298\n",
            "Classifier loss: 1.5715457201004028\n",
            "Generator loss: 0.0019679516553878784\n",
            "Classifier loss: 0.15440388023853302\n",
            "Classifier loss: 0.025875024497509003\n",
            "Generator loss: 0.07216829061508179\n",
            "Running epoch 107 out of 1900\n",
            "Classifier loss: 0.2332463562488556\n",
            "Classifier loss: 0.04859786480665207\n",
            "Generator loss: 0.017881974577903748\n",
            "Classifier loss: 0.3651418089866638\n",
            "Classifier loss: 0.024720866233110428\n",
            "Generator loss: 3.09944390153305e-08\n",
            "Classifier loss: 0.15887518227100372\n",
            "Classifier loss: 0.020195750519633293\n",
            "Generator loss: 0.022444142028689384\n",
            "Classifier loss: 0.14771565794944763\n",
            "Classifier loss: 0.020732713863253593\n",
            "Generator loss: 4.4584771785594057e-07\n",
            "Classifier loss: 0.13795575499534607\n",
            "Classifier loss: 0.09385881572961807\n",
            "Generator loss: 0.03873217850923538\n",
            "Classifier loss: 0.1916174292564392\n",
            "Classifier loss: 0.01745889149606228\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10553129762411118\n",
            "Classifier loss: 0.04220326244831085\n",
            "Generator loss: 0.013159211724996567\n",
            "Classifier loss: 0.11670450121164322\n",
            "Classifier loss: 0.02419811114668846\n",
            "Generator loss: 0.06249341741204262\n",
            "Classifier loss: 0.08577841520309448\n",
            "Classifier loss: 0.05018749088048935\n",
            "Generator loss: 0.0026329399552196264\n",
            "Classifier loss: 0.06816527247428894\n",
            "Classifier loss: 0.03713572397828102\n",
            "Generator loss: 1.1920931797249068e-08\n",
            "Running epoch 108 out of 1900\n",
            "Classifier loss: 0.07173410058021545\n",
            "Classifier loss: 0.07189920544624329\n",
            "Generator loss: 0.011550167575478554\n",
            "Classifier loss: 0.0722762942314148\n",
            "Classifier loss: 0.042222004383802414\n",
            "Generator loss: 1.3804910850012675e-06\n",
            "Classifier loss: 0.0635736808180809\n",
            "Classifier loss: 0.0821651816368103\n",
            "Generator loss: 0.08314042538404465\n",
            "Classifier loss: 0.06417706608772278\n",
            "Classifier loss: 0.027852267026901245\n",
            "Generator loss: 0.04187975823879242\n",
            "Classifier loss: 0.10630481690168381\n",
            "Classifier loss: 0.5512993335723877\n",
            "Generator loss: 0.03831818327307701\n",
            "Classifier loss: 0.046399787068367004\n",
            "Classifier loss: 0.048637568950653076\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.03516243025660515\n",
            "Classifier loss: 0.05980938300490379\n",
            "Generator loss: 2.0026454876642674e-05\n",
            "Classifier loss: 0.03791695460677147\n",
            "Classifier loss: 0.03530217707157135\n",
            "Generator loss: 4.387060471344739e-05\n",
            "Classifier loss: 0.04099461808800697\n",
            "Classifier loss: 0.03756440058350563\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.057783093303442\n",
            "Classifier loss: 0.5627793669700623\n",
            "Generator loss: 0.02704429253935814\n",
            "Running epoch 109 out of 1900\n",
            "Classifier loss: 0.1972568780183792\n",
            "Classifier loss: 1.1350468397140503\n",
            "Generator loss: 0.012261847965419292\n",
            "Classifier loss: 0.09600937366485596\n",
            "Classifier loss: 1.0471467971801758\n",
            "Generator loss: 0.009438199922442436\n",
            "Classifier loss: 0.24171927571296692\n",
            "Classifier loss: 0.5503354668617249\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10631964355707169\n",
            "Classifier loss: 1.5301023721694946\n",
            "Generator loss: 0.0005140855791978538\n",
            "Classifier loss: 0.11058293282985687\n",
            "Classifier loss: 0.5445894598960876\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10662121325731277\n",
            "Classifier loss: 1.042004108428955\n",
            "Generator loss: 6.198891355779779e-08\n",
            "Classifier loss: 0.11958730220794678\n",
            "Classifier loss: 0.1786838173866272\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10926833003759384\n",
            "Classifier loss: 1.031707763671875\n",
            "Generator loss: 0.02261485531926155\n",
            "Classifier loss: 0.19526179134845734\n",
            "Classifier loss: 0.034832604229450226\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1070866584777832\n",
            "Classifier loss: 0.5498225092887878\n",
            "Generator loss: 0.043757710605859756\n",
            "Running epoch 110 out of 1900\n",
            "Classifier loss: 0.1342403143644333\n",
            "Classifier loss: 0.04798922315239906\n",
            "Generator loss: 8.821505304013044e-08\n",
            "Classifier loss: 0.10836463421583176\n",
            "Classifier loss: 0.0710415244102478\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.15063439309597015\n",
            "Classifier loss: 1.1178311109542847\n",
            "Generator loss: 0.02689686417579651\n",
            "Classifier loss: 0.20620086789131165\n",
            "Classifier loss: 1.5917612314224243\n",
            "Generator loss: 0.04035773500800133\n",
            "Classifier loss: 0.11674915999174118\n",
            "Classifier loss: 1.053995966911316\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.32515785098075867\n",
            "Classifier loss: 2.04095458984375\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06157074496150017\n",
            "Classifier loss: 2.537350654602051\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.17938368022441864\n",
            "Classifier loss: 2.536959409713745\n",
            "Generator loss: 0.005168554838746786\n",
            "Classifier loss: 0.07310696691274643\n",
            "Classifier loss: 2.049142360687256\n",
            "Generator loss: 1.1920964482214913e-07\n",
            "Classifier loss: 0.06726629287004471\n",
            "Classifier loss: 2.0753209590911865\n",
            "Generator loss: 0.03172606974840164\n",
            "Running epoch 111 out of 1900\n",
            "Classifier loss: 0.06384188681840897\n",
            "Classifier loss: 2.5553858280181885\n",
            "Generator loss: 0.011530362069606781\n",
            "Classifier loss: 0.060713332146406174\n",
            "Classifier loss: 3.1675424575805664\n",
            "Generator loss: 0.04284028336405754\n",
            "Classifier loss: 0.04728223383426666\n",
            "Classifier loss: 2.1962294578552246\n",
            "Generator loss: 0.028496090322732925\n",
            "Classifier loss: 0.04518388956785202\n",
            "Classifier loss: 1.5622596740722656\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.03262791782617569\n",
            "Classifier loss: 0.6318649649620056\n",
            "Generator loss: 0.012729336507618427\n",
            "Classifier loss: 0.0606330968439579\n",
            "Classifier loss: 1.095609426498413\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07378698885440826\n",
            "Classifier loss: 2.0311708450317383\n",
            "Generator loss: 0.006871092598885298\n",
            "Classifier loss: 0.18850941956043243\n",
            "Classifier loss: 1.051679253578186\n",
            "Generator loss: 0.030118826776742935\n",
            "Classifier loss: 0.2864138185977936\n",
            "Classifier loss: 1.0631697177886963\n",
            "Generator loss: 9.536765332995856e-08\n",
            "Classifier loss: 0.27021846175193787\n",
            "Classifier loss: 1.0256620645523071\n",
            "Generator loss: 0.03321344405412674\n",
            "Running epoch 112 out of 1900\n",
            "Classifier loss: 0.2553703784942627\n",
            "Classifier loss: 1.045894980430603\n",
            "Generator loss: 0.015194879844784737\n",
            "Classifier loss: 0.1782488226890564\n",
            "Classifier loss: 1.5425256490707397\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.12558333575725555\n",
            "Classifier loss: 1.5689644813537598\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19116047024726868\n",
            "Classifier loss: 1.5630370378494263\n",
            "Generator loss: 0.022141193971037865\n",
            "Classifier loss: 0.13287942111492157\n",
            "Classifier loss: 1.5620663166046143\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.056786391884088516\n",
            "Classifier loss: 0.6214421987533569\n",
            "Generator loss: 0.052274439483881\n",
            "Classifier loss: 0.08114021271467209\n",
            "Classifier loss: 1.5510071516036987\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1176588237285614\n",
            "Classifier loss: 1.5992013216018677\n",
            "Generator loss: 0.008181918412446976\n",
            "Classifier loss: 0.11431171000003815\n",
            "Classifier loss: 0.5403493642807007\n",
            "Generator loss: 7.152558545442389e-09\n",
            "Classifier loss: 0.16565482318401337\n",
            "Classifier loss: 1.0315937995910645\n",
            "Generator loss: 0.0\n",
            "Running epoch 113 out of 1900\n",
            "Classifier loss: 0.30647915601730347\n",
            "Classifier loss: 1.5381770133972168\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19867725670337677\n",
            "Classifier loss: 0.12276370823383331\n",
            "Generator loss: 2.3533298190159258e-06\n",
            "Classifier loss: 0.19932468235492706\n",
            "Classifier loss: 0.14773614704608917\n",
            "Generator loss: 0.02735043689608574\n",
            "Classifier loss: 0.16444173455238342\n",
            "Classifier loss: 1.094572901725769\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2291182279586792\n",
            "Classifier loss: 1.047993540763855\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1706530600786209\n",
            "Classifier loss: 0.6567284464836121\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.18044090270996094\n",
            "Classifier loss: 0.14572635293006897\n",
            "Generator loss: 0.021855738013982773\n",
            "Classifier loss: 0.17084990441799164\n",
            "Classifier loss: 0.058389823883771896\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14592145383358002\n",
            "Classifier loss: 0.08136779814958572\n",
            "Generator loss: 0.025215014815330505\n",
            "Classifier loss: 0.16070808470249176\n",
            "Classifier loss: 0.13485290110111237\n",
            "Generator loss: 0.014257367700338364\n",
            "Running epoch 114 out of 1900\n",
            "Classifier loss: 0.2026221603155136\n",
            "Classifier loss: 0.05041689798235893\n",
            "Generator loss: 0.01815548539161682\n",
            "Classifier loss: 0.2263975441455841\n",
            "Classifier loss: 0.10172466188669205\n",
            "Generator loss: 0.04082626849412918\n",
            "Classifier loss: 0.15454506874084473\n",
            "Classifier loss: 0.04442357271909714\n",
            "Generator loss: 0.09380478411912918\n",
            "Classifier loss: 0.1414826512336731\n",
            "Classifier loss: 0.09929679334163666\n",
            "Generator loss: 0.006862631067633629\n",
            "Classifier loss: 0.14655816555023193\n",
            "Classifier loss: 0.17757254838943481\n",
            "Generator loss: 0.034735046327114105\n",
            "Classifier loss: 0.1565418541431427\n",
            "Classifier loss: 0.17786742746829987\n",
            "Generator loss: 0.02682625688612461\n",
            "Classifier loss: 0.15934284031391144\n",
            "Classifier loss: 0.07560597360134125\n",
            "Generator loss: 0.06005258485674858\n",
            "Classifier loss: 0.11029291152954102\n",
            "Classifier loss: 0.052173614501953125\n",
            "Generator loss: 0.0620511956512928\n",
            "Classifier loss: 0.12782444059848785\n",
            "Classifier loss: 0.5838372111320496\n",
            "Generator loss: 0.026694195345044136\n",
            "Classifier loss: 0.15974807739257812\n",
            "Classifier loss: 1.0829682350158691\n",
            "Generator loss: 0.0\n",
            "Running epoch 115 out of 1900\n",
            "Classifier loss: 0.3296312391757965\n",
            "Classifier loss: 1.152884840965271\n",
            "Generator loss: 0.1447189599275589\n",
            "Classifier loss: 0.27736154198646545\n",
            "Classifier loss: 0.5830382704734802\n",
            "Generator loss: 0.0720643699169159\n",
            "Classifier loss: 0.3551495373249054\n",
            "Classifier loss: 0.5612404346466064\n",
            "Generator loss: 0.055160071700811386\n",
            "Classifier loss: 0.3053467273712158\n",
            "Classifier loss: 0.07908713817596436\n",
            "Generator loss: 3.7193629509602033e-07\n",
            "Classifier loss: 0.22189722955226898\n",
            "Classifier loss: 1.152480959892273\n",
            "Generator loss: 0.0820719450712204\n",
            "Classifier loss: 0.4145374894142151\n",
            "Classifier loss: 1.5484482049942017\n",
            "Generator loss: 0.02370654046535492\n",
            "Classifier loss: 0.2278946489095688\n",
            "Classifier loss: 0.6059162020683289\n",
            "Generator loss: 2.1791511244373396e-05\n",
            "Classifier loss: 0.20913110673427582\n",
            "Classifier loss: 1.1018410921096802\n",
            "Generator loss: 2.4320152078871615e-06\n",
            "Classifier loss: 0.2011050134897232\n",
            "Classifier loss: 1.1488094329833984\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.28231653571128845\n",
            "Classifier loss: 0.5712514519691467\n",
            "Generator loss: 0.0845310166478157\n",
            "Running epoch 116 out of 1900\n",
            "Classifier loss: 0.10412606596946716\n",
            "Classifier loss: 1.137060523033142\n",
            "Generator loss: 0.023975610733032227\n",
            "Classifier loss: 0.09808776527643204\n",
            "Classifier loss: 0.69731205701828\n",
            "Generator loss: 1.4305117979063198e-08\n",
            "Classifier loss: 0.1038271114230156\n",
            "Classifier loss: 0.5997745394706726\n",
            "Generator loss: 0.027341203764081\n",
            "Classifier loss: 0.16482532024383545\n",
            "Classifier loss: 0.17787215113639832\n",
            "Generator loss: 0.025325795635581017\n",
            "Classifier loss: 0.1047542616724968\n",
            "Classifier loss: 0.5728736519813538\n",
            "Generator loss: 0.01660320721566677\n",
            "Classifier loss: 0.08371581882238388\n",
            "Classifier loss: 0.6183150410652161\n",
            "Generator loss: 0.003287655534222722\n",
            "Classifier loss: 0.08306477218866348\n",
            "Classifier loss: 0.6235542297363281\n",
            "Generator loss: 0.0049737547524273396\n",
            "Classifier loss: 0.09031146764755249\n",
            "Classifier loss: 0.5734298825263977\n",
            "Generator loss: 0.04468121752142906\n",
            "Classifier loss: 0.08898643404245377\n",
            "Classifier loss: 0.6370996236801147\n",
            "Generator loss: 0.03823859989643097\n",
            "Classifier loss: 0.08417020738124847\n",
            "Classifier loss: 0.5671958923339844\n",
            "Generator loss: 0.0002999052812810987\n",
            "Running epoch 117 out of 1900\n",
            "Classifier loss: 0.09811443090438843\n",
            "Classifier loss: 1.1269344091415405\n",
            "Generator loss: 0.004142390564084053\n",
            "Classifier loss: 0.08906341344118118\n",
            "Classifier loss: 1.1005489826202393\n",
            "Generator loss: 2.0760338884429075e-05\n",
            "Classifier loss: 0.1172223910689354\n",
            "Classifier loss: 0.1265178918838501\n",
            "Generator loss: 0.0007336917333304882\n",
            "Classifier loss: 0.08099005371332169\n",
            "Classifier loss: 0.13242538273334503\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11031194776296616\n",
            "Classifier loss: 0.08496280759572983\n",
            "Generator loss: 0.06891824305057526\n",
            "Classifier loss: 0.11852660030126572\n",
            "Classifier loss: 0.08067400753498077\n",
            "Generator loss: 0.0007133322069421411\n",
            "Classifier loss: 0.13268481194972992\n",
            "Classifier loss: 0.08478265255689621\n",
            "Generator loss: 0.0034592992160469294\n",
            "Classifier loss: 0.10620982944965363\n",
            "Classifier loss: 0.04952700436115265\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08022350072860718\n",
            "Classifier loss: 0.06772179156541824\n",
            "Generator loss: 0.0017362996004521847\n",
            "Classifier loss: 0.0768381655216217\n",
            "Classifier loss: 0.05528045445680618\n",
            "Generator loss: 0.01052802987396717\n",
            "Running epoch 118 out of 1900\n",
            "Classifier loss: 0.09449897706508636\n",
            "Classifier loss: 0.0577206015586853\n",
            "Generator loss: 0.019297322258353233\n",
            "Classifier loss: 0.10149377584457397\n",
            "Classifier loss: 0.06517206132411957\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1309107542037964\n",
            "Classifier loss: 0.10664109140634537\n",
            "Generator loss: 0.0670819953083992\n",
            "Classifier loss: 0.11162177473306656\n",
            "Classifier loss: 0.548695981502533\n",
            "Generator loss: 0.006096887867897749\n",
            "Classifier loss: 0.104341521859169\n",
            "Classifier loss: 0.0486200712621212\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1072508692741394\n",
            "Classifier loss: 0.0746355876326561\n",
            "Generator loss: 0.0042297085747122765\n",
            "Classifier loss: 0.08027837425470352\n",
            "Classifier loss: 0.02261257916688919\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07400573790073395\n",
            "Classifier loss: 0.040508270263671875\n",
            "Generator loss: 0.0047419131733477116\n",
            "Classifier loss: 0.10172278434038162\n",
            "Classifier loss: 0.04148334264755249\n",
            "Generator loss: 0.007443901617079973\n",
            "Classifier loss: 0.09137879312038422\n",
            "Classifier loss: 0.07309750467538834\n",
            "Generator loss: 0.003140826476737857\n",
            "Running epoch 119 out of 1900\n",
            "Classifier loss: 0.1145077645778656\n",
            "Classifier loss: 0.5960525870323181\n",
            "Generator loss: 0.017315352335572243\n",
            "Classifier loss: 0.11285806447267532\n",
            "Classifier loss: 0.5367679595947266\n",
            "Generator loss: 0.07436445355415344\n",
            "Classifier loss: 0.07656146585941315\n",
            "Classifier loss: 0.18393786251544952\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10794375091791153\n",
            "Classifier loss: 0.2170935571193695\n",
            "Generator loss: 1.4552402717527002e-05\n",
            "Classifier loss: 0.0734771192073822\n",
            "Classifier loss: 0.10827391594648361\n",
            "Generator loss: 8.583086952285157e-08\n",
            "Classifier loss: 0.0910937637090683\n",
            "Classifier loss: 0.050500091165304184\n",
            "Generator loss: 0.052704453468322754\n",
            "Classifier loss: 0.13281051814556122\n",
            "Classifier loss: 0.06626119464635849\n",
            "Generator loss: 0.014709982089698315\n",
            "Classifier loss: 0.08087741583585739\n",
            "Classifier loss: 0.13711240887641907\n",
            "Generator loss: 0.02330029383301735\n",
            "Classifier loss: 0.06458713114261627\n",
            "Classifier loss: 0.027369851246476173\n",
            "Generator loss: 0.00032427351106889546\n",
            "Classifier loss: 0.10682723671197891\n",
            "Classifier loss: 0.04574733227491379\n",
            "Generator loss: 1.1819515748356935e-05\n",
            "Running epoch 120 out of 1900\n",
            "Classifier loss: 0.04306149482727051\n",
            "Classifier loss: 0.025847014039754868\n",
            "Generator loss: 9.107797040996957e-07\n",
            "Classifier loss: 0.025333084166049957\n",
            "Classifier loss: 0.5524585843086243\n",
            "Generator loss: 0.0007308009080588818\n",
            "Classifier loss: 0.14193286001682281\n",
            "Classifier loss: 0.05424714833498001\n",
            "Generator loss: 4.7683719195390495e-09\n",
            "Classifier loss: 0.15724924206733704\n",
            "Classifier loss: 0.558280348777771\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08573662489652634\n",
            "Classifier loss: 0.07595495879650116\n",
            "Generator loss: 0.016231374815106392\n",
            "Classifier loss: 0.09843458235263824\n",
            "Classifier loss: 0.0942232683300972\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07485175877809525\n",
            "Classifier loss: 0.05624529719352722\n",
            "Generator loss: 0.0023277970030903816\n",
            "Classifier loss: 0.053861916065216064\n",
            "Classifier loss: 0.027497677132487297\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08493717759847641\n",
            "Classifier loss: 0.032177962362766266\n",
            "Generator loss: 0.002471808111295104\n",
            "Classifier loss: 0.11972251534461975\n",
            "Classifier loss: 0.06547534465789795\n",
            "Generator loss: 0.0\n",
            "Running epoch 121 out of 1900\n",
            "Classifier loss: 0.08468431234359741\n",
            "Classifier loss: 0.04757864773273468\n",
            "Generator loss: 0.06532931327819824\n",
            "Classifier loss: 0.12458869814872742\n",
            "Classifier loss: 0.02006244659423828\n",
            "Generator loss: 0.013014943338930607\n",
            "Classifier loss: 0.1183062493801117\n",
            "Classifier loss: 0.04580201208591461\n",
            "Generator loss: 0.017976175993680954\n",
            "Classifier loss: 0.0765029639005661\n",
            "Classifier loss: 0.04669545218348503\n",
            "Generator loss: 0.07078000903129578\n",
            "Classifier loss: 0.10478702932596207\n",
            "Classifier loss: 0.044373806565999985\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08910689502954483\n",
            "Classifier loss: 0.026558607816696167\n",
            "Generator loss: 0.09492640942335129\n",
            "Classifier loss: 0.16272804141044617\n",
            "Classifier loss: 0.5815259218215942\n",
            "Generator loss: 2.4760784071986564e-05\n",
            "Classifier loss: 0.12701986730098724\n",
            "Classifier loss: 0.11578837782144547\n",
            "Generator loss: 6.11875657341443e-06\n",
            "Classifier loss: 0.09449830651283264\n",
            "Classifier loss: 0.07137744873762131\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1004163920879364\n",
            "Classifier loss: 0.03406481817364693\n",
            "Generator loss: 2.9487795472959988e-05\n",
            "Running epoch 122 out of 1900\n",
            "Classifier loss: 0.13103440403938293\n",
            "Classifier loss: 0.039845142513513565\n",
            "Generator loss: 0.01810050569474697\n",
            "Classifier loss: 0.11854571849107742\n",
            "Classifier loss: 0.06755726039409637\n",
            "Generator loss: 0.005104479845613241\n",
            "Classifier loss: 0.1215546503663063\n",
            "Classifier loss: 0.08024018257856369\n",
            "Generator loss: 0.05897677689790726\n",
            "Classifier loss: 0.07648657262325287\n",
            "Classifier loss: 0.04475511983036995\n",
            "Generator loss: 0.04155541956424713\n",
            "Classifier loss: 0.11295419186353683\n",
            "Classifier loss: 0.07583282887935638\n",
            "Generator loss: 0.006497462745755911\n",
            "Classifier loss: 0.07964832335710526\n",
            "Classifier loss: 0.02121650241315365\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07645475119352341\n",
            "Classifier loss: 0.035680368542671204\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14890816807746887\n",
            "Classifier loss: 0.10912667214870453\n",
            "Generator loss: 0.029413660988211632\n",
            "Classifier loss: 0.09435008466243744\n",
            "Classifier loss: 0.07087086886167526\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08721952140331268\n",
            "Classifier loss: 0.07541079074144363\n",
            "Generator loss: 0.0\n",
            "Running epoch 123 out of 1900\n",
            "Classifier loss: 0.33654436469078064\n",
            "Classifier loss: 0.12635482847690582\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10312360525131226\n",
            "Classifier loss: 0.03959455341100693\n",
            "Generator loss: 0.010751106776297092\n",
            "Classifier loss: 0.13584288954734802\n",
            "Classifier loss: 0.01465602871030569\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2955048382282257\n",
            "Classifier loss: 0.0257366131991148\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13686516880989075\n",
            "Classifier loss: 0.03956122323870659\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0864354819059372\n",
            "Classifier loss: 0.02448207326233387\n",
            "Generator loss: 0.11295828223228455\n",
            "Classifier loss: 0.1315721571445465\n",
            "Classifier loss: 0.04097085818648338\n",
            "Generator loss: 0.07263827323913574\n",
            "Classifier loss: 0.04823460802435875\n",
            "Classifier loss: 0.05542619153857231\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.12489953637123108\n",
            "Classifier loss: 0.0870763435959816\n",
            "Generator loss: 1.4535700756823644e-05\n",
            "Classifier loss: 0.07053124904632568\n",
            "Classifier loss: 0.0484028197824955\n",
            "Generator loss: 0.014421072788536549\n",
            "Running epoch 124 out of 1900\n",
            "Classifier loss: 0.193730428814888\n",
            "Classifier loss: 0.6153554320335388\n",
            "Generator loss: 9.457075066165999e-06\n",
            "Classifier loss: 0.12003766745328903\n",
            "Classifier loss: 1.0479869842529297\n",
            "Generator loss: 2.5510948375995213e-07\n",
            "Classifier loss: 0.17290353775024414\n",
            "Classifier loss: 0.03214773163199425\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14041279256343842\n",
            "Classifier loss: 0.5352854132652283\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06812525540590286\n",
            "Classifier loss: 1.0328197479248047\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.12977272272109985\n",
            "Classifier loss: 1.0241341590881348\n",
            "Generator loss: 0.01284466590732336\n",
            "Classifier loss: 0.1378491371870041\n",
            "Classifier loss: 0.5579701066017151\n",
            "Generator loss: 8.581332622270565e-06\n",
            "Classifier loss: 0.0800325945019722\n",
            "Classifier loss: 0.5926133394241333\n",
            "Generator loss: 5.722053941781269e-08\n",
            "Classifier loss: 0.1043182760477066\n",
            "Classifier loss: 0.025141609832644463\n",
            "Generator loss: 0.053110431879758835\n",
            "Classifier loss: 0.09781044721603394\n",
            "Classifier loss: 0.053066834807395935\n",
            "Generator loss: 0.0\n",
            "Running epoch 125 out of 1900\n",
            "Classifier loss: 0.10351378470659256\n",
            "Classifier loss: 0.03301601856946945\n",
            "Generator loss: 0.025326840579509735\n",
            "Classifier loss: 0.172561913728714\n",
            "Classifier loss: 0.030127104371786118\n",
            "Generator loss: 0.002640297869220376\n",
            "Classifier loss: 0.26663413643836975\n",
            "Classifier loss: 0.05165227875113487\n",
            "Generator loss: 0.08128228038549423\n",
            "Classifier loss: 0.18113330006599426\n",
            "Classifier loss: 0.04017847403883934\n",
            "Generator loss: 0.027415363118052483\n",
            "Classifier loss: 0.1542215496301651\n",
            "Classifier loss: 0.042509775608778\n",
            "Generator loss: 0.032514188438653946\n",
            "Classifier loss: 0.11939407140016556\n",
            "Classifier loss: 0.04925014451146126\n",
            "Generator loss: 0.05605778470635414\n",
            "Classifier loss: 0.14112478494644165\n",
            "Classifier loss: 0.0286202784627676\n",
            "Generator loss: 0.0013961349613964558\n",
            "Classifier loss: 0.13390488922595978\n",
            "Classifier loss: 0.14827904105186462\n",
            "Generator loss: 0.003081577131524682\n",
            "Classifier loss: 0.12444006651639938\n",
            "Classifier loss: 0.13024216890335083\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1521596908569336\n",
            "Classifier loss: 0.13197994232177734\n",
            "Generator loss: 0.0033617427106946707\n",
            "Running epoch 126 out of 1900\n",
            "Classifier loss: 0.02462349273264408\n",
            "Classifier loss: 0.04062642529606819\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.03216812387108803\n",
            "Classifier loss: 0.07724121958017349\n",
            "Generator loss: 6.289825250860304e-05\n",
            "Classifier loss: 0.032091572880744934\n",
            "Classifier loss: 0.5951277613639832\n",
            "Generator loss: 0.05567237734794617\n",
            "Classifier loss: 0.03241095319390297\n",
            "Classifier loss: 0.12768936157226562\n",
            "Generator loss: 0.05359969660639763\n",
            "Classifier loss: 0.07013628631830215\n",
            "Classifier loss: 0.5675793886184692\n",
            "Generator loss: 0.024767836555838585\n",
            "Classifier loss: 0.06623882800340652\n",
            "Classifier loss: 0.03807507082819939\n",
            "Generator loss: 0.03577359765768051\n",
            "Classifier loss: 0.044341400265693665\n",
            "Classifier loss: 0.6097182035446167\n",
            "Generator loss: 0.02128925919532776\n",
            "Classifier loss: 0.053805217146873474\n",
            "Classifier loss: 0.04582700505852699\n",
            "Generator loss: 0.04206409677863121\n",
            "Classifier loss: 0.05154906213283539\n",
            "Classifier loss: 0.0408933088183403\n",
            "Generator loss: 0.03988535329699516\n",
            "Classifier loss: 0.005078642629086971\n",
            "Classifier loss: 0.04976293444633484\n",
            "Generator loss: 0.0\n",
            "Running epoch 127 out of 1900\n",
            "Classifier loss: 0.1905927062034607\n",
            "Classifier loss: 0.05478786304593086\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.38167235255241394\n",
            "Classifier loss: 0.024666504934430122\n",
            "Generator loss: 0.011689790524542332\n",
            "Classifier loss: 0.2987378239631653\n",
            "Classifier loss: 0.03807780519127846\n",
            "Generator loss: 7.152558545442389e-09\n",
            "Classifier loss: 0.30471691489219666\n",
            "Classifier loss: 0.027334675192832947\n",
            "Generator loss: 0.07550495117902756\n",
            "Classifier loss: 0.148458331823349\n",
            "Classifier loss: 0.03508898615837097\n",
            "Generator loss: 0.012739522382616997\n",
            "Classifier loss: 0.1683960109949112\n",
            "Classifier loss: 0.05350823327898979\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1394628882408142\n",
            "Classifier loss: 0.5883322954177856\n",
            "Generator loss: 1.7023794498527423e-06\n",
            "Classifier loss: 0.15504254400730133\n",
            "Classifier loss: 0.04792746901512146\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14863285422325134\n",
            "Classifier loss: 0.038742899894714355\n",
            "Generator loss: 0.029002858325839043\n",
            "Classifier loss: 0.152587890625\n",
            "Classifier loss: 0.03616342321038246\n",
            "Generator loss: 0.0\n",
            "Running epoch 128 out of 1900\n",
            "Classifier loss: 0.12372783571481705\n",
            "Classifier loss: 0.11786679178476334\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13899831473827362\n",
            "Classifier loss: 0.047204941511154175\n",
            "Generator loss: 0.010375572368502617\n",
            "Classifier loss: 0.09341295808553696\n",
            "Classifier loss: 0.0698155015707016\n",
            "Generator loss: 0.059949420392513275\n",
            "Classifier loss: 0.1313604861497879\n",
            "Classifier loss: 0.053842391818761826\n",
            "Generator loss: 3.04871573462151e-05\n",
            "Classifier loss: 0.07069912552833557\n",
            "Classifier loss: 0.06276728212833405\n",
            "Generator loss: 0.0025478932075202465\n",
            "Classifier loss: 0.07949826866388321\n",
            "Classifier loss: 0.05892487242817879\n",
            "Generator loss: 1.6689307713591006e-08\n",
            "Classifier loss: 0.09251302480697632\n",
            "Classifier loss: 0.13421191275119781\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08093728125095367\n",
            "Classifier loss: 0.11896034330129623\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09046544879674911\n",
            "Classifier loss: 0.1167907863855362\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07265189290046692\n",
            "Classifier loss: 0.10515258461236954\n",
            "Generator loss: 0.0\n",
            "Running epoch 129 out of 1900\n",
            "Classifier loss: 0.15012384951114655\n",
            "Classifier loss: 0.556892454624176\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.23167523741722107\n",
            "Classifier loss: 0.06811834871768951\n",
            "Generator loss: 1.263658305106219e-06\n",
            "Classifier loss: 0.243912011384964\n",
            "Classifier loss: 1.062534213066101\n",
            "Generator loss: 0.014917289838194847\n",
            "Classifier loss: 0.18389824032783508\n",
            "Classifier loss: 0.5485923290252686\n",
            "Generator loss: 0.021048085764050484\n",
            "Classifier loss: 0.12850354611873627\n",
            "Classifier loss: 0.5660161375999451\n",
            "Generator loss: 9.536745615434938e-09\n",
            "Classifier loss: 0.13813374936580658\n",
            "Classifier loss: 0.104689821600914\n",
            "Generator loss: 0.001244901679456234\n",
            "Classifier loss: 0.10666956007480621\n",
            "Classifier loss: 0.5892553329467773\n",
            "Generator loss: 0.07548310607671738\n",
            "Classifier loss: 0.10229802876710892\n",
            "Classifier loss: 0.06348876655101776\n",
            "Generator loss: 0.054708294570446014\n",
            "Classifier loss: 0.12392863631248474\n",
            "Classifier loss: 0.0528983473777771\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13184164464473724\n",
            "Classifier loss: 0.04796188324689865\n",
            "Generator loss: 0.01845122128725052\n",
            "Running epoch 130 out of 1900\n",
            "Classifier loss: 0.11552836745977402\n",
            "Classifier loss: 0.05275176092982292\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.16230207681655884\n",
            "Classifier loss: 0.0982189029455185\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09979211539030075\n",
            "Classifier loss: 0.041695546358823776\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09533348679542542\n",
            "Classifier loss: 0.03937319293618202\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13363099098205566\n",
            "Classifier loss: 0.05527505278587341\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1257363259792328\n",
            "Classifier loss: 0.04761110991239548\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11111032217741013\n",
            "Classifier loss: 0.04748530313372612\n",
            "Generator loss: 0.011448943056166172\n",
            "Classifier loss: 0.13217759132385254\n",
            "Classifier loss: 0.08079659938812256\n",
            "Generator loss: 0.01478730421513319\n",
            "Classifier loss: 0.07982124388217926\n",
            "Classifier loss: 0.13238194584846497\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09902597963809967\n",
            "Classifier loss: 0.05443618819117546\n",
            "Generator loss: 0.0\n",
            "Running epoch 131 out of 1900\n",
            "Classifier loss: 0.14917485415935516\n",
            "Classifier loss: 0.12557336688041687\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1802133172750473\n",
            "Classifier loss: 0.04504675790667534\n",
            "Generator loss: 4.988209548173472e-05\n",
            "Classifier loss: 0.11161801964044571\n",
            "Classifier loss: 0.04221535474061966\n",
            "Generator loss: 0.03255061060190201\n",
            "Classifier loss: 0.15463818609714508\n",
            "Classifier loss: 0.05807299539446831\n",
            "Generator loss: 0.0014578148256987333\n",
            "Classifier loss: 0.17653948068618774\n",
            "Classifier loss: 0.03936827555298805\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14721520245075226\n",
            "Classifier loss: 0.05024353414773941\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1535036861896515\n",
            "Classifier loss: 0.06737710535526276\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11189398169517517\n",
            "Classifier loss: 0.09398138523101807\n",
            "Generator loss: 0.007027143146842718\n",
            "Classifier loss: 0.1204257681965828\n",
            "Classifier loss: 0.04861660674214363\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1813817173242569\n",
            "Classifier loss: 0.5461381673812866\n",
            "Generator loss: 0.0\n",
            "Running epoch 132 out of 1900\n",
            "Classifier loss: 0.17897118628025055\n",
            "Classifier loss: 2.5439066886901855\n",
            "Generator loss: 9.298345560182497e-08\n",
            "Classifier loss: 0.125932976603508\n",
            "Classifier loss: 1.12032151222229\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13806390762329102\n",
            "Classifier loss: 2.036241292953491\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.14321528375148773\n",
            "Classifier loss: 1.080996036529541\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19398295879364014\n",
            "Classifier loss: 1.0341684818267822\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.16502225399017334\n",
            "Classifier loss: 0.5445367693901062\n",
            "Generator loss: 0.008924667723476887\n",
            "Classifier loss: 0.22711920738220215\n",
            "Classifier loss: 1.0381466150283813\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.17086324095726013\n",
            "Classifier loss: 1.0347880125045776\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13858602941036224\n",
            "Classifier loss: 1.6211156845092773\n",
            "Generator loss: 0.00013371242675930262\n",
            "Classifier loss: 0.4065198302268982\n",
            "Classifier loss: 1.0552359819412231\n",
            "Generator loss: 0.0\n",
            "Running epoch 133 out of 1900\n",
            "Classifier loss: 0.062377285212278366\n",
            "Classifier loss: 2.037036418914795\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1237897276878357\n",
            "Classifier loss: 1.120062232017517\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10584238171577454\n",
            "Classifier loss: 0.09008913487195969\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1069275364279747\n",
            "Classifier loss: 0.5428370833396912\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06956962496042252\n",
            "Classifier loss: 1.120914101600647\n",
            "Generator loss: 1.3065764505881816e-06\n",
            "Classifier loss: 0.07594449818134308\n",
            "Classifier loss: 0.571049690246582\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.108954057097435\n",
            "Classifier loss: 1.0765608549118042\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.12167039513587952\n",
            "Classifier loss: 0.5883119702339172\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09306641668081284\n",
            "Classifier loss: 0.08600065112113953\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0934283584356308\n",
            "Classifier loss: 0.044016752392053604\n",
            "Generator loss: 3.848199048661627e-05\n",
            "Running epoch 134 out of 1900\n",
            "Classifier loss: 0.22510316967964172\n",
            "Classifier loss: 0.03366686403751373\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.28438764810562134\n",
            "Classifier loss: 0.037191472947597504\n",
            "Generator loss: 0.0841720923781395\n",
            "Classifier loss: 0.20237882435321808\n",
            "Classifier loss: 0.03585875779390335\n",
            "Generator loss: 0.09505786746740341\n",
            "Classifier loss: 0.4351350963115692\n",
            "Classifier loss: 0.03080487623810768\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2266804426908493\n",
            "Classifier loss: 0.029505116865038872\n",
            "Generator loss: 0.055947016924619675\n",
            "Classifier loss: 0.16707107424736023\n",
            "Classifier loss: 0.09135454893112183\n",
            "Generator loss: 0.05626576393842697\n",
            "Classifier loss: 0.18625129759311676\n",
            "Classifier loss: 0.03364987671375275\n",
            "Generator loss: 0.05766037851572037\n",
            "Classifier loss: 0.1332244873046875\n",
            "Classifier loss: 0.037610139697790146\n",
            "Generator loss: 0.00010382613982073963\n",
            "Classifier loss: 0.14426247775554657\n",
            "Classifier loss: 0.02994687482714653\n",
            "Generator loss: 0.012231184169650078\n",
            "Classifier loss: 0.1713051199913025\n",
            "Classifier loss: 0.07877212017774582\n",
            "Generator loss: 0.005326293408870697\n",
            "Running epoch 135 out of 1900\n",
            "Classifier loss: 0.21808989346027374\n",
            "Classifier loss: 2.032440662384033\n",
            "Generator loss: 2.071499329758808e-05\n",
            "Classifier loss: 0.18253295123577118\n",
            "Classifier loss: 0.6293907761573792\n",
            "Generator loss: 0.03372886776924133\n",
            "Classifier loss: 0.24963851273059845\n",
            "Classifier loss: 1.5532342195510864\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.15452584624290466\n",
            "Classifier loss: 0.5440651774406433\n",
            "Generator loss: 0.014649290591478348\n",
            "Classifier loss: 0.18249750137329102\n",
            "Classifier loss: 0.5720419883728027\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13472115993499756\n",
            "Classifier loss: 0.5443015098571777\n",
            "Generator loss: 0.06274406611919403\n",
            "Classifier loss: 0.13042549788951874\n",
            "Classifier loss: 0.5384169220924377\n",
            "Generator loss: 0.014874554239213467\n",
            "Classifier loss: 0.12748458981513977\n",
            "Classifier loss: 0.5408966541290283\n",
            "Generator loss: 0.028344040736556053\n",
            "Classifier loss: 0.12740635871887207\n",
            "Classifier loss: 0.5397526621818542\n",
            "Generator loss: 0.03268921375274658\n",
            "Classifier loss: 0.1334485560655594\n",
            "Classifier loss: 0.5673908591270447\n",
            "Generator loss: 0.0\n",
            "Running epoch 136 out of 1900\n",
            "Classifier loss: 0.16065402328968048\n",
            "Classifier loss: 0.5345258712768555\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.22315959632396698\n",
            "Classifier loss: 0.565263569355011\n",
            "Generator loss: 0.023326409980654716\n",
            "Classifier loss: 0.14356696605682373\n",
            "Classifier loss: 0.5487766265869141\n",
            "Generator loss: 0.03474094346165657\n",
            "Classifier loss: 0.15063995122909546\n",
            "Classifier loss: 0.04980532079935074\n",
            "Generator loss: 0.0025710889603942633\n",
            "Classifier loss: 0.22655139863491058\n",
            "Classifier loss: 0.03785388544201851\n",
            "Generator loss: 0.0059416526928544044\n",
            "Classifier loss: 0.11650987714529037\n",
            "Classifier loss: 0.58535236120224\n",
            "Generator loss: 0.009341382421553135\n",
            "Classifier loss: 0.09208577871322632\n",
            "Classifier loss: 0.05969574674963951\n",
            "Generator loss: 3.09944390153305e-08\n",
            "Classifier loss: 0.1275520622730255\n",
            "Classifier loss: 0.6257674098014832\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0830734446644783\n",
            "Classifier loss: 0.03791068121790886\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07636690884828568\n",
            "Classifier loss: 0.0614115409553051\n",
            "Generator loss: 0.011959043331444263\n",
            "Running epoch 137 out of 1900\n",
            "Classifier loss: 0.1336686611175537\n",
            "Classifier loss: 0.5404872894287109\n",
            "Generator loss: 0.020187780261039734\n",
            "Classifier loss: 0.07748518139123917\n",
            "Classifier loss: 0.03315221890807152\n",
            "Generator loss: 0.04382898658514023\n",
            "Classifier loss: 0.11923187226057053\n",
            "Classifier loss: 0.045311953872442245\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08373595029115677\n",
            "Classifier loss: 0.0895078256726265\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08269689232110977\n",
            "Classifier loss: 0.5427014231681824\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09617247432470322\n",
            "Classifier loss: 0.030924152582883835\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05510742962360382\n",
            "Classifier loss: 0.03745122253894806\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07009878754615784\n",
            "Classifier loss: 0.06375198811292648\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.03204705938696861\n",
            "Classifier loss: 0.6095679402351379\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.04725412279367447\n",
            "Classifier loss: 0.21443524956703186\n",
            "Generator loss: 0.03187151998281479\n",
            "Running epoch 138 out of 1900\n",
            "Classifier loss: 0.06306137144565582\n",
            "Classifier loss: 1.0485984086990356\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.15105371177196503\n",
            "Classifier loss: 1.052564024925232\n",
            "Generator loss: 0.0028295964002609253\n",
            "Classifier loss: 0.07213929295539856\n",
            "Classifier loss: 1.1929683685302734\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.07425987720489502\n",
            "Classifier loss: 0.6037041544914246\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.05762718245387077\n",
            "Classifier loss: 1.1618391275405884\n",
            "Generator loss: 0.025940362364053726\n",
            "Classifier loss: 0.06555953621864319\n",
            "Classifier loss: 0.550873875617981\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08814620971679688\n",
            "Classifier loss: 0.09013181179761887\n",
            "Generator loss: 0.012989926151931286\n",
            "Classifier loss: 0.16477760672569275\n",
            "Classifier loss: 1.0803866386413574\n",
            "Generator loss: 1.9050551145483041e-06\n",
            "Classifier loss: 0.07900504022836685\n",
            "Classifier loss: 1.0556656122207642\n",
            "Generator loss: 0.009507639333605766\n",
            "Classifier loss: 0.07473725825548172\n",
            "Classifier loss: 0.5622928738594055\n",
            "Generator loss: 0.017646169289946556\n",
            "Running epoch 139 out of 1900\n",
            "Classifier loss: 0.09002532809972763\n",
            "Classifier loss: 0.07763904333114624\n",
            "Generator loss: 0.05127789452672005\n",
            "Classifier loss: 0.08181626349687576\n",
            "Classifier loss: 0.549514651298523\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08100865036249161\n",
            "Classifier loss: 0.043112002313137054\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.08552230894565582\n",
            "Classifier loss: 0.5235190987586975\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.12166879326105118\n",
            "Classifier loss: 0.044226303696632385\n",
            "Generator loss: 0.014035948552191257\n",
            "Classifier loss: 0.09898269176483154\n",
            "Classifier loss: 0.02758120931684971\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09837554395198822\n",
            "Classifier loss: 0.05090000852942467\n",
            "Generator loss: 0.05787248536944389\n",
            "Classifier loss: 0.08091722428798676\n",
            "Classifier loss: 0.04440506175160408\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1294274926185608\n",
            "Classifier loss: 0.11195047199726105\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.12228816002607346\n",
            "Classifier loss: 0.032014455646276474\n",
            "Generator loss: 6.357249731081538e-06\n",
            "Running epoch 140 out of 1900\n",
            "Classifier loss: 0.16695372760295868\n",
            "Classifier loss: 0.06243235990405083\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.32996639609336853\n",
            "Classifier loss: 0.047949280589818954\n",
            "Generator loss: 4.2884180402325e-06\n",
            "Classifier loss: 0.20368899405002594\n",
            "Classifier loss: 0.5499940514564514\n",
            "Generator loss: 0.05806206911802292\n",
            "Classifier loss: 0.13768181204795837\n",
            "Classifier loss: 0.6044039130210876\n",
            "Generator loss: 0.05809362232685089\n",
            "Classifier loss: 0.14165808260440826\n",
            "Classifier loss: 0.7615408301353455\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0844293162226677\n",
            "Classifier loss: 0.05146195366978645\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.0910656750202179\n",
            "Classifier loss: 0.06449290364980698\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1203836053609848\n",
            "Classifier loss: 0.06484397500753403\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.13023369014263153\n",
            "Classifier loss: 0.05990326777100563\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.09320701658725739\n",
            "Classifier loss: 0.06542766839265823\n",
            "Generator loss: 0.05828307569026947\n",
            "Running epoch 141 out of 1900\n",
            "Classifier loss: 0.1570766270160675\n",
            "Classifier loss: 0.5285397171974182\n",
            "Generator loss: 4.529957919885419e-08\n",
            "Classifier loss: 0.2458595484495163\n",
            "Classifier loss: 0.03533341735601425\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.10580834746360779\n",
            "Classifier loss: 0.5951016545295715\n",
            "Generator loss: 1.263658305106219e-06\n",
            "Classifier loss: 0.15225781500339508\n",
            "Classifier loss: 0.03222871571779251\n",
            "Generator loss: 0.00010987845598720014\n",
            "Classifier loss: 0.3449694812297821\n",
            "Classifier loss: 0.5397931337356567\n",
            "Generator loss: 0.06997397541999817\n",
            "Classifier loss: 0.09689625352621078\n",
            "Classifier loss: 0.038066308945417404\n",
            "Generator loss: 0.024123894050717354\n",
            "Classifier loss: 0.06582043319940567\n",
            "Classifier loss: 0.1511097252368927\n",
            "Generator loss: 0.018502818420529366\n",
            "Classifier loss: 0.07095310837030411\n",
            "Classifier loss: 0.03362962603569031\n",
            "Generator loss: 0.08164890110492706\n",
            "Classifier loss: 0.059281494468450546\n",
            "Classifier loss: 0.039617717266082764\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.06223160773515701\n",
            "Classifier loss: 0.11375848203897476\n",
            "Generator loss: 0.0\n",
            "Running epoch 142 out of 1900\n",
            "Classifier loss: 0.2113548368215561\n",
            "Classifier loss: 0.0633472129702568\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.16009366512298584\n",
            "Classifier loss: 0.034847553819417953\n",
            "Generator loss: 0.05866137892007828\n",
            "Classifier loss: 0.15378378331661224\n",
            "Classifier loss: 1.1361733675003052\n",
            "Generator loss: 0.04252809286117554\n",
            "Classifier loss: 0.3876660168170929\n",
            "Classifier loss: 0.04261217638850212\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1438928097486496\n",
            "Classifier loss: 1.0294442176818848\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19483745098114014\n",
            "Classifier loss: 1.0329551696777344\n",
            "Generator loss: 0.00433791009709239\n",
            "Classifier loss: 0.2581647038459778\n",
            "Classifier loss: 1.027366042137146\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.38738980889320374\n",
            "Classifier loss: 0.5800684690475464\n",
            "Generator loss: 3.09944390153305e-08\n",
            "Classifier loss: 0.16339828073978424\n",
            "Classifier loss: 1.0688440799713135\n",
            "Generator loss: 0.0701388418674469\n",
            "Classifier loss: 0.15696139633655548\n",
            "Classifier loss: 1.0909796953201294\n",
            "Generator loss: 0.0\n",
            "Running epoch 143 out of 1900\n",
            "Classifier loss: 0.16735954582691193\n",
            "Classifier loss: 2.025730848312378\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11528045684099197\n",
            "Classifier loss: 2.5292141437530518\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.140077143907547\n",
            "Classifier loss: 2.068211793899536\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.17595060169696808\n",
            "Classifier loss: 2.0896053314208984\n",
            "Generator loss: 0.041537895798683167\n",
            "Classifier loss: 0.1028246283531189\n",
            "Classifier loss: 3.068882465362549\n",
            "Generator loss: 0.020850863307714462\n",
            "Classifier loss: 0.28664374351501465\n",
            "Classifier loss: 1.5487014055252075\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.11854331940412521\n",
            "Classifier loss: 2.61310076713562\n",
            "Generator loss: 9.536745615434938e-09\n",
            "Classifier loss: 0.13592040538787842\n",
            "Classifier loss: 3.581428050994873\n",
            "Generator loss: 0.02559599280357361\n",
            "Classifier loss: 0.2913369834423065\n",
            "Classifier loss: 2.1481103897094727\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1659741997718811\n",
            "Classifier loss: 2.029834747314453\n",
            "Generator loss: 0.059221986681222916\n",
            "Running epoch 144 out of 1900\n",
            "Classifier loss: 0.7526444792747498\n",
            "Classifier loss: 0.060125332325696945\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.710516631603241\n",
            "Classifier loss: 0.03564111515879631\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3396429419517517\n",
            "Classifier loss: 0.5722701549530029\n",
            "Generator loss: 2.303255996594089e-06\n",
            "Classifier loss: 0.5156489014625549\n",
            "Classifier loss: 0.02983715757727623\n",
            "Generator loss: 0.08536384254693985\n",
            "Classifier loss: 0.6254350543022156\n",
            "Classifier loss: 0.03332943469285965\n",
            "Generator loss: 0.08693771809339523\n",
            "Classifier loss: 0.7041225433349609\n",
            "Classifier loss: 0.5877207517623901\n",
            "Generator loss: 0.001985980197787285\n",
            "Classifier loss: 0.982885479927063\n",
            "Classifier loss: 0.08010520786046982\n",
            "Generator loss: 0.013591282069683075\n",
            "Classifier loss: 0.7575030326843262\n",
            "Classifier loss: 0.05500501021742821\n",
            "Generator loss: 0.0005735017475672066\n",
            "Classifier loss: 0.6327322125434875\n",
            "Classifier loss: 0.03540267050266266\n",
            "Generator loss: 0.06052596867084503\n",
            "Classifier loss: 0.302114874124527\n",
            "Classifier loss: 0.043321073055267334\n",
            "Generator loss: 0.0\n",
            "Running epoch 145 out of 1900\n",
            "Classifier loss: 0.2188996970653534\n",
            "Classifier loss: 0.1864163726568222\n",
            "Generator loss: 0.002908579306676984\n",
            "Classifier loss: 0.21273162961006165\n",
            "Classifier loss: 1.0437140464782715\n",
            "Generator loss: 0.09130559116601944\n",
            "Classifier loss: 0.2354326695203781\n",
            "Classifier loss: 0.050886791199445724\n",
            "Generator loss: 4.076999005064863e-07\n",
            "Classifier loss: 0.24139918386936188\n",
            "Classifier loss: 0.6214532256126404\n",
            "Generator loss: 0.05964658036828041\n",
            "Classifier loss: 0.22207409143447876\n",
            "Classifier loss: 0.5341939926147461\n",
            "Generator loss: 2.155153197236359e-05\n",
            "Classifier loss: 0.23002414405345917\n",
            "Classifier loss: 0.6290533542633057\n",
            "Generator loss: 0.0006761322729289532\n",
            "Classifier loss: 0.2621091902256012\n",
            "Classifier loss: 0.5622933506965637\n",
            "Generator loss: 0.008606878109276295\n",
            "Classifier loss: 0.2517772912979126\n",
            "Classifier loss: 0.10610847920179367\n",
            "Generator loss: 0.00010899385961238295\n",
            "Classifier loss: 0.21301019191741943\n",
            "Classifier loss: 0.037008121609687805\n",
            "Generator loss: 0.059796418994665146\n",
            "Classifier loss: 0.23218531906604767\n",
            "Classifier loss: 0.564388632774353\n",
            "Generator loss: 0.001513569732196629\n",
            "Running epoch 146 out of 1900\n",
            "Classifier loss: 0.15108056366443634\n",
            "Classifier loss: 0.5575194954872131\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1749502569437027\n",
            "Classifier loss: 1.0870285034179688\n",
            "Generator loss: 0.09108639508485794\n",
            "Classifier loss: 0.20133423805236816\n",
            "Classifier loss: 1.0612515211105347\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19562315940856934\n",
            "Classifier loss: 1.0626258850097656\n",
            "Generator loss: 0.01758314110338688\n",
            "Classifier loss: 0.19722777605056763\n",
            "Classifier loss: 1.0757588148117065\n",
            "Generator loss: 0.009345405735075474\n",
            "Classifier loss: 0.15796887874603271\n",
            "Classifier loss: 1.1182606220245361\n",
            "Generator loss: 0.04767651855945587\n",
            "Classifier loss: 0.15325434505939484\n",
            "Classifier loss: 1.1119691133499146\n",
            "Generator loss: 0.004308980889618397\n",
            "Classifier loss: 0.188608318567276\n",
            "Classifier loss: 1.1423226594924927\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19777065515518188\n",
            "Classifier loss: 1.5737987756729126\n",
            "Generator loss: 0.0014887917786836624\n",
            "Classifier loss: 0.20979167520999908\n",
            "Classifier loss: 2.1248953342437744\n",
            "Generator loss: 0.035457905381917953\n",
            "Running epoch 147 out of 1900\n",
            "Classifier loss: 0.7093037962913513\n",
            "Classifier loss: 4.1778717041015625\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.34191974997520447\n",
            "Classifier loss: 5.103725910186768\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.31660473346710205\n",
            "Classifier loss: 4.590928554534912\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3653188645839691\n",
            "Classifier loss: 4.1386260986328125\n",
            "Generator loss: 0.0016252071363851428\n",
            "Classifier loss: 0.34153151512145996\n",
            "Classifier loss: 3.7257442474365234\n",
            "Generator loss: 0.00221696007065475\n",
            "Classifier loss: 0.36113402247428894\n",
            "Classifier loss: 4.6174702644348145\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.7016909718513489\n",
            "Classifier loss: 5.191586971282959\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4675147831439972\n",
            "Classifier loss: 3.5593109130859375\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5643009543418884\n",
            "Classifier loss: 3.155251979827881\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3250299096107483\n",
            "Classifier loss: 3.060927152633667\n",
            "Generator loss: 0.0\n",
            "Running epoch 148 out of 1900\n",
            "Classifier loss: 0.31819334626197815\n",
            "Classifier loss: 2.691239833831787\n",
            "Generator loss: 0.002035728422924876\n",
            "Classifier loss: 0.46412497758865356\n",
            "Classifier loss: 4.077422618865967\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3344033360481262\n",
            "Classifier loss: 3.121140718460083\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.31764575839042664\n",
            "Classifier loss: 2.581488847732544\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.35654416680336\n",
            "Classifier loss: 3.142925977706909\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.429512083530426\n",
            "Classifier loss: 3.55326771736145\n",
            "Generator loss: 0.00648802425712347\n",
            "Classifier loss: 0.3215341866016388\n",
            "Classifier loss: 4.562889575958252\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.41356727480888367\n",
            "Classifier loss: 2.547880172729492\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3134964406490326\n",
            "Classifier loss: 3.08988881111145\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33269527554512024\n",
            "Classifier loss: 3.1317973136901855\n",
            "Generator loss: 0.0\n",
            "Running epoch 149 out of 1900\n",
            "Classifier loss: 0.4110735356807709\n",
            "Classifier loss: 4.780242919921875\n",
            "Generator loss: 0.1271640807390213\n",
            "Classifier loss: 1.1090373992919922\n",
            "Classifier loss: 5.673423767089844\n",
            "Generator loss: 0.07279911637306213\n",
            "Classifier loss: 0.4759694039821625\n",
            "Classifier loss: 4.064116477966309\n",
            "Generator loss: 0.0063498858362436295\n",
            "Classifier loss: 0.901304304599762\n",
            "Classifier loss: 4.119094371795654\n",
            "Generator loss: 0.06090943142771721\n",
            "Classifier loss: 0.5645818114280701\n",
            "Classifier loss: 3.6798338890075684\n",
            "Generator loss: 0.049078233540058136\n",
            "Classifier loss: 0.48521512746810913\n",
            "Classifier loss: 3.1472222805023193\n",
            "Generator loss: 0.060831017792224884\n",
            "Classifier loss: 0.7430886626243591\n",
            "Classifier loss: 2.5872106552124023\n",
            "Generator loss: 0.12728562951087952\n",
            "Classifier loss: 0.32910972833633423\n",
            "Classifier loss: 3.140134811401367\n",
            "Generator loss: 0.06521148979663849\n",
            "Classifier loss: 0.33555954694747925\n",
            "Classifier loss: 3.076268434524536\n",
            "Generator loss: 0.05235450714826584\n",
            "Classifier loss: 0.3116677701473236\n",
            "Classifier loss: 3.694469451904297\n",
            "Generator loss: 0.06093300133943558\n",
            "Running epoch 150 out of 1900\n",
            "Classifier loss: 0.22400176525115967\n",
            "Classifier loss: 0.6632860898971558\n",
            "Generator loss: 0.06095823273062706\n",
            "Classifier loss: 0.2367621213197708\n",
            "Classifier loss: 2.1036412715911865\n",
            "Generator loss: 0.06504994630813599\n",
            "Classifier loss: 0.21607130765914917\n",
            "Classifier loss: 1.6963776350021362\n",
            "Generator loss: 0.052048053592443466\n",
            "Classifier loss: 0.21190738677978516\n",
            "Classifier loss: 0.685960054397583\n",
            "Generator loss: 0.09421570599079132\n",
            "Classifier loss: 0.2195003479719162\n",
            "Classifier loss: 0.11410465091466904\n",
            "Generator loss: 0.061058785766363144\n",
            "Classifier loss: 0.19004836678504944\n",
            "Classifier loss: 1.65962815284729\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.21306514739990234\n",
            "Classifier loss: 1.072699785232544\n",
            "Generator loss: 0.061108872294425964\n",
            "Classifier loss: 0.17733502388000488\n",
            "Classifier loss: 1.1042929887771606\n",
            "Generator loss: 0.061133887618780136\n",
            "Classifier loss: 0.2333621233701706\n",
            "Classifier loss: 1.5543535947799683\n",
            "Generator loss: 0.06115886941552162\n",
            "Classifier loss: 0.21648913621902466\n",
            "Classifier loss: 0.7449712157249451\n",
            "Generator loss: 0.08293750882148743\n",
            "Running epoch 151 out of 1900\n",
            "Classifier loss: 0.7632148861885071\n",
            "Classifier loss: 1.5897396802902222\n",
            "Generator loss: 4.686666216002777e-06\n",
            "Classifier loss: 0.4243833124637604\n",
            "Classifier loss: 3.073665142059326\n",
            "Generator loss: 0.09378066658973694\n",
            "Classifier loss: 0.3717343807220459\n",
            "Classifier loss: 1.0602819919586182\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.31186431646347046\n",
            "Classifier loss: 1.5588412284851074\n",
            "Generator loss: 0.061282139271497726\n",
            "Classifier loss: 0.3635725975036621\n",
            "Classifier loss: 2.551409959793091\n",
            "Generator loss: 0.06924964487552643\n",
            "Classifier loss: 0.47767606377601624\n",
            "Classifier loss: 2.5519258975982666\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2941804528236389\n",
            "Classifier loss: 2.081798553466797\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.25815391540527344\n",
            "Classifier loss: 1.5686746835708618\n",
            "Generator loss: 0.710541844367981\n",
            "Classifier loss: 0.33344054222106934\n",
            "Classifier loss: 2.083193063735962\n",
            "Generator loss: 0.003610990010201931\n",
            "Classifier loss: 0.2835606634616852\n",
            "Classifier loss: 2.568251371383667\n",
            "Generator loss: 0.013864177279174328\n",
            "Running epoch 152 out of 1900\n",
            "Classifier loss: 0.2792623043060303\n",
            "Classifier loss: 2.815772533416748\n",
            "Generator loss: 0.0016591208986938\n",
            "Classifier loss: 0.26563143730163574\n",
            "Classifier loss: 2.6363298892974854\n",
            "Generator loss: 0.07026088237762451\n",
            "Classifier loss: 0.2608824074268341\n",
            "Classifier loss: 3.6328887939453125\n",
            "Generator loss: 0.3005881905555725\n",
            "Classifier loss: 0.30119845271110535\n",
            "Classifier loss: 2.1531755924224854\n",
            "Generator loss: 0.05440477654337883\n",
            "Classifier loss: 0.2539011240005493\n",
            "Classifier loss: 3.1657423973083496\n",
            "Generator loss: 3.853940143017098e-05\n",
            "Classifier loss: 0.264462947845459\n",
            "Classifier loss: 2.1247639656066895\n",
            "Generator loss: 0.0011349685955792665\n",
            "Classifier loss: 0.33277446031570435\n",
            "Classifier loss: 2.0847678184509277\n",
            "Generator loss: 0.08423910290002823\n",
            "Classifier loss: 0.2688271105289459\n",
            "Classifier loss: 1.6327201128005981\n",
            "Generator loss: 0.020409567281603813\n",
            "Classifier loss: 0.25800979137420654\n",
            "Classifier loss: 2.6149017810821533\n",
            "Generator loss: 0.09176584333181381\n",
            "Classifier loss: 0.32032135128974915\n",
            "Classifier loss: 1.5986099243164062\n",
            "Generator loss: 0.09318388998508453\n",
            "Running epoch 153 out of 1900\n",
            "Classifier loss: 0.49975916743278503\n",
            "Classifier loss: 1.6796362400054932\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.35137930512428284\n",
            "Classifier loss: 1.1376065015792847\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4809519052505493\n",
            "Classifier loss: 2.0965263843536377\n",
            "Generator loss: 2.8415828637662344e-05\n",
            "Classifier loss: 0.3738787770271301\n",
            "Classifier loss: 1.0828323364257812\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5204923152923584\n",
            "Classifier loss: 1.1328729391098022\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5201246738433838\n",
            "Classifier loss: 2.206693172454834\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4487467110157013\n",
            "Classifier loss: 1.597161889076233\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7018870115280151\n",
            "Classifier loss: 0.6661946773529053\n",
            "Generator loss: 0.001790805021300912\n",
            "Classifier loss: 0.4563884735107422\n",
            "Classifier loss: 1.0685745477676392\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4780932366847992\n",
            "Classifier loss: 1.5878695249557495\n",
            "Generator loss: 0.0\n",
            "Running epoch 154 out of 1900\n",
            "Classifier loss: 0.29597577452659607\n",
            "Classifier loss: 0.6090059280395508\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3485804796218872\n",
            "Classifier loss: 0.6568102240562439\n",
            "Generator loss: 0.00015120417810976505\n",
            "Classifier loss: 0.30850163102149963\n",
            "Classifier loss: 1.5707244873046875\n",
            "Generator loss: 2.4653750188008416e-06\n",
            "Classifier loss: 0.27434203028678894\n",
            "Classifier loss: 1.6348012685775757\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3468307852745056\n",
            "Classifier loss: 1.614863395690918\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.30868011713027954\n",
            "Classifier loss: 1.1592848300933838\n",
            "Generator loss: 0.062219373881816864\n",
            "Classifier loss: 0.37171420454978943\n",
            "Classifier loss: 0.7759189605712891\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3357211947441101\n",
            "Classifier loss: 1.0984221696853638\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2923191487789154\n",
            "Classifier loss: 0.5760267972946167\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2642471492290497\n",
            "Classifier loss: 1.0942333936691284\n",
            "Generator loss: 0.0\n",
            "Running epoch 155 out of 1900\n",
            "Classifier loss: 0.37332260608673096\n",
            "Classifier loss: 3.63340163230896\n",
            "Generator loss: 0.047673217952251434\n",
            "Classifier loss: 0.631711483001709\n",
            "Classifier loss: 3.567147970199585\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3667391836643219\n",
            "Classifier loss: 3.0682640075683594\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6070371270179749\n",
            "Classifier loss: 2.5694048404693604\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.35527303814888\n",
            "Classifier loss: 2.6006033420562744\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2980365753173828\n",
            "Classifier loss: 2.6258764266967773\n",
            "Generator loss: 0.016094615682959557\n",
            "Classifier loss: 0.4291400909423828\n",
            "Classifier loss: 4.07763671875\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.39224833250045776\n",
            "Classifier loss: 3.6519687175750732\n",
            "Generator loss: 0.0013786682393401861\n",
            "Classifier loss: 0.3878342807292938\n",
            "Classifier loss: 3.0864202976226807\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.32634270191192627\n",
            "Classifier loss: 4.0977301597595215\n",
            "Generator loss: 0.0\n",
            "Running epoch 156 out of 1900\n",
            "Classifier loss: 0.2070484310388565\n",
            "Classifier loss: 3.093975782394409\n",
            "Generator loss: 0.1954021006822586\n",
            "Classifier loss: 0.2588929235935211\n",
            "Classifier loss: 2.6031737327575684\n",
            "Generator loss: 0.23007403314113617\n",
            "Classifier loss: 0.24913735687732697\n",
            "Classifier loss: 3.072333335876465\n",
            "Generator loss: 0.21882179379463196\n",
            "Classifier loss: 0.2608738839626312\n",
            "Classifier loss: 3.622715473175049\n",
            "Generator loss: 0.11127384752035141\n",
            "Classifier loss: 0.20680081844329834\n",
            "Classifier loss: 2.6200170516967773\n",
            "Generator loss: 0.06241099163889885\n",
            "Classifier loss: 0.23825137317180634\n",
            "Classifier loss: 3.101154088973999\n",
            "Generator loss: 0.16658233106136322\n",
            "Classifier loss: 0.22633033990859985\n",
            "Classifier loss: 2.5771191120147705\n",
            "Generator loss: 0.06268493831157684\n",
            "Classifier loss: 0.24928882718086243\n",
            "Classifier loss: 2.6220881938934326\n",
            "Generator loss: 0.07440416514873505\n",
            "Classifier loss: 0.21427933871746063\n",
            "Classifier loss: 2.59503173828125\n",
            "Generator loss: 0.09895215928554535\n",
            "Classifier loss: 0.3018275797367096\n",
            "Classifier loss: 2.0760200023651123\n",
            "Generator loss: 0.04161049798130989\n",
            "Running epoch 157 out of 1900\n",
            "Classifier loss: 0.4633164405822754\n",
            "Classifier loss: 2.5948081016540527\n",
            "Generator loss: 0.18752485513687134\n",
            "Classifier loss: 0.3343803286552429\n",
            "Classifier loss: 1.571437954902649\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5676612854003906\n",
            "Classifier loss: 2.5616602897644043\n",
            "Generator loss: 2.619908809720073e-05\n",
            "Classifier loss: 0.26952266693115234\n",
            "Classifier loss: 2.5737144947052\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2643013298511505\n",
            "Classifier loss: 2.563534736633301\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.24371279776096344\n",
            "Classifier loss: 1.6722549200057983\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2162027359008789\n",
            "Classifier loss: 2.094114065170288\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4094657897949219\n",
            "Classifier loss: 2.4016945362091064\n",
            "Generator loss: 0.04503927752375603\n",
            "Classifier loss: 0.20485714077949524\n",
            "Classifier loss: 1.5629793405532837\n",
            "Generator loss: 0.13556712865829468\n",
            "Classifier loss: 0.2755206823348999\n",
            "Classifier loss: 2.0650525093078613\n",
            "Generator loss: 0.0\n",
            "Running epoch 158 out of 1900\n",
            "Classifier loss: 0.7948626279830933\n",
            "Classifier loss: 2.6280770301818848\n",
            "Generator loss: 0.12544716894626617\n",
            "Classifier loss: 0.8315569162368774\n",
            "Classifier loss: 2.5626869201660156\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3120309114456177\n",
            "Classifier loss: 2.5729851722717285\n",
            "Generator loss: 0.14474093914031982\n",
            "Classifier loss: 0.3446974754333496\n",
            "Classifier loss: 3.06087064743042\n",
            "Generator loss: 0.06278013437986374\n",
            "Classifier loss: 0.8399171233177185\n",
            "Classifier loss: 2.5924131870269775\n",
            "Generator loss: 0.035052597522735596\n",
            "Classifier loss: 0.39862510561943054\n",
            "Classifier loss: 2.6221532821655273\n",
            "Generator loss: 0.22593148052692413\n",
            "Classifier loss: 0.35100847482681274\n",
            "Classifier loss: 2.0737812519073486\n",
            "Generator loss: 0.06185155734419823\n",
            "Classifier loss: 1.303621530532837\n",
            "Classifier loss: 2.6495141983032227\n",
            "Generator loss: 0.08748611062765121\n",
            "Classifier loss: 0.6245225667953491\n",
            "Classifier loss: 2.591508150100708\n",
            "Generator loss: 0.0018864356679841876\n",
            "Classifier loss: 0.8763662576675415\n",
            "Classifier loss: 2.5709266662597656\n",
            "Generator loss: 0.06288905441761017\n",
            "Running epoch 159 out of 1900\n",
            "Classifier loss: 0.5977773070335388\n",
            "Classifier loss: 1.0910189151763916\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.7933875322341919\n",
            "Classifier loss: 0.5897743701934814\n",
            "Generator loss: 0.04580732062458992\n",
            "Classifier loss: 0.26370394229888916\n",
            "Classifier loss: 1.096119999885559\n",
            "Generator loss: 0.00020456264610402286\n",
            "Classifier loss: 0.5060408711433411\n",
            "Classifier loss: 0.6293809413909912\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.41037115454673767\n",
            "Classifier loss: 0.6689504981040955\n",
            "Generator loss: 0.06297697126865387\n",
            "Classifier loss: 0.25850561261177063\n",
            "Classifier loss: 0.7010098099708557\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2785671651363373\n",
            "Classifier loss: 1.1210942268371582\n",
            "Generator loss: 0.12627358734607697\n",
            "Classifier loss: 0.23565736413002014\n",
            "Classifier loss: 1.101754903793335\n",
            "Generator loss: 0.06302911788225174\n",
            "Classifier loss: 0.2630399763584137\n",
            "Classifier loss: 0.5769410133361816\n",
            "Generator loss: 0.00024890771601349115\n",
            "Classifier loss: 0.23829473555088043\n",
            "Classifier loss: 0.5656366348266602\n",
            "Generator loss: 0.0\n",
            "Running epoch 160 out of 1900\n",
            "Classifier loss: 0.3385261595249176\n",
            "Classifier loss: 0.5748568773269653\n",
            "Generator loss: 0.00043402082519605756\n",
            "Classifier loss: 0.380093514919281\n",
            "Classifier loss: 0.5744727253913879\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.27561014890670776\n",
            "Classifier loss: 0.5661652088165283\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.43710485100746155\n",
            "Classifier loss: 1.0680917501449585\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.29007160663604736\n",
            "Classifier loss: 0.569874107837677\n",
            "Generator loss: 9.531861905998085e-06\n",
            "Classifier loss: 0.27675020694732666\n",
            "Classifier loss: 1.072528600692749\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33773764967918396\n",
            "Classifier loss: 0.5808162689208984\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33133572340011597\n",
            "Classifier loss: 0.5694193840026855\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2814691960811615\n",
            "Classifier loss: 0.5710598826408386\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8150448203086853\n",
            "Classifier loss: 0.5654630661010742\n",
            "Generator loss: 0.0\n",
            "Running epoch 161 out of 1900\n",
            "Classifier loss: 0.4515824019908905\n",
            "Classifier loss: 3.6121349334716797\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7151349186897278\n",
            "Classifier loss: 3.574451446533203\n",
            "Generator loss: 0.013017121702432632\n",
            "Classifier loss: 0.824151337146759\n",
            "Classifier loss: 3.0929372310638428\n",
            "Generator loss: 0.0024128518998622894\n",
            "Classifier loss: 0.8782793879508972\n",
            "Classifier loss: 3.143256425857544\n",
            "Generator loss: 0.0027297898195683956\n",
            "Classifier loss: 0.8143494725227356\n",
            "Classifier loss: 3.581028461456299\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.31445297598838806\n",
            "Classifier loss: 3.662193536758423\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.30656129121780396\n",
            "Classifier loss: 3.5789241790771484\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7917592525482178\n",
            "Classifier loss: 4.06262731552124\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7903831601142883\n",
            "Classifier loss: 4.131716728210449\n",
            "Generator loss: 0.0002510466438252479\n",
            "Classifier loss: 0.2940915822982788\n",
            "Classifier loss: 4.100419998168945\n",
            "Generator loss: 0.0\n",
            "Running epoch 162 out of 1900\n",
            "Classifier loss: 0.818923830986023\n",
            "Classifier loss: 3.081254720687866\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8908206820487976\n",
            "Classifier loss: 2.6252434253692627\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.36917686462402344\n",
            "Classifier loss: 2.6020500659942627\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5218841433525085\n",
            "Classifier loss: 2.5920193195343018\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2946220338344574\n",
            "Classifier loss: 2.5778186321258545\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.34987249970436096\n",
            "Classifier loss: 2.569164276123047\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.32766619324684143\n",
            "Classifier loss: 2.570272445678711\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.37101808190345764\n",
            "Classifier loss: 2.5767924785614014\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33908551931381226\n",
            "Classifier loss: 3.146266460418701\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.29233255982398987\n",
            "Classifier loss: 2.58203387260437\n",
            "Generator loss: 0.0\n",
            "Running epoch 163 out of 1900\n",
            "Classifier loss: 0.27184534072875977\n",
            "Classifier loss: 2.0639936923980713\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3036300539970398\n",
            "Classifier loss: 1.630452275276184\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2533881962299347\n",
            "Classifier loss: 1.648081660270691\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.23868003487586975\n",
            "Classifier loss: 2.0653486251831055\n",
            "Generator loss: 9.536745615434938e-09\n",
            "Classifier loss: 0.25566762685775757\n",
            "Classifier loss: 1.1128555536270142\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.24408523738384247\n",
            "Classifier loss: 1.5699752569198608\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.20531147718429565\n",
            "Classifier loss: 1.615183711051941\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.48050281405448914\n",
            "Classifier loss: 1.06419038772583\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.25375834107398987\n",
            "Classifier loss: 1.5622445344924927\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2629522979259491\n",
            "Classifier loss: 1.5673530101776123\n",
            "Generator loss: 0.0\n",
            "Running epoch 164 out of 1900\n",
            "Classifier loss: 0.35645681619644165\n",
            "Classifier loss: 3.0662481784820557\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33575600385665894\n",
            "Classifier loss: 3.562058925628662\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8022535443305969\n",
            "Classifier loss: 3.5616040229797363\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3184729814529419\n",
            "Classifier loss: 3.5653929710388184\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3235829174518585\n",
            "Classifier loss: 4.135551452636719\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.34907230734825134\n",
            "Classifier loss: 3.56015944480896\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.305767685174942\n",
            "Classifier loss: 3.5600459575653076\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.32865309715270996\n",
            "Classifier loss: 3.5763652324676514\n",
            "Generator loss: 0.14879785478115082\n",
            "Classifier loss: 0.31525367498397827\n",
            "Classifier loss: 3.5638647079467773\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.278984397649765\n",
            "Classifier loss: 3.6027190685272217\n",
            "Generator loss: 0.0\n",
            "Running epoch 165 out of 1900\n",
            "Classifier loss: 0.19296248257160187\n",
            "Classifier loss: 1.1040936708450317\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.255372017621994\n",
            "Classifier loss: 0.10236506164073944\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.23312653601169586\n",
            "Classifier loss: 0.1451610028743744\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19043195247650146\n",
            "Classifier loss: 0.0957873985171318\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.20619890093803406\n",
            "Classifier loss: 0.1310986429452896\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.1795610785484314\n",
            "Classifier loss: 0.5688983201980591\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.24184173345565796\n",
            "Classifier loss: 0.0689106434583664\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.20646029710769653\n",
            "Classifier loss: 1.087826132774353\n",
            "Generator loss: 0.06393701583147049\n",
            "Classifier loss: 0.22350803017616272\n",
            "Classifier loss: 0.06828675419092178\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.22913758456707\n",
            "Classifier loss: 0.0627477839589119\n",
            "Generator loss: 0.0\n",
            "Running epoch 166 out of 1900\n",
            "Classifier loss: 0.25344541668891907\n",
            "Classifier loss: 2.0643460750579834\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.27098238468170166\n",
            "Classifier loss: 1.0665332078933716\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2556860148906708\n",
            "Classifier loss: 1.570413589477539\n",
            "Generator loss: 0.37572282552719116\n",
            "Classifier loss: 0.31652769446372986\n",
            "Classifier loss: 1.0665740966796875\n",
            "Generator loss: 0.03891803324222565\n",
            "Classifier loss: 0.2912035286426544\n",
            "Classifier loss: 1.0725866556167603\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.30737489461898804\n",
            "Classifier loss: 1.0675595998764038\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3174624443054199\n",
            "Classifier loss: 1.5817241668701172\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2753152847290039\n",
            "Classifier loss: 1.0901108980178833\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.29354429244995117\n",
            "Classifier loss: 1.163543462753296\n",
            "Generator loss: 0.002071716357022524\n",
            "Classifier loss: 0.2863403558731079\n",
            "Classifier loss: 1.1482794284820557\n",
            "Generator loss: 0.00017396430484950542\n",
            "Running epoch 167 out of 1900\n",
            "Classifier loss: 0.33596739172935486\n",
            "Classifier loss: 2.0606536865234375\n",
            "Generator loss: 2.6226061322631722e-08\n",
            "Classifier loss: 0.3456646800041199\n",
            "Classifier loss: 2.060084819793701\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3446843922138214\n",
            "Classifier loss: 1.58975088596344\n",
            "Generator loss: 0.06413272023200989\n",
            "Classifier loss: 0.41120925545692444\n",
            "Classifier loss: 2.079782009124756\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.41565558314323425\n",
            "Classifier loss: 2.0730559825897217\n",
            "Generator loss: 0.00093522306997329\n",
            "Classifier loss: 0.3249862492084503\n",
            "Classifier loss: 2.0647125244140625\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.35973089933395386\n",
            "Classifier loss: 2.0737173557281494\n",
            "Generator loss: 1.7016018318827264e-05\n",
            "Classifier loss: 0.3718035817146301\n",
            "Classifier loss: 2.0712661743164062\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.308347225189209\n",
            "Classifier loss: 2.078685760498047\n",
            "Generator loss: 0.13057580590248108\n",
            "Classifier loss: 0.31010621786117554\n",
            "Classifier loss: 2.132463216781616\n",
            "Generator loss: 0.0\n",
            "Running epoch 168 out of 1900\n",
            "Classifier loss: 0.3196995258331299\n",
            "Classifier loss: 2.619450092315674\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33329159021377563\n",
            "Classifier loss: 2.0793683528900146\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3958955705165863\n",
            "Classifier loss: 3.078528642654419\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.38412776589393616\n",
            "Classifier loss: 2.106842279434204\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3327051103115082\n",
            "Classifier loss: 2.581489086151123\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4028836488723755\n",
            "Classifier loss: 2.129617929458618\n",
            "Generator loss: 0.0007103737443685532\n",
            "Classifier loss: 0.37463802099227905\n",
            "Classifier loss: 1.598931908607483\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33085188269615173\n",
            "Classifier loss: 2.083777904510498\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.36721381545066833\n",
            "Classifier loss: 2.590000867843628\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.37531477212905884\n",
            "Classifier loss: 2.1111998558044434\n",
            "Generator loss: 0.0\n",
            "Running epoch 169 out of 1900\n",
            "Classifier loss: 0.34147223830223083\n",
            "Classifier loss: 3.5790657997131348\n",
            "Generator loss: 0.12866921722888947\n",
            "Classifier loss: 0.3088565468788147\n",
            "Classifier loss: 3.129099130630493\n",
            "Generator loss: 0.1258106529712677\n",
            "Classifier loss: 0.44589003920555115\n",
            "Classifier loss: 3.5806472301483154\n",
            "Generator loss: 0.06435506045818329\n",
            "Classifier loss: 0.2750299274921417\n",
            "Classifier loss: 4.105519771575928\n",
            "Generator loss: 0.06436508148908615\n",
            "Classifier loss: 0.3495497405529022\n",
            "Classifier loss: 3.610250234603882\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.305038720369339\n",
            "Classifier loss: 3.6221728324890137\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5198146104812622\n",
            "Classifier loss: 3.07165789604187\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2944132387638092\n",
            "Classifier loss: 3.1619133949279785\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2629011571407318\n",
            "Classifier loss: 3.622342824935913\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.27663227915763855\n",
            "Classifier loss: 4.145634174346924\n",
            "Generator loss: 0.06452575325965881\n",
            "Running epoch 170 out of 1900\n",
            "Classifier loss: 0.806280791759491\n",
            "Classifier loss: 2.586993932723999\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.32535994052886963\n",
            "Classifier loss: 2.5639760494232178\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3447478413581848\n",
            "Classifier loss: 2.604243755340576\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.3756980299949646\n",
            "Classifier loss: 3.067460775375366\n",
            "Generator loss: 0.0644615963101387\n",
            "Classifier loss: 0.4799365997314453\n",
            "Classifier loss: 3.094487190246582\n",
            "Generator loss: 3.734257916221395e-05\n",
            "Classifier loss: 0.26014479994773865\n",
            "Classifier loss: 4.214441776275635\n",
            "Generator loss: 0.00011127015022793785\n",
            "Classifier loss: 0.2613641917705536\n",
            "Classifier loss: 4.662062168121338\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.27172091603279114\n",
            "Classifier loss: 4.072037220001221\n",
            "Generator loss: 0.06449846923351288\n",
            "Classifier loss: 0.26619526743888855\n",
            "Classifier loss: 4.092806339263916\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.23534885048866272\n",
            "Classifier loss: 5.098649978637695\n",
            "Generator loss: 0.12913787364959717\n",
            "Running epoch 171 out of 1900\n",
            "Classifier loss: 0.24716819822788239\n",
            "Classifier loss: 6.130364894866943\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19730645418167114\n",
            "Classifier loss: 4.1333441734313965\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.18148288130760193\n",
            "Classifier loss: 5.561614990234375\n",
            "Generator loss: 0.004347406327724457\n",
            "Classifier loss: 0.1954376995563507\n",
            "Classifier loss: 4.687932014465332\n",
            "Generator loss: 0.06455215811729431\n",
            "Classifier loss: 0.20074893534183502\n",
            "Classifier loss: 4.657926082611084\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.18459048867225647\n",
            "Classifier loss: 4.0725603103637695\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.22447258234024048\n",
            "Classifier loss: 4.084571838378906\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2936914265155792\n",
            "Classifier loss: 5.052074909210205\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6032760739326477\n",
            "Classifier loss: 6.054146766662598\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19425924122333527\n",
            "Classifier loss: 4.629262447357178\n",
            "Generator loss: 0.018294792622327805\n",
            "Running epoch 172 out of 1900\n",
            "Classifier loss: 0.2615399956703186\n",
            "Classifier loss: 2.5550596714019775\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33318716287612915\n",
            "Classifier loss: 4.054328441619873\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3156748414039612\n",
            "Classifier loss: 1.5639622211456299\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.30555880069732666\n",
            "Classifier loss: 3.192173480987549\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3111662268638611\n",
            "Classifier loss: 3.5686473846435547\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.292671263217926\n",
            "Classifier loss: 2.5553176403045654\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3062165677547455\n",
            "Classifier loss: 2.0607597827911377\n",
            "Generator loss: 0.30616408586502075\n",
            "Classifier loss: 0.29665157198905945\n",
            "Classifier loss: 3.1113171577453613\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.35930389165878296\n",
            "Classifier loss: 3.053356885910034\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.28378191590309143\n",
            "Classifier loss: 1.5547808408737183\n",
            "Generator loss: 0.0\n",
            "Running epoch 173 out of 1900\n",
            "Classifier loss: 0.2618860602378845\n",
            "Classifier loss: 2.068206548690796\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2984461486339569\n",
            "Classifier loss: 1.558215856552124\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.555648148059845\n",
            "Classifier loss: 1.572877049446106\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.47642987966537476\n",
            "Classifier loss: 2.1389307975769043\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.22737738490104675\n",
            "Classifier loss: 2.047396421432495\n",
            "Generator loss: 0.06472522765398026\n",
            "Classifier loss: 0.22150343656539917\n",
            "Classifier loss: 2.577901601791382\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.22512014210224152\n",
            "Classifier loss: 2.1885485649108887\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.19189848005771637\n",
            "Classifier loss: 4.05219841003418\n",
            "Generator loss: 0.02241954766213894\n",
            "Classifier loss: 0.22023557126522064\n",
            "Classifier loss: 4.118770599365234\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.25333186984062195\n",
            "Classifier loss: 2.1890718936920166\n",
            "Generator loss: 0.0\n",
            "Running epoch 174 out of 1900\n",
            "Classifier loss: 0.22717933356761932\n",
            "Classifier loss: 6.133120536804199\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33890098333358765\n",
            "Classifier loss: 5.786080360412598\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.371616929769516\n",
            "Classifier loss: 7.658367156982422\n",
            "Generator loss: 0.32005247473716736\n",
            "Classifier loss: 0.7358266115188599\n",
            "Classifier loss: 8.680399894714355\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2600956857204437\n",
            "Classifier loss: 7.664980411529541\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.43385469913482666\n",
            "Classifier loss: 5.826979160308838\n",
            "Generator loss: 0.02369551919400692\n",
            "Classifier loss: 0.65987229347229\n",
            "Classifier loss: 5.680999755859375\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.24375563859939575\n",
            "Classifier loss: 4.586629390716553\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2280980795621872\n",
            "Classifier loss: 5.080442428588867\n",
            "Generator loss: 0.05667524039745331\n",
            "Classifier loss: 0.3120802044868469\n",
            "Classifier loss: 4.098531246185303\n",
            "Generator loss: 0.0\n",
            "Running epoch 175 out of 1900\n",
            "Classifier loss: 0.43541085720062256\n",
            "Classifier loss: 5.564192295074463\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.49752703309059143\n",
            "Classifier loss: 5.090585231781006\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3921528458595276\n",
            "Classifier loss: 4.094040870666504\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3011791408061981\n",
            "Classifier loss: 4.559876441955566\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2125440388917923\n",
            "Classifier loss: 4.547554016113281\n",
            "Generator loss: 0.00010422398190712556\n",
            "Classifier loss: 0.4077834188938141\n",
            "Classifier loss: 5.087172031402588\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 1.1039162874221802\n",
            "Classifier loss: 6.0989508628845215\n",
            "Generator loss: 1.9073494783583556e-08\n",
            "Classifier loss: 0.512329638004303\n",
            "Classifier loss: 3.5397393703460693\n",
            "Generator loss: 1.3399571798800025e-06\n",
            "Classifier loss: 0.2583572268486023\n",
            "Classifier loss: 3.70131254196167\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8185598850250244\n",
            "Classifier loss: 4.5462493896484375\n",
            "Generator loss: 2.572043740656227e-05\n",
            "Running epoch 176 out of 1900\n",
            "Classifier loss: 0.228046715259552\n",
            "Classifier loss: 2.120260238647461\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 1.219460368156433\n",
            "Classifier loss: 2.2362751960754395\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8707162141799927\n",
            "Classifier loss: 3.596958637237549\n",
            "Generator loss: 4.064915180206299\n",
            "Classifier loss: 0.8119675517082214\n",
            "Classifier loss: 2.6307923793792725\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.798589825630188\n",
            "Classifier loss: 3.590320348739624\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5591107606887817\n",
            "Classifier loss: 1.6173533201217651\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.9792645573616028\n",
            "Classifier loss: 4.130401134490967\n",
            "Generator loss: 0.06493830680847168\n",
            "Classifier loss: 0.21741004288196564\n",
            "Classifier loss: 2.611650228500366\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.627735435962677\n",
            "Classifier loss: 2.667372465133667\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2516920268535614\n",
            "Classifier loss: 3.069228172302246\n",
            "Generator loss: 0.0\n",
            "Running epoch 177 out of 1900\n",
            "Classifier loss: 0.49262723326683044\n",
            "Classifier loss: 4.087808609008789\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.25174862146377563\n",
            "Classifier loss: 4.172677040100098\n",
            "Generator loss: 1.4567906418960774e-06\n",
            "Classifier loss: 0.24805191159248352\n",
            "Classifier loss: 3.124224901199341\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2669488787651062\n",
            "Classifier loss: 2.630164384841919\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.28506821393966675\n",
            "Classifier loss: 4.054229259490967\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3067212700843811\n",
            "Classifier loss: 3.5728719234466553\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.24444064497947693\n",
            "Classifier loss: 2.5689871311187744\n",
            "Generator loss: 0.0018669391283765435\n",
            "Classifier loss: 0.354715496301651\n",
            "Classifier loss: 4.661858558654785\n",
            "Generator loss: 0.06499454379081726\n",
            "Classifier loss: 0.26759153604507446\n",
            "Classifier loss: 3.111966371536255\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2593212127685547\n",
            "Classifier loss: 2.55108642578125\n",
            "Generator loss: 0.0\n",
            "Running epoch 178 out of 1900\n",
            "Classifier loss: 0.5570391416549683\n",
            "Classifier loss: 1.3521690368652344\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.37823039293289185\n",
            "Classifier loss: 1.3168413639068604\n",
            "Generator loss: 0.0019255041843280196\n",
            "Classifier loss: 0.4392896890640259\n",
            "Classifier loss: 1.5706719160079956\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.36345016956329346\n",
            "Classifier loss: 1.5536946058273315\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.37429508566856384\n",
            "Classifier loss: 1.671226143836975\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.45061102509498596\n",
            "Classifier loss: 2.1313157081604004\n",
            "Generator loss: 0.06502869725227356\n",
            "Classifier loss: 0.54456627368927\n",
            "Classifier loss: 1.0601768493652344\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6773602962493896\n",
            "Classifier loss: 2.1547186374664307\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3730890452861786\n",
            "Classifier loss: 1.5681403875350952\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.32829490303993225\n",
            "Classifier loss: 1.632820725440979\n",
            "Generator loss: 0.0\n",
            "Running epoch 179 out of 1900\n",
            "Classifier loss: 0.5192355513572693\n",
            "Classifier loss: 5.231513023376465\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4670482575893402\n",
            "Classifier loss: 2.5636303424835205\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6262485980987549\n",
            "Classifier loss: 2.6413676738739014\n",
            "Generator loss: 0.06504932045936584\n",
            "Classifier loss: 0.6245611310005188\n",
            "Classifier loss: 3.538088798522949\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.45048990845680237\n",
            "Classifier loss: 3.5368733406066895\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4426719546318054\n",
            "Classifier loss: 5.045085430145264\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4293464124202728\n",
            "Classifier loss: 2.539958953857422\n",
            "Generator loss: 0.0006500870804302394\n",
            "Classifier loss: 0.5083724856376648\n",
            "Classifier loss: 2.5399463176727295\n",
            "Generator loss: 2.694148122373008e-07\n",
            "Classifier loss: 0.3936176300048828\n",
            "Classifier loss: 4.537757396697998\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6850624084472656\n",
            "Classifier loss: 4.538321495056152\n",
            "Generator loss: 0.0\n",
            "Running epoch 180 out of 1900\n",
            "Classifier loss: 0.47577139735221863\n",
            "Classifier loss: 2.603957414627075\n",
            "Generator loss: 0.3754821717739105\n",
            "Classifier loss: 0.32513734698295593\n",
            "Classifier loss: 3.154167413711548\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5883757472038269\n",
            "Classifier loss: 3.081719398498535\n",
            "Generator loss: 0.06506150960922241\n",
            "Classifier loss: 0.3278407156467438\n",
            "Classifier loss: 2.5454535484313965\n",
            "Generator loss: 0.032197341322898865\n",
            "Classifier loss: 0.817992091178894\n",
            "Classifier loss: 3.562413454055786\n",
            "Generator loss: 0.0650608018040657\n",
            "Classifier loss: 0.3344886302947998\n",
            "Classifier loss: 3.6172735691070557\n",
            "Generator loss: 0.06506046652793884\n",
            "Classifier loss: 0.4467693269252777\n",
            "Classifier loss: 3.059582471847534\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5629861354827881\n",
            "Classifier loss: 2.5796992778778076\n",
            "Generator loss: 2.4296327865158673e-06\n",
            "Classifier loss: 0.3195244073867798\n",
            "Classifier loss: 3.574275493621826\n",
            "Generator loss: 0.4356468617916107\n",
            "Classifier loss: 0.2792917490005493\n",
            "Classifier loss: 3.544212579727173\n",
            "Generator loss: 0.0\n",
            "Running epoch 181 out of 1900\n",
            "Classifier loss: 0.5214419960975647\n",
            "Classifier loss: 1.546549916267395\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4913661479949951\n",
            "Classifier loss: 3.0462357997894287\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.43030714988708496\n",
            "Classifier loss: 2.0559475421905518\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.47533661127090454\n",
            "Classifier loss: 2.5662636756896973\n",
            "Generator loss: 0.06505157053470612\n",
            "Classifier loss: 0.4683785140514374\n",
            "Classifier loss: 3.5503060817718506\n",
            "Generator loss: 0.02492772787809372\n",
            "Classifier loss: 0.5498790144920349\n",
            "Classifier loss: 2.6126179695129395\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.47823745012283325\n",
            "Classifier loss: 1.5639911890029907\n",
            "Generator loss: 0.110819511115551\n",
            "Classifier loss: 0.8859550952911377\n",
            "Classifier loss: 2.553797721862793\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.46427398920059204\n",
            "Classifier loss: 2.574611186981201\n",
            "Generator loss: 0.13007459044456482\n",
            "Classifier loss: 0.515411913394928\n",
            "Classifier loss: 2.222432851791382\n",
            "Generator loss: 0.0\n",
            "Running epoch 182 out of 1900\n",
            "Classifier loss: 0.3853682279586792\n",
            "Classifier loss: 2.6889941692352295\n",
            "Generator loss: 0.030829710885882378\n",
            "Classifier loss: 0.5422199368476868\n",
            "Classifier loss: 3.579710006713867\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.37386825680732727\n",
            "Classifier loss: 3.1764042377471924\n",
            "Generator loss: 0.06502080708742142\n",
            "Classifier loss: 0.42514365911483765\n",
            "Classifier loss: 2.1168532371520996\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.431130975484848\n",
            "Classifier loss: 2.1316580772399902\n",
            "Generator loss: 1.6451558622065932e-06\n",
            "Classifier loss: 0.4005708694458008\n",
            "Classifier loss: 2.6256697177886963\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3726590573787689\n",
            "Classifier loss: 2.098965883255005\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3466978073120117\n",
            "Classifier loss: 3.1207094192504883\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3413858711719513\n",
            "Classifier loss: 3.651520252227783\n",
            "Generator loss: 0.030775167047977448\n",
            "Classifier loss: 0.3751542568206787\n",
            "Classifier loss: 2.6217379570007324\n",
            "Generator loss: 0.12997078895568848\n",
            "Running epoch 183 out of 1900\n",
            "Classifier loss: 0.38739192485809326\n",
            "Classifier loss: 6.65600061416626\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.48022177815437317\n",
            "Classifier loss: 2.7061963081359863\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.36874762177467346\n",
            "Classifier loss: 5.214763641357422\n",
            "Generator loss: 0.05910123512148857\n",
            "Classifier loss: 0.4971313774585724\n",
            "Classifier loss: 3.627037525177002\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.749889075756073\n",
            "Classifier loss: 3.7166922092437744\n",
            "Generator loss: 0.060886990278959274\n",
            "Classifier loss: 0.4105567932128906\n",
            "Classifier loss: 3.207853317260742\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6217869520187378\n",
            "Classifier loss: 2.654902696609497\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.40819716453552246\n",
            "Classifier loss: 3.7332799434661865\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.42727524042129517\n",
            "Classifier loss: 3.196613311767578\n",
            "Generator loss: 0.00045785962720401585\n",
            "Classifier loss: 1.0390366315841675\n",
            "Classifier loss: 4.128174781799316\n",
            "Generator loss: 0.0\n",
            "Running epoch 184 out of 1900\n",
            "Classifier loss: 0.271886944770813\n",
            "Classifier loss: 1.6730778217315674\n",
            "Generator loss: 0.0007487714174203575\n",
            "Classifier loss: 0.2620599567890167\n",
            "Classifier loss: 2.1226446628570557\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3200675845146179\n",
            "Classifier loss: 2.171363592147827\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.39403676986694336\n",
            "Classifier loss: 1.7012996673583984\n",
            "Generator loss: 0.06489988416433334\n",
            "Classifier loss: 0.2739965319633484\n",
            "Classifier loss: 1.6573606729507446\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2484549731016159\n",
            "Classifier loss: 1.1331192255020142\n",
            "Generator loss: 0.129774272441864\n",
            "Classifier loss: 0.35560062527656555\n",
            "Classifier loss: 1.143272876739502\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.567683219909668\n",
            "Classifier loss: 2.1088364124298096\n",
            "Generator loss: 0.06492821127176285\n",
            "Classifier loss: 0.35119184851646423\n",
            "Classifier loss: 1.1352546215057373\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.27098509669303894\n",
            "Classifier loss: 1.6393909454345703\n",
            "Generator loss: 0.06486142426729202\n",
            "Running epoch 185 out of 1900\n",
            "Classifier loss: 0.35593631863594055\n",
            "Classifier loss: 2.0998637676239014\n",
            "Generator loss: 0.04865281656384468\n",
            "Classifier loss: 0.34130728244781494\n",
            "Classifier loss: 2.148003578186035\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.37119540572166443\n",
            "Classifier loss: 1.6664419174194336\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3403949737548828\n",
            "Classifier loss: 2.2121286392211914\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3949785828590393\n",
            "Classifier loss: 1.6317613124847412\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4127698540687561\n",
            "Classifier loss: 2.627960681915283\n",
            "Generator loss: 0.002333046169951558\n",
            "Classifier loss: 0.37154170870780945\n",
            "Classifier loss: 2.0970101356506348\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8806138634681702\n",
            "Classifier loss: 1.5939202308654785\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3647896349430084\n",
            "Classifier loss: 1.6435538530349731\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.35976505279541016\n",
            "Classifier loss: 2.194568634033203\n",
            "Generator loss: 0.0\n",
            "Running epoch 186 out of 1900\n",
            "Classifier loss: 0.31729546189308167\n",
            "Classifier loss: 2.1566760540008545\n",
            "Generator loss: 0.0647829994559288\n",
            "Classifier loss: 0.4208422005176544\n",
            "Classifier loss: 1.6966854333877563\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.37483495473861694\n",
            "Classifier loss: 2.622058629989624\n",
            "Generator loss: 0.05728920176625252\n",
            "Classifier loss: 0.3121127188205719\n",
            "Classifier loss: 2.142029285430908\n",
            "Generator loss: 0.5708797574043274\n",
            "Classifier loss: 0.39516589045524597\n",
            "Classifier loss: 2.1404690742492676\n",
            "Generator loss: 0.06475125998258591\n",
            "Classifier loss: 0.3230332136154175\n",
            "Classifier loss: 2.6263694763183594\n",
            "Generator loss: 0.06474309414625168\n",
            "Classifier loss: 0.5953770875930786\n",
            "Classifier loss: 1.6362890005111694\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7820872068405151\n",
            "Classifier loss: 2.1033689975738525\n",
            "Generator loss: 0.7833870053291321\n",
            "Classifier loss: 0.2922895848751068\n",
            "Classifier loss: 2.6147758960723877\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.30864378809928894\n",
            "Classifier loss: 1.650016188621521\n",
            "Generator loss: 0.0011602526064962149\n",
            "Running epoch 187 out of 1900\n",
            "Classifier loss: 0.26816317439079285\n",
            "Classifier loss: 3.5744035243988037\n",
            "Generator loss: 0.12940232455730438\n",
            "Classifier loss: 0.2885362505912781\n",
            "Classifier loss: 3.6028738021850586\n",
            "Generator loss: 0.10439489036798477\n",
            "Classifier loss: 0.8689454197883606\n",
            "Classifier loss: 3.1829910278320312\n",
            "Generator loss: 0.06468368321657181\n",
            "Classifier loss: 0.3451698124408722\n",
            "Classifier loss: 3.5923290252685547\n",
            "Generator loss: 1.4305119755420037e-08\n",
            "Classifier loss: 0.33913740515708923\n",
            "Classifier loss: 2.7018096446990967\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.347100168466568\n",
            "Classifier loss: 3.5741195678710938\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6356406807899475\n",
            "Classifier loss: 2.5850725173950195\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.27814096212387085\n",
            "Classifier loss: 3.1796560287475586\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3567935824394226\n",
            "Classifier loss: 2.5956597328186035\n",
            "Generator loss: 0.133042573928833\n",
            "Classifier loss: 0.7967405319213867\n",
            "Classifier loss: 3.6230311393737793\n",
            "Generator loss: 0.06517619639635086\n",
            "Running epoch 188 out of 1900\n",
            "Classifier loss: 0.4921453297138214\n",
            "Classifier loss: 5.112028121948242\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4058813750743866\n",
            "Classifier loss: 3.66068696975708\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.5360309481620789\n",
            "Classifier loss: 2.6257619857788086\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4088287949562073\n",
            "Classifier loss: 3.6231374740600586\n",
            "Generator loss: 0.06457797437906265\n",
            "Classifier loss: 0.4310327172279358\n",
            "Classifier loss: 3.578359842300415\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.39741072058677673\n",
            "Classifier loss: 3.1417758464813232\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4033287763595581\n",
            "Classifier loss: 3.57320499420166\n",
            "Generator loss: 0.06454566866159439\n",
            "Classifier loss: 0.8801591396331787\n",
            "Classifier loss: 4.111404895782471\n",
            "Generator loss: 0.2172178030014038\n",
            "Classifier loss: 0.39890578389167786\n",
            "Classifier loss: 2.5692334175109863\n",
            "Generator loss: 0.09669365733861923\n",
            "Classifier loss: 0.41988304257392883\n",
            "Classifier loss: 5.573020935058594\n",
            "Generator loss: 0.0\n",
            "Running epoch 189 out of 1900\n",
            "Classifier loss: 0.24531309306621552\n",
            "Classifier loss: 1.5816810131072998\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.27255064249038696\n",
            "Classifier loss: 2.0751171112060547\n",
            "Generator loss: 0.06448733061552048\n",
            "Classifier loss: 0.2887125313282013\n",
            "Classifier loss: 1.6462997198104858\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.21545018255710602\n",
            "Classifier loss: 1.747644305229187\n",
            "Generator loss: 0.0644630417227745\n",
            "Classifier loss: 0.2246905118227005\n",
            "Classifier loss: 1.0816339254379272\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2640332281589508\n",
            "Classifier loss: 2.1421163082122803\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2185741811990738\n",
            "Classifier loss: 2.069967031478882\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2505019009113312\n",
            "Classifier loss: 2.6181747913360596\n",
            "Generator loss: 0.06792035698890686\n",
            "Classifier loss: 0.36042776703834534\n",
            "Classifier loss: 1.0786185264587402\n",
            "Generator loss: 0.06440149247646332\n",
            "Classifier loss: 0.21549205482006073\n",
            "Classifier loss: 2.591073751449585\n",
            "Generator loss: 0.06593751162290573\n",
            "Running epoch 190 out of 1900\n",
            "Classifier loss: 0.32005617022514343\n",
            "Classifier loss: 2.131760597229004\n",
            "Generator loss: 2.9103461201884784e-05\n",
            "Classifier loss: 0.3988420069217682\n",
            "Classifier loss: 4.120091915130615\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3007860779762268\n",
            "Classifier loss: 4.124563694000244\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4059678614139557\n",
            "Classifier loss: 2.0674331188201904\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.41016387939453125\n",
            "Classifier loss: 2.6317639350891113\n",
            "Generator loss: 3.933361222152598e-05\n",
            "Classifier loss: 0.352663516998291\n",
            "Classifier loss: 3.647036075592041\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3001489043235779\n",
            "Classifier loss: 3.0867228507995605\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.797220766544342\n",
            "Classifier loss: 2.1533327102661133\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4016890525817871\n",
            "Classifier loss: 4.154369354248047\n",
            "Generator loss: 0.06426922976970673\n",
            "Classifier loss: 0.35803499817848206\n",
            "Classifier loss: 4.110496520996094\n",
            "Generator loss: 0.0\n",
            "Running epoch 191 out of 1900\n",
            "Classifier loss: 0.2563057243824005\n",
            "Classifier loss: 2.6407275199890137\n",
            "Generator loss: 0.12848249077796936\n",
            "Classifier loss: 0.2910369336605072\n",
            "Classifier loss: 4.1919074058532715\n",
            "Generator loss: 0.06422709673643112\n",
            "Classifier loss: 0.21518808603286743\n",
            "Classifier loss: 3.644432544708252\n",
            "Generator loss: 0.064212866127491\n",
            "Classifier loss: 0.28081753849983215\n",
            "Classifier loss: 4.104313850402832\n",
            "Generator loss: 0.06419854611158371\n",
            "Classifier loss: 0.33771640062332153\n",
            "Classifier loss: 3.5839054584503174\n",
            "Generator loss: 0.034086644649505615\n",
            "Classifier loss: 0.41335082054138184\n",
            "Classifier loss: 3.5711381435394287\n",
            "Generator loss: 0.06416945159435272\n",
            "Classifier loss: 0.27772513031959534\n",
            "Classifier loss: 3.065124750137329\n",
            "Generator loss: 0.06415461003780365\n",
            "Classifier loss: 0.3192770183086395\n",
            "Classifier loss: 4.573693752288818\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3602202534675598\n",
            "Classifier loss: 3.108492612838745\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2978832423686981\n",
            "Classifier loss: 3.6021721363067627\n",
            "Generator loss: 0.06410904973745346\n",
            "Running epoch 192 out of 1900\n",
            "Classifier loss: 0.3088410198688507\n",
            "Classifier loss: 5.089389801025391\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.28615766763687134\n",
            "Classifier loss: 4.057407379150391\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2836298644542694\n",
            "Classifier loss: 4.559762954711914\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2999395430088043\n",
            "Classifier loss: 5.56617546081543\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.292786568403244\n",
            "Classifier loss: 4.632306098937988\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.26504242420196533\n",
            "Classifier loss: 4.120907783508301\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2977663278579712\n",
            "Classifier loss: 5.061114311218262\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.25258350372314453\n",
            "Classifier loss: 5.616701126098633\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.23965443670749664\n",
            "Classifier loss: 4.560557842254639\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.23561160266399384\n",
            "Classifier loss: 4.065469741821289\n",
            "Generator loss: 0.0\n",
            "Running epoch 193 out of 1900\n",
            "Classifier loss: 0.4582318067550659\n",
            "Classifier loss: 3.564840078353882\n",
            "Generator loss: 1.6344309187843464e-05\n",
            "Classifier loss: 0.4139710068702698\n",
            "Classifier loss: 4.563460350036621\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.43824079632759094\n",
            "Classifier loss: 5.113862037658691\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4019356369972229\n",
            "Classifier loss: 4.0643510818481445\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.39142584800720215\n",
            "Classifier loss: 5.0756425857543945\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3820834755897522\n",
            "Classifier loss: 4.089522838592529\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3544178605079651\n",
            "Classifier loss: 3.5827531814575195\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.41711264848709106\n",
            "Classifier loss: 3.5854387283325195\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3435974419116974\n",
            "Classifier loss: 4.6132073402404785\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3921508193016052\n",
            "Classifier loss: 4.590986251831055\n",
            "Generator loss: 0.0\n",
            "Running epoch 194 out of 1900\n",
            "Classifier loss: 0.23030345141887665\n",
            "Classifier loss: 2.737168550491333\n",
            "Generator loss: 0.050380971282720566\n",
            "Classifier loss: 0.26939260959625244\n",
            "Classifier loss: 1.1955831050872803\n",
            "Generator loss: 0.06373482197523117\n",
            "Classifier loss: 0.22419564425945282\n",
            "Classifier loss: 1.1055866479873657\n",
            "Generator loss: 0.06371608376502991\n",
            "Classifier loss: 0.20920631289482117\n",
            "Classifier loss: 1.6778260469436646\n",
            "Generator loss: 0.11129648983478546\n",
            "Classifier loss: 0.20535938441753387\n",
            "Classifier loss: 1.1796847581863403\n",
            "Generator loss: 0.0636785700917244\n",
            "Classifier loss: 0.24107395112514496\n",
            "Classifier loss: 1.0978171825408936\n",
            "Generator loss: 0.12731949985027313\n",
            "Classifier loss: 0.24548189342021942\n",
            "Classifier loss: 0.7461262345314026\n",
            "Generator loss: 0.06364084780216217\n",
            "Classifier loss: 0.23126712441444397\n",
            "Classifier loss: 0.5971551537513733\n",
            "Generator loss: 0.12724381685256958\n",
            "Classifier loss: 0.25806576013565063\n",
            "Classifier loss: 1.1428872346878052\n",
            "Generator loss: 0.1272057294845581\n",
            "Classifier loss: 0.2723889946937561\n",
            "Classifier loss: 0.5859842896461487\n",
            "Generator loss: 0.06359218060970306\n",
            "Running epoch 195 out of 1900\n",
            "Classifier loss: 0.5732740163803101\n",
            "Classifier loss: 4.077533721923828\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3036508858203888\n",
            "Classifier loss: 4.575162887573242\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.31657370924949646\n",
            "Classifier loss: 4.074134349822998\n",
            "Generator loss: 7.152558545442389e-09\n",
            "Classifier loss: 0.2825550138950348\n",
            "Classifier loss: 4.622938632965088\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.37216514348983765\n",
            "Classifier loss: 4.074903964996338\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3550102114677429\n",
            "Classifier loss: 4.630898952484131\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.29456833004951477\n",
            "Classifier loss: 4.5705156326293945\n",
            "Generator loss: 0.04011774808168411\n",
            "Classifier loss: 0.2761724889278412\n",
            "Classifier loss: 4.071412086486816\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.334267258644104\n",
            "Classifier loss: 5.069021224975586\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.30271509289741516\n",
            "Classifier loss: 4.1496992111206055\n",
            "Generator loss: 0.0\n",
            "Running epoch 196 out of 1900\n",
            "Classifier loss: 0.29660171270370483\n",
            "Classifier loss: 2.6168878078460693\n",
            "Generator loss: 0.06338352710008621\n",
            "Classifier loss: 0.2613336741924286\n",
            "Classifier loss: 2.5826094150543213\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2785567343235016\n",
            "Classifier loss: 2.6020760536193848\n",
            "Generator loss: 0.06332097202539444\n",
            "Classifier loss: 0.267522394657135\n",
            "Classifier loss: 2.0864129066467285\n",
            "Generator loss: 0.18989966809749603\n",
            "Classifier loss: 0.2743196487426758\n",
            "Classifier loss: 3.1752166748046875\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.22955039143562317\n",
            "Classifier loss: 2.129101276397705\n",
            "Generator loss: 0.11628762632608414\n",
            "Classifier loss: 0.33061927556991577\n",
            "Classifier loss: 3.0848894119262695\n",
            "Generator loss: 0.12647143006324768\n",
            "Classifier loss: 0.3010624945163727\n",
            "Classifier loss: 2.5849177837371826\n",
            "Generator loss: 0.06353217363357544\n",
            "Classifier loss: 0.26587873697280884\n",
            "Classifier loss: 3.0841832160949707\n",
            "Generator loss: 0.06319491565227509\n",
            "Classifier loss: 0.2556595504283905\n",
            "Classifier loss: 2.0843505859375\n",
            "Generator loss: 0.13431385159492493\n",
            "Running epoch 197 out of 1900\n",
            "Classifier loss: 0.3074289560317993\n",
            "Classifier loss: 2.5955357551574707\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2625967264175415\n",
            "Classifier loss: 2.6238110065460205\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.22803619503974915\n",
            "Classifier loss: 1.671762228012085\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.25763198733329773\n",
            "Classifier loss: 1.6032726764678955\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2365744709968567\n",
            "Classifier loss: 2.091036558151245\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2862904369831085\n",
            "Classifier loss: 1.688859224319458\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.23165908455848694\n",
            "Classifier loss: 2.5903093814849854\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7380630373954773\n",
            "Classifier loss: 3.085966110229492\n",
            "Generator loss: 0.00021806433505844325\n",
            "Classifier loss: 0.29518747329711914\n",
            "Classifier loss: 2.0935263633728027\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3844141364097595\n",
            "Classifier loss: 2.092468023300171\n",
            "Generator loss: 0.0\n",
            "Running epoch 198 out of 1900\n",
            "Classifier loss: 0.28530868887901306\n",
            "Classifier loss: 4.081874847412109\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3425425887107849\n",
            "Classifier loss: 2.089366912841797\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7143418788909912\n",
            "Classifier loss: 2.607421398162842\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 1.3446098566055298\n",
            "Classifier loss: 3.581984281539917\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8406802415847778\n",
            "Classifier loss: 2.5777604579925537\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6029253602027893\n",
            "Classifier loss: 2.629272699356079\n",
            "Generator loss: 0.6733935475349426\n",
            "Classifier loss: 0.38721251487731934\n",
            "Classifier loss: 2.598649740219116\n",
            "Generator loss: 0.06278622895479202\n",
            "Classifier loss: 0.5889027118682861\n",
            "Classifier loss: 2.163918972015381\n",
            "Generator loss: 0.06276290118694305\n",
            "Classifier loss: 0.3621244728565216\n",
            "Classifier loss: 2.57816481590271\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.43605878949165344\n",
            "Classifier loss: 2.1516730785369873\n",
            "Generator loss: 0.06271573901176453\n",
            "Running epoch 199 out of 1900\n",
            "Classifier loss: 0.2552046477794647\n",
            "Classifier loss: 3.18091082572937\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2341863512992859\n",
            "Classifier loss: 3.0906014442443848\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2162685990333557\n",
            "Classifier loss: 3.131783962249756\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2586915194988251\n",
            "Classifier loss: 3.0860183238983154\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.20282530784606934\n",
            "Classifier loss: 3.5696423053741455\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6741107106208801\n",
            "Classifier loss: 3.570091485977173\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2679279148578644\n",
            "Classifier loss: 4.061987400054932\n",
            "Generator loss: 1.6193982446566224e-05\n",
            "Classifier loss: 0.3166840970516205\n",
            "Classifier loss: 2.611436605453491\n",
            "Generator loss: 0.27820834517478943\n",
            "Classifier loss: 0.21290424466133118\n",
            "Classifier loss: 2.075993061065674\n",
            "Generator loss: 0.06250125914812088\n",
            "Classifier loss: 0.19670158624649048\n",
            "Classifier loss: 3.5717005729675293\n",
            "Generator loss: 0.0\n",
            "Running epoch 200 out of 1900\n",
            "Classifier loss: 0.36992374062538147\n",
            "Classifier loss: 2.572654962539673\n",
            "Generator loss: 0.06245279312133789\n",
            "Classifier loss: 0.48522841930389404\n",
            "Classifier loss: 4.13173246383667\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.32746565341949463\n",
            "Classifier loss: 2.57364559173584\n",
            "Generator loss: 0.06240350008010864\n",
            "Classifier loss: 0.39933058619499207\n",
            "Classifier loss: 3.092348575592041\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.41379430890083313\n",
            "Classifier loss: 3.077753782272339\n",
            "Generator loss: 0.0623534731566906\n",
            "Classifier loss: 0.3578498661518097\n",
            "Classifier loss: 4.184596061706543\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4801402986049652\n",
            "Classifier loss: 3.1654186248779297\n",
            "Generator loss: 0.06230272725224495\n",
            "Classifier loss: 0.30599257349967957\n",
            "Classifier loss: 3.5899314880371094\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3643389046192169\n",
            "Classifier loss: 3.5965425968170166\n",
            "Generator loss: 3.1233076924763736e-07\n",
            "Classifier loss: 0.3914860486984253\n",
            "Classifier loss: 2.658303737640381\n",
            "Generator loss: 0.0\n",
            "Running epoch 201 out of 1900\n",
            "Classifier loss: 0.2376316636800766\n",
            "Classifier loss: 1.6066057682037354\n",
            "Generator loss: 0.18659870326519012\n",
            "Classifier loss: 0.5278798341751099\n",
            "Classifier loss: 2.098393678665161\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.33629828691482544\n",
            "Classifier loss: 2.0880420207977295\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2723122537136078\n",
            "Classifier loss: 2.587214946746826\n",
            "Generator loss: 0.06212075054645538\n",
            "Classifier loss: 0.30996063351631165\n",
            "Classifier loss: 2.097947835922241\n",
            "Generator loss: 0.06209424510598183\n",
            "Classifier loss: 0.2861267924308777\n",
            "Classifier loss: 2.097848892211914\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3650349974632263\n",
            "Classifier loss: 1.5910123586654663\n",
            "Generator loss: 0.1240817978978157\n",
            "Classifier loss: 0.3278214931488037\n",
            "Classifier loss: 2.089120626449585\n",
            "Generator loss: 0.06201397627592087\n",
            "Classifier loss: 0.37456220388412476\n",
            "Classifier loss: 1.6256648302078247\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2976987659931183\n",
            "Classifier loss: 1.6235243082046509\n",
            "Generator loss: 0.0\n",
            "Running epoch 202 out of 1900\n",
            "Classifier loss: 0.48419079184532166\n",
            "Classifier loss: 3.0855319499969482\n",
            "Generator loss: 0.12386433035135269\n",
            "Classifier loss: 0.4606974720954895\n",
            "Classifier loss: 2.085690975189209\n",
            "Generator loss: 0.18571312725543976\n",
            "Classifier loss: 0.4604538679122925\n",
            "Classifier loss: 1.6263020038604736\n",
            "Generator loss: 0.099103182554245\n",
            "Classifier loss: 0.5373004674911499\n",
            "Classifier loss: 1.5758548974990845\n",
            "Generator loss: 0.247390016913414\n",
            "Classifier loss: 0.453493595123291\n",
            "Classifier loss: 2.0799977779388428\n",
            "Generator loss: 0.1236366555094719\n",
            "Classifier loss: 0.5102680921554565\n",
            "Classifier loss: 2.073962450027466\n",
            "Generator loss: 0.12357669323682785\n",
            "Classifier loss: 0.5545331239700317\n",
            "Classifier loss: 1.0721348524093628\n",
            "Generator loss: 0.12351693958044052\n",
            "Classifier loss: 0.5151861310005188\n",
            "Classifier loss: 2.073259115219116\n",
            "Generator loss: 0.06172778829932213\n",
            "Classifier loss: 0.5173900723457336\n",
            "Classifier loss: 1.0708504915237427\n",
            "Generator loss: 0.06169665604829788\n",
            "Classifier loss: 0.46618688106536865\n",
            "Classifier loss: 1.6342798471450806\n",
            "Generator loss: 0.2477240264415741\n",
            "Running epoch 203 out of 1900\n",
            "Classifier loss: 0.3742002844810486\n",
            "Classifier loss: 2.6462793350219727\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.260039746761322\n",
            "Classifier loss: 2.1188104152679443\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4169129729270935\n",
            "Classifier loss: 4.074466705322266\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.26982784271240234\n",
            "Classifier loss: 3.578486204147339\n",
            "Generator loss: 6.365882290992886e-05\n",
            "Classifier loss: 0.28361907601356506\n",
            "Classifier loss: 2.5732362270355225\n",
            "Generator loss: 0.06186487898230553\n",
            "Classifier loss: 0.3131585121154785\n",
            "Classifier loss: 2.574338436126709\n",
            "Generator loss: 0.06147781386971474\n",
            "Classifier loss: 0.2962985932826996\n",
            "Classifier loss: 2.0668785572052\n",
            "Generator loss: 3.3948606869671494e-05\n",
            "Classifier loss: 0.23889701068401337\n",
            "Classifier loss: 2.5694832801818848\n",
            "Generator loss: 0.10893331468105316\n",
            "Classifier loss: 0.3126499056816101\n",
            "Classifier loss: 2.5703020095825195\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8499557375907898\n",
            "Classifier loss: 2.584357261657715\n",
            "Generator loss: 0.0\n",
            "Running epoch 204 out of 1900\n",
            "Classifier loss: 0.4036761522293091\n",
            "Classifier loss: 1.6404471397399902\n",
            "Generator loss: 0.06130797415971756\n",
            "Classifier loss: 0.5222352743148804\n",
            "Classifier loss: 2.56496262550354\n",
            "Generator loss: 0.061274509876966476\n",
            "Classifier loss: 0.4656510055065155\n",
            "Classifier loss: 1.061754822731018\n",
            "Generator loss: 0.12144635617733002\n",
            "Classifier loss: 0.4285332262516022\n",
            "Classifier loss: 3.10217022895813\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4271889328956604\n",
            "Classifier loss: 2.072748899459839\n",
            "Generator loss: 3.971941623603925e-05\n",
            "Classifier loss: 0.48159629106521606\n",
            "Classifier loss: 2.582413911819458\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4035603106021881\n",
            "Classifier loss: 1.5609155893325806\n",
            "Generator loss: 1.056222117767902e-06\n",
            "Classifier loss: 0.4185866415500641\n",
            "Classifier loss: 0.5653719902038574\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4186347723007202\n",
            "Classifier loss: 1.5591496229171753\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.40667402744293213\n",
            "Classifier loss: 1.0610438585281372\n",
            "Generator loss: 0.060995738953351974\n",
            "Running epoch 205 out of 1900\n",
            "Classifier loss: 0.36500510573387146\n",
            "Classifier loss: 2.560408353805542\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.39507991075515747\n",
            "Classifier loss: 2.0573294162750244\n",
            "Generator loss: 0.07356757670640945\n",
            "Classifier loss: 0.4590485990047455\n",
            "Classifier loss: 2.5604257583618164\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8854580521583557\n",
            "Classifier loss: 2.112043619155884\n",
            "Generator loss: 0.06084991246461868\n",
            "Classifier loss: 0.40814903378486633\n",
            "Classifier loss: 2.554558038711548\n",
            "Generator loss: 2.2296215320238844e-05\n",
            "Classifier loss: 0.35709822177886963\n",
            "Classifier loss: 1.558282494544983\n",
            "Generator loss: 0.06077536940574646\n",
            "Classifier loss: 0.37922587990760803\n",
            "Classifier loss: 2.5650429725646973\n",
            "Generator loss: 0.03573910892009735\n",
            "Classifier loss: 0.7412194609642029\n",
            "Classifier loss: 1.560198426246643\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4131373465061188\n",
            "Classifier loss: 2.0762715339660645\n",
            "Generator loss: 0.12132325023412704\n",
            "Classifier loss: 0.37586870789527893\n",
            "Classifier loss: 1.6421756744384766\n",
            "Generator loss: 0.060623157769441605\n",
            "Running epoch 206 out of 1900\n",
            "Classifier loss: 0.35523390769958496\n",
            "Classifier loss: 5.060810565948486\n",
            "Generator loss: 0.1817532628774643\n",
            "Classifier loss: 0.39552024006843567\n",
            "Classifier loss: 4.120054721832275\n",
            "Generator loss: 0.06054532900452614\n",
            "Classifier loss: 0.4638158977031708\n",
            "Classifier loss: 5.133677959442139\n",
            "Generator loss: 0.06050600856542587\n",
            "Classifier loss: 0.34752973914146423\n",
            "Classifier loss: 3.625631332397461\n",
            "Generator loss: 0.060466475784778595\n",
            "Classifier loss: 0.3472561538219452\n",
            "Classifier loss: 4.557127475738525\n",
            "Generator loss: 0.1208534687757492\n",
            "Classifier loss: 0.30733686685562134\n",
            "Classifier loss: 4.572540283203125\n",
            "Generator loss: 0.12077349424362183\n",
            "Classifier loss: 0.4126315116882324\n",
            "Classifier loss: 3.5592145919799805\n",
            "Generator loss: 0.060346439480781555\n",
            "Classifier loss: 0.32171186804771423\n",
            "Classifier loss: 4.558310031890869\n",
            "Generator loss: 0.12061174213886261\n",
            "Classifier loss: 0.4537303149700165\n",
            "Classifier loss: 4.566729545593262\n",
            "Generator loss: 0.2956690192222595\n",
            "Classifier loss: 0.46013307571411133\n",
            "Classifier loss: 4.558475017547607\n",
            "Generator loss: 0.14310140907764435\n",
            "Running epoch 207 out of 1900\n",
            "Classifier loss: 0.3687654733657837\n",
            "Classifier loss: 3.56095290184021\n",
            "Generator loss: 0.2883760333061218\n",
            "Classifier loss: 0.4583818018436432\n",
            "Classifier loss: 2.0588057041168213\n",
            "Generator loss: 0.48111364245414734\n",
            "Classifier loss: 0.39164283871650696\n",
            "Classifier loss: 2.059753656387329\n",
            "Generator loss: 0.35777053236961365\n",
            "Classifier loss: 0.4482874870300293\n",
            "Classifier loss: 3.562725067138672\n",
            "Generator loss: 0.34345361590385437\n",
            "Classifier loss: 0.483534038066864\n",
            "Classifier loss: 2.626523494720459\n",
            "Generator loss: 0.4163576066493988\n",
            "Classifier loss: 0.42231643199920654\n",
            "Classifier loss: 4.062049388885498\n",
            "Generator loss: 0.3553551435470581\n",
            "Classifier loss: 0.3883322477340698\n",
            "Classifier loss: 3.067941188812256\n",
            "Generator loss: 0.23516122996807098\n",
            "Classifier loss: 0.3957950472831726\n",
            "Classifier loss: 2.5730066299438477\n",
            "Generator loss: 0.29563915729522705\n",
            "Classifier loss: 0.38532575964927673\n",
            "Classifier loss: 3.0694596767425537\n",
            "Generator loss: 0.1865967959165573\n",
            "Classifier loss: 0.40019676089286804\n",
            "Classifier loss: 3.0687096118927\n",
            "Generator loss: 0.27623850107192993\n",
            "Running epoch 208 out of 1900\n",
            "Classifier loss: 0.4271210730075836\n",
            "Classifier loss: 1.571492314338684\n",
            "Generator loss: 0.28606703877449036\n",
            "Classifier loss: 0.9064047336578369\n",
            "Classifier loss: 2.572718381881714\n",
            "Generator loss: 0.2665392756462097\n",
            "Classifier loss: 0.5309502482414246\n",
            "Classifier loss: 2.5685882568359375\n",
            "Generator loss: 0.2666449248790741\n",
            "Classifier loss: 0.41791415214538574\n",
            "Classifier loss: 1.078165054321289\n",
            "Generator loss: 0.27628764510154724\n",
            "Classifier loss: 0.5174098610877991\n",
            "Classifier loss: 0.5773866772651672\n",
            "Generator loss: 0.19551394879817963\n",
            "Classifier loss: 0.47790664434432983\n",
            "Classifier loss: 1.6518093347549438\n",
            "Generator loss: 0.18137942254543304\n",
            "Classifier loss: 0.4661997854709625\n",
            "Classifier loss: 1.0854899883270264\n",
            "Generator loss: 0.21671435236930847\n",
            "Classifier loss: 0.512492299079895\n",
            "Classifier loss: 1.0859593152999878\n",
            "Generator loss: 0.16914565861225128\n",
            "Classifier loss: 0.42602217197418213\n",
            "Classifier loss: 2.088897466659546\n",
            "Generator loss: 0.15845265984535217\n",
            "Classifier loss: 0.4280225336551666\n",
            "Classifier loss: 1.5974630117416382\n",
            "Generator loss: 0.21017704904079437\n",
            "Running epoch 209 out of 1900\n",
            "Classifier loss: 0.4232916533946991\n",
            "Classifier loss: 5.152665138244629\n",
            "Generator loss: 0.1184503361582756\n",
            "Classifier loss: 0.5055308938026428\n",
            "Classifier loss: 3.0960075855255127\n",
            "Generator loss: 0.05917242541909218\n",
            "Classifier loss: 0.4181899130344391\n",
            "Classifier loss: 3.6331636905670166\n",
            "Generator loss: 0.05911943316459656\n",
            "Classifier loss: 0.5101702213287354\n",
            "Classifier loss: 2.1327481269836426\n",
            "Generator loss: 0.059066228568553925\n",
            "Classifier loss: 0.4541095495223999\n",
            "Classifier loss: 4.107852458953857\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.43714049458503723\n",
            "Classifier loss: 4.184802532196045\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.46829870343208313\n",
            "Classifier loss: 3.1034209728240967\n",
            "Generator loss: 0.037059202790260315\n",
            "Classifier loss: 0.4267124533653259\n",
            "Classifier loss: 3.6214616298675537\n",
            "Generator loss: 0.05885167792439461\n",
            "Classifier loss: 0.7062280178070068\n",
            "Classifier loss: 3.7270469665527344\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3408143222332001\n",
            "Classifier loss: 4.674972057342529\n",
            "Generator loss: 0.0\n",
            "Running epoch 210 out of 1900\n",
            "Classifier loss: 0.3053290843963623\n",
            "Classifier loss: 1.6843295097351074\n",
            "Generator loss: 0.05869000777602196\n",
            "Classifier loss: 0.335332453250885\n",
            "Classifier loss: 2.1201202869415283\n",
            "Generator loss: 0.05863621458411217\n",
            "Classifier loss: 0.3165838122367859\n",
            "Classifier loss: 1.6274394989013672\n",
            "Generator loss: 0.05858241394162178\n",
            "Classifier loss: 0.3024156391620636\n",
            "Classifier loss: 1.1595616340637207\n",
            "Generator loss: 0.058528631925582886\n",
            "Classifier loss: 0.3964296579360962\n",
            "Classifier loss: 1.1237813234329224\n",
            "Generator loss: 3.7553974834736437e-05\n",
            "Classifier loss: 0.8704664707183838\n",
            "Classifier loss: 1.116936445236206\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3762817978858948\n",
            "Classifier loss: 2.1200032234191895\n",
            "Generator loss: 0.1167341023683548\n",
            "Classifier loss: 0.28988006711006165\n",
            "Classifier loss: 1.2017561197280884\n",
            "Generator loss: 0.058313120156526566\n",
            "Classifier loss: 0.3025423288345337\n",
            "Classifier loss: 0.6357762217521667\n",
            "Generator loss: 0.05825920030474663\n",
            "Classifier loss: 0.36126747727394104\n",
            "Classifier loss: 0.62747722864151\n",
            "Generator loss: 0.0582052581012249\n",
            "Running epoch 211 out of 1900\n",
            "Classifier loss: 0.6915621757507324\n",
            "Classifier loss: 4.657858848571777\n",
            "Generator loss: 0.11630256474018097\n",
            "Classifier loss: 0.331419974565506\n",
            "Classifier loss: 4.609458923339844\n",
            "Generator loss: 0.05809720978140831\n",
            "Classifier loss: 0.8463789224624634\n",
            "Classifier loss: 3.7110989093780518\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3798935115337372\n",
            "Classifier loss: 4.6226935386657715\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.36663833260536194\n",
            "Classifier loss: 3.6545000076293945\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.40470001101493835\n",
            "Classifier loss: 3.676156520843506\n",
            "Generator loss: 0.11576106399297714\n",
            "Classifier loss: 0.5492430925369263\n",
            "Classifier loss: 3.1062920093536377\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.32834747433662415\n",
            "Classifier loss: 3.1105763912200928\n",
            "Generator loss: 0.2310873419046402\n",
            "Classifier loss: 0.6950129270553589\n",
            "Classifier loss: 3.226470470428467\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3298851251602173\n",
            "Classifier loss: 4.608209133148193\n",
            "Generator loss: 0.05766266584396362\n",
            "Running epoch 212 out of 1900\n",
            "Classifier loss: 0.3424893915653229\n",
            "Classifier loss: 2.599092721939087\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.32538658380508423\n",
            "Classifier loss: 3.108398914337158\n",
            "Generator loss: 0.05755332484841347\n",
            "Classifier loss: 0.3101367950439453\n",
            "Classifier loss: 2.1022603511810303\n",
            "Generator loss: 0.057498615235090256\n",
            "Classifier loss: 0.40486443042755127\n",
            "Classifier loss: 2.6553866863250732\n",
            "Generator loss: 0.08236127346754074\n",
            "Classifier loss: 0.4057758152484894\n",
            "Classifier loss: 3.596571922302246\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3792024850845337\n",
            "Classifier loss: 2.088953733444214\n",
            "Generator loss: 0.11466743052005768\n",
            "Classifier loss: 0.37933626770973206\n",
            "Classifier loss: 1.5892730951309204\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.36406564712524414\n",
            "Classifier loss: 4.621397495269775\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.390664279460907\n",
            "Classifier loss: 2.584074020385742\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.42624542117118835\n",
            "Classifier loss: 3.608342170715332\n",
            "Generator loss: 0.057112015783786774\n",
            "Running epoch 213 out of 1900\n",
            "Classifier loss: 0.9044999480247498\n",
            "Classifier loss: 4.233614921569824\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.4021305441856384\n",
            "Classifier loss: 5.587878227233887\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.38792431354522705\n",
            "Classifier loss: 3.58382511138916\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.899627149105072\n",
            "Classifier loss: 4.582826137542725\n",
            "Generator loss: 0.05688853561878204\n",
            "Classifier loss: 0.3881755769252777\n",
            "Classifier loss: 4.582192420959473\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3860487937927246\n",
            "Classifier loss: 4.103851795196533\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.36312341690063477\n",
            "Classifier loss: 4.587797164916992\n",
            "Generator loss: 1.6568459272384644\n",
            "Classifier loss: 0.3853325843811035\n",
            "Classifier loss: 4.582073211669922\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3461865484714508\n",
            "Classifier loss: 5.085229873657227\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3366791903972626\n",
            "Classifier loss: 5.645307540893555\n",
            "Generator loss: 0.0\n",
            "Running epoch 214 out of 1900\n",
            "Classifier loss: 0.18769407272338867\n",
            "Classifier loss: 9.602380752563477\n",
            "Generator loss: 0.056493502110242844\n",
            "Classifier loss: 0.29068803787231445\n",
            "Classifier loss: 8.596185684204102\n",
            "Generator loss: 0.05643696337938309\n",
            "Classifier loss: 0.23764583468437195\n",
            "Classifier loss: 8.13343334197998\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2326699197292328\n",
            "Classifier loss: 8.598939895629883\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2149110734462738\n",
            "Classifier loss: 9.638751029968262\n",
            "Generator loss: 0.056267689913511276\n",
            "Classifier loss: 0.1880563497543335\n",
            "Classifier loss: 9.613767623901367\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.22171813249588013\n",
            "Classifier loss: 10.590909957885742\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2803557813167572\n",
            "Classifier loss: 10.152713775634766\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.21933118999004364\n",
            "Classifier loss: 9.077093124389648\n",
            "Generator loss: 0.05604315176606178\n",
            "Classifier loss: 0.7085726857185364\n",
            "Classifier loss: 10.07938003540039\n",
            "Generator loss: 0.0\n",
            "Running epoch 215 out of 1900\n",
            "Classifier loss: 0.877470076084137\n",
            "Classifier loss: 9.073108673095703\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.41703304648399353\n",
            "Classifier loss: 7.621420860290527\n",
            "Generator loss: 0.055875249207019806\n",
            "Classifier loss: 0.27569106221199036\n",
            "Classifier loss: 6.690155029296875\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.2249060571193695\n",
            "Classifier loss: 5.114436626434326\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.41273894906044006\n",
            "Classifier loss: 5.576819896697998\n",
            "Generator loss: 0.11141523718833923\n",
            "Classifier loss: 0.8022273182868958\n",
            "Classifier loss: 6.081393718719482\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.26616939902305603\n",
            "Classifier loss: 5.573580265045166\n",
            "Generator loss: 0.055595822632312775\n",
            "Classifier loss: 0.24184571206569672\n",
            "Classifier loss: 8.09783935546875\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.22230176627635956\n",
            "Classifier loss: 11.569863319396973\n",
            "Generator loss: 2.8133590035395173e-07\n",
            "Classifier loss: 0.2761819064617157\n",
            "Classifier loss: 8.10002326965332\n",
            "Generator loss: 0.0554281547665596\n",
            "Running epoch 216 out of 1900\n",
            "Classifier loss: 0.32894423604011536\n",
            "Classifier loss: 6.570300579071045\n",
            "Generator loss: 0.05537222698330879\n",
            "Classifier loss: 0.3701885938644409\n",
            "Classifier loss: 9.138572692871094\n",
            "Generator loss: 0.05531616136431694\n",
            "Classifier loss: 0.35406309366226196\n",
            "Classifier loss: 7.571020126342773\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8213709592819214\n",
            "Classifier loss: 7.631666660308838\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8574377298355103\n",
            "Classifier loss: 7.071541786193848\n",
            "Generator loss: 0.055147379636764526\n",
            "Classifier loss: 0.3880622386932373\n",
            "Classifier loss: 8.077067375183105\n",
            "Generator loss: 0.055090948939323425\n",
            "Classifier loss: 0.34473657608032227\n",
            "Classifier loss: 8.6701021194458\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3543216288089752\n",
            "Classifier loss: 8.594178199768066\n",
            "Generator loss: 0.05497779697179794\n",
            "Classifier loss: 0.36846616864204407\n",
            "Classifier loss: 9.070301055908203\n",
            "Generator loss: 0.05492107570171356\n",
            "Classifier loss: 0.3368346691131592\n",
            "Classifier loss: 9.569550514221191\n",
            "Generator loss: 0.0\n",
            "Running epoch 217 out of 1900\n",
            "Classifier loss: 0.8804799318313599\n",
            "Classifier loss: 15.198448181152344\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.38904687762260437\n",
            "Classifier loss: 12.395270347595215\n",
            "Generator loss: 0.05475034937262535\n",
            "Classifier loss: 0.3692687451839447\n",
            "Classifier loss: 10.61061954498291\n",
            "Generator loss: 0.05469334125518799\n",
            "Classifier loss: 0.506591796875\n",
            "Classifier loss: 12.06694507598877\n",
            "Generator loss: 0.05463624745607376\n",
            "Classifier loss: 0.3571857511997223\n",
            "Classifier loss: 12.58791732788086\n",
            "Generator loss: 0.05457903817296028\n",
            "Classifier loss: 0.5002110600471497\n",
            "Classifier loss: 11.571067810058594\n",
            "Generator loss: 0.056780438870191574\n",
            "Classifier loss: 0.8332650661468506\n",
            "Classifier loss: 10.582228660583496\n",
            "Generator loss: 0.10892854630947113\n",
            "Classifier loss: 0.37847578525543213\n",
            "Classifier loss: 10.567144393920898\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.3920612335205078\n",
            "Classifier loss: 12.069073677062988\n",
            "Generator loss: 0.054348915815353394\n",
            "Classifier loss: 0.9133671522140503\n",
            "Classifier loss: 12.09065055847168\n",
            "Generator loss: 0.10858200490474701\n",
            "Running epoch 218 out of 1900\n",
            "Classifier loss: 0.5827544331550598\n",
            "Classifier loss: 4.074090003967285\n",
            "Generator loss: 0.16269835829734802\n",
            "Classifier loss: 1.6148655414581299\n",
            "Classifier loss: 5.071735382080078\n",
            "Generator loss: 0.1083483025431633\n",
            "Classifier loss: 0.613224446773529\n",
            "Classifier loss: 3.0778067111968994\n",
            "Generator loss: 0.1623452752828598\n",
            "Classifier loss: 0.6596769690513611\n",
            "Classifier loss: 2.1732873916625977\n",
            "Generator loss: 2.527251581341261e-07\n",
            "Classifier loss: 0.5838096141815186\n",
            "Classifier loss: 3.07554292678833\n",
            "Generator loss: 0.05399566516280174\n",
            "Classifier loss: 0.6509174704551697\n",
            "Classifier loss: 3.5769662857055664\n",
            "Generator loss: 0.10787081718444824\n",
            "Classifier loss: 1.121248722076416\n",
            "Classifier loss: 2.5795187950134277\n",
            "Generator loss: 0.10774946957826614\n",
            "Classifier loss: 1.1845582723617554\n",
            "Classifier loss: 2.0812430381774902\n",
            "Generator loss: 0.10762722790241241\n",
            "Classifier loss: 0.7332839965820312\n",
            "Classifier loss: 2.084568977355957\n",
            "Generator loss: 0.16125597059726715\n",
            "Classifier loss: 0.847756564617157\n",
            "Classifier loss: 2.587040662765503\n",
            "Generator loss: 0.05368981137871742\n",
            "Running epoch 219 out of 1900\n",
            "Classifier loss: 1.1281535625457764\n",
            "Classifier loss: 4.196877956390381\n",
            "Generator loss: 0.10725444555282593\n",
            "Classifier loss: 0.68295818567276\n",
            "Classifier loss: 3.596846342086792\n",
            "Generator loss: 0.16069263219833374\n",
            "Classifier loss: 1.487781047821045\n",
            "Classifier loss: 3.1648433208465576\n",
            "Generator loss: 2.107001543045044\n",
            "Classifier loss: 0.8062404990196228\n",
            "Classifier loss: 4.19020414352417\n",
            "Generator loss: 0.9108719229698181\n",
            "Classifier loss: 0.7263818383216858\n",
            "Classifier loss: 4.117311477661133\n",
            "Generator loss: 0.05337262526154518\n",
            "Classifier loss: 0.7195295691490173\n",
            "Classifier loss: 4.6685471534729\n",
            "Generator loss: 2.1986031532287598\n",
            "Classifier loss: 0.7266412973403931\n",
            "Classifier loss: 4.621389865875244\n",
            "Generator loss: 0.04267456382513046\n",
            "Classifier loss: 0.7109643220901489\n",
            "Classifier loss: 3.256478786468506\n",
            "Generator loss: 0.10635437071323395\n",
            "Classifier loss: 1.542670726776123\n",
            "Classifier loss: 3.749779462814331\n",
            "Generator loss: 1.3074084520339966\n",
            "Classifier loss: 1.3426584005355835\n",
            "Classifier loss: 3.642678737640381\n",
            "Generator loss: 0.18939359486103058\n",
            "Running epoch 220 out of 1900\n",
            "Classifier loss: 1.2655168771743774\n",
            "Classifier loss: 4.6649394035339355\n",
            "Generator loss: 0.13621163368225098\n",
            "Classifier loss: 0.7456969022750854\n",
            "Classifier loss: 4.725578784942627\n",
            "Generator loss: 0.10303361713886261\n",
            "Classifier loss: 0.7338135242462158\n",
            "Classifier loss: 3.224182605743408\n",
            "Generator loss: 0.13479985296726227\n",
            "Classifier loss: 1.2211822271347046\n",
            "Classifier loss: 4.733509063720703\n",
            "Generator loss: 0.10213603079319\n",
            "Classifier loss: 0.7274175882339478\n",
            "Classifier loss: 2.2534549236297607\n",
            "Generator loss: 0.10541593283414841\n",
            "Classifier loss: 0.7592382431030273\n",
            "Classifier loss: 3.776096820831299\n",
            "Generator loss: 2.0317561626434326\n",
            "Classifier loss: 0.709172785282135\n",
            "Classifier loss: 5.269445896148682\n",
            "Generator loss: 2.0188980102539062\n",
            "Classifier loss: 0.7113476395606995\n",
            "Classifier loss: 4.272449970245361\n",
            "Generator loss: 0.07406666874885559\n",
            "Classifier loss: 0.7406315207481384\n",
            "Classifier loss: 4.746200084686279\n",
            "Generator loss: 0.07165420800447464\n",
            "Classifier loss: 0.7686712741851807\n",
            "Classifier loss: 3.79215145111084\n",
            "Generator loss: 0.10472932457923889\n",
            "Running epoch 221 out of 1900\n",
            "Classifier loss: 0.647802472114563\n",
            "Classifier loss: 3.7791125774383545\n",
            "Generator loss: 2.0487349033355713\n",
            "Classifier loss: 1.1341462135314941\n",
            "Classifier loss: 4.369642734527588\n",
            "Generator loss: 0.18145401775836945\n",
            "Classifier loss: 0.6238464713096619\n",
            "Classifier loss: 4.2888288497924805\n",
            "Generator loss: 1.638622522354126\n",
            "Classifier loss: 0.6785337924957275\n",
            "Classifier loss: 2.793951988220215\n",
            "Generator loss: 0.4974035918712616\n",
            "Classifier loss: 0.6340897679328918\n",
            "Classifier loss: 3.7930681705474854\n",
            "Generator loss: 0.1560559868812561\n",
            "Classifier loss: 0.6336796283721924\n",
            "Classifier loss: 3.8168327808380127\n",
            "Generator loss: 0.787972629070282\n",
            "Classifier loss: 0.6531251668930054\n",
            "Classifier loss: 3.3435893058776855\n",
            "Generator loss: 1.0230238437652588\n",
            "Classifier loss: 0.7000729441642761\n",
            "Classifier loss: 3.2516818046569824\n",
            "Generator loss: 0.15542840957641602\n",
            "Classifier loss: 1.204489827156067\n",
            "Classifier loss: 3.265692949295044\n",
            "Generator loss: 0.33754342794418335\n",
            "Classifier loss: 0.8073813915252686\n",
            "Classifier loss: 3.245053291320801\n",
            "Generator loss: 0.20667561888694763\n",
            "Running epoch 222 out of 1900\n",
            "Classifier loss: 0.8581172227859497\n",
            "Classifier loss: 2.7463040351867676\n",
            "Generator loss: 0.21322213113307953\n",
            "Classifier loss: 1.041982650756836\n",
            "Classifier loss: 3.7205302715301514\n",
            "Generator loss: 0.15678392350673676\n",
            "Classifier loss: 0.8226336240768433\n",
            "Classifier loss: 2.7364370822906494\n",
            "Generator loss: 0.08222050219774246\n",
            "Classifier loss: 0.8125466704368591\n",
            "Classifier loss: 3.739506959915161\n",
            "Generator loss: 0.0685013011097908\n",
            "Classifier loss: 1.3576571941375732\n",
            "Classifier loss: 3.2199699878692627\n",
            "Generator loss: 0.10264360159635544\n",
            "Classifier loss: 0.8091562390327454\n",
            "Classifier loss: 1.7114639282226562\n",
            "Generator loss: 0.10248750448226929\n",
            "Classifier loss: 0.9795746207237244\n",
            "Classifier loss: 2.2400739192962646\n",
            "Generator loss: 0.1796281784772873\n",
            "Classifier loss: 1.1797239780426025\n",
            "Classifier loss: 2.2418899536132812\n",
            "Generator loss: 0.051092375069856644\n",
            "Classifier loss: 1.3435299396514893\n",
            "Classifier loss: 2.2080721855163574\n",
            "Generator loss: 0.10203760117292404\n",
            "Classifier loss: 1.3048423528671265\n",
            "Classifier loss: 2.230766534805298\n",
            "Generator loss: 0.05783241242170334\n",
            "Running epoch 223 out of 1900\n",
            "Classifier loss: 1.0192224979400635\n",
            "Classifier loss: 2.208658456802368\n",
            "Generator loss: 0.07537662982940674\n",
            "Classifier loss: 1.4466067552566528\n",
            "Classifier loss: 2.226471424102783\n",
            "Generator loss: 0.07100380212068558\n",
            "Classifier loss: 0.9387966990470886\n",
            "Classifier loss: 2.2439918518066406\n",
            "Generator loss: 0.17656223475933075\n",
            "Classifier loss: 0.9844209551811218\n",
            "Classifier loss: 2.2484803199768066\n",
            "Generator loss: 0.21788382530212402\n",
            "Classifier loss: 0.9472475051879883\n",
            "Classifier loss: 2.264392375946045\n",
            "Generator loss: 2.5161447525024414\n",
            "Classifier loss: 0.9629541039466858\n",
            "Classifier loss: 2.2535715103149414\n",
            "Generator loss: 0.15903601050376892\n",
            "Classifier loss: 0.9180445671081543\n",
            "Classifier loss: 2.263456106185913\n",
            "Generator loss: 0.14050894975662231\n",
            "Classifier loss: 1.3986790180206299\n",
            "Classifier loss: 2.298781633377075\n",
            "Generator loss: 1.0333552360534668\n",
            "Classifier loss: 0.9481025338172913\n",
            "Classifier loss: 2.326572895050049\n",
            "Generator loss: 0.22609980404376984\n",
            "Classifier loss: 0.8855144381523132\n",
            "Classifier loss: 2.3028624057769775\n",
            "Generator loss: 0.07186541706323624\n",
            "Running epoch 224 out of 1900\n",
            "Classifier loss: 0.907042384147644\n",
            "Classifier loss: 3.317949056625366\n",
            "Generator loss: 0.05036640912294388\n",
            "Classifier loss: 0.9484006762504578\n",
            "Classifier loss: 3.3381741046905518\n",
            "Generator loss: 0.10005790740251541\n",
            "Classifier loss: 0.9210440516471863\n",
            "Classifier loss: 3.3176355361938477\n",
            "Generator loss: 0.09990157186985016\n",
            "Classifier loss: 0.9341782331466675\n",
            "Classifier loss: 2.8697423934936523\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.8994684219360352\n",
            "Classifier loss: 3.3090803623199463\n",
            "Generator loss: 0.09958785772323608\n",
            "Classifier loss: 0.9118108749389648\n",
            "Classifier loss: 3.3240270614624023\n",
            "Generator loss: 0.14914575219154358\n",
            "Classifier loss: 0.9775658845901489\n",
            "Classifier loss: 3.3315112590789795\n",
            "Generator loss: 0.09927266091108322\n",
            "Classifier loss: 0.9782059788703918\n",
            "Classifier loss: 3.327866792678833\n",
            "Generator loss: 0.04955718293786049\n",
            "Classifier loss: 0.9209513664245605\n",
            "Classifier loss: 2.836434841156006\n",
            "Generator loss: 0.09895574301481247\n",
            "Classifier loss: 0.9023793339729309\n",
            "Classifier loss: 3.3266377449035645\n",
            "Generator loss: 0.09879680722951889\n",
            "Running epoch 225 out of 1900\n",
            "Classifier loss: 0.7274555563926697\n",
            "Classifier loss: 2.3180227279663086\n",
            "Generator loss: 0.09367688000202179\n",
            "Classifier loss: 0.7084299921989441\n",
            "Classifier loss: 2.3297386169433594\n",
            "Generator loss: 0.14024679362773895\n",
            "Classifier loss: 0.7221590280532837\n",
            "Classifier loss: 2.342392921447754\n",
            "Generator loss: 0.017186161130666733\n",
            "Classifier loss: 0.7337763905525208\n",
            "Classifier loss: 2.3171157836914062\n",
            "Generator loss: 0.11039373278617859\n",
            "Classifier loss: 0.7208108305931091\n",
            "Classifier loss: 2.327582836151123\n",
            "Generator loss: 0.06330789625644684\n",
            "Classifier loss: 0.7116822600364685\n",
            "Classifier loss: 2.3711273670196533\n",
            "Generator loss: 0.04892309010028839\n",
            "Classifier loss: 0.6788046360015869\n",
            "Classifier loss: 2.8048152923583984\n",
            "Generator loss: 0.048848707228899\n",
            "Classifier loss: 0.784217894077301\n",
            "Classifier loss: 2.292276620864868\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7909521460533142\n",
            "Classifier loss: 2.3017709255218506\n",
            "Generator loss: 0.06254877895116806\n",
            "Classifier loss: 0.7156944870948792\n",
            "Classifier loss: 2.319779396057129\n",
            "Generator loss: 0.10524484515190125\n",
            "Running epoch 226 out of 1900\n",
            "Classifier loss: 1.1795929670333862\n",
            "Classifier loss: 1.3062360286712646\n",
            "Generator loss: 0.07240908592939377\n",
            "Classifier loss: 1.0235111713409424\n",
            "Classifier loss: 1.2879606485366821\n",
            "Generator loss: 0.09689465910196304\n",
            "Classifier loss: 0.6710590720176697\n",
            "Classifier loss: 1.284504771232605\n",
            "Generator loss: 0.17528173327445984\n",
            "Classifier loss: 0.6935399174690247\n",
            "Classifier loss: 1.3409250974655151\n",
            "Generator loss: 0.03100779466331005\n",
            "Classifier loss: 0.6386522650718689\n",
            "Classifier loss: 1.351647973060608\n",
            "Generator loss: 0.09642138332128525\n",
            "Classifier loss: 0.6274011135101318\n",
            "Classifier loss: 1.3538436889648438\n",
            "Generator loss: 0.022964278236031532\n",
            "Classifier loss: 1.152113676071167\n",
            "Classifier loss: 1.3436131477355957\n",
            "Generator loss: 0.02359694615006447\n",
            "Classifier loss: 0.7280880808830261\n",
            "Classifier loss: 1.3237273693084717\n",
            "Generator loss: 0.06153791397809982\n",
            "Classifier loss: 0.6572408676147461\n",
            "Classifier loss: 1.2988815307617188\n",
            "Generator loss: 0.08285146206617355\n",
            "Classifier loss: 0.7213050723075867\n",
            "Classifier loss: 1.2895152568817139\n",
            "Generator loss: 0.06595255434513092\n",
            "Running epoch 227 out of 1900\n",
            "Classifier loss: 0.7480613589286804\n",
            "Classifier loss: 1.244956374168396\n",
            "Generator loss: 0.09937568753957748\n",
            "Classifier loss: 0.7715713977813721\n",
            "Classifier loss: 1.2534983158111572\n",
            "Generator loss: 0.15095029771327972\n",
            "Classifier loss: 0.7876724004745483\n",
            "Classifier loss: 1.251666784286499\n",
            "Generator loss: 0.13300149142742157\n",
            "Classifier loss: 0.7257204055786133\n",
            "Classifier loss: 1.267702579498291\n",
            "Generator loss: 0.07228310406208038\n",
            "Classifier loss: 0.7693108916282654\n",
            "Classifier loss: 1.281053900718689\n",
            "Generator loss: 0.16043870151042938\n",
            "Classifier loss: 0.7139779329299927\n",
            "Classifier loss: 1.2887693643569946\n",
            "Generator loss: 0.1392696648836136\n",
            "Classifier loss: 0.7361060380935669\n",
            "Classifier loss: 1.359620451927185\n",
            "Generator loss: 0.18349702656269073\n",
            "Classifier loss: 0.6906578540802002\n",
            "Classifier loss: 1.345401406288147\n",
            "Generator loss: 0.10369852930307388\n",
            "Classifier loss: 0.6951043605804443\n",
            "Classifier loss: 1.3546327352523804\n",
            "Generator loss: 0.12715879082679749\n",
            "Classifier loss: 0.6786407828330994\n",
            "Classifier loss: 1.3628127574920654\n",
            "Generator loss: 0.10784639418125153\n",
            "Running epoch 228 out of 1900\n",
            "Classifier loss: 0.6353722810745239\n",
            "Classifier loss: 2.377227783203125\n",
            "Generator loss: 0.20375466346740723\n",
            "Classifier loss: 0.7091721892356873\n",
            "Classifier loss: 2.3419976234436035\n",
            "Generator loss: 0.004569751210510731\n",
            "Classifier loss: 0.6381641030311584\n",
            "Classifier loss: 2.366881847381592\n",
            "Generator loss: 0.13146348297595978\n",
            "Classifier loss: 0.6972532272338867\n",
            "Classifier loss: 2.4085512161254883\n",
            "Generator loss: 0.0007526262197643518\n",
            "Classifier loss: 0.6495926380157471\n",
            "Classifier loss: 2.3594954013824463\n",
            "Generator loss: 0.04664139822125435\n",
            "Classifier loss: 0.7314143180847168\n",
            "Classifier loss: 1.86231529712677\n",
            "Generator loss: 0.175643190741539\n",
            "Classifier loss: 0.8017173409461975\n",
            "Classifier loss: 2.322160243988037\n",
            "Generator loss: 0.02545228600502014\n",
            "Classifier loss: 0.8284785151481628\n",
            "Classifier loss: 2.347458839416504\n",
            "Generator loss: 0.04647310450673103\n",
            "Classifier loss: 0.7895962595939636\n",
            "Classifier loss: 2.3183939456939697\n",
            "Generator loss: 0.1257094144821167\n",
            "Classifier loss: 0.792518138885498\n",
            "Classifier loss: 2.262969970703125\n",
            "Generator loss: 0.14253392815589905\n",
            "Running epoch 229 out of 1900\n",
            "Classifier loss: 0.774014413356781\n",
            "Classifier loss: 1.7810338735580444\n",
            "Generator loss: 0.0017515885410830379\n",
            "Classifier loss: 0.8428676128387451\n",
            "Classifier loss: 1.7791284322738647\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7732571363449097\n",
            "Classifier loss: 1.7959706783294678\n",
            "Generator loss: 0.046017661690711975\n",
            "Classifier loss: 0.8300284147262573\n",
            "Classifier loss: 1.8305394649505615\n",
            "Generator loss: 0.04593959078192711\n",
            "Classifier loss: 0.742717444896698\n",
            "Classifier loss: 1.8477141857147217\n",
            "Generator loss: 0.009331976063549519\n",
            "Classifier loss: 0.7708829045295715\n",
            "Classifier loss: 1.8379021883010864\n",
            "Generator loss: 2.3841859597695247e-09\n",
            "Classifier loss: 0.7472869753837585\n",
            "Classifier loss: 1.8468021154403687\n",
            "Generator loss: 0.04570576176047325\n",
            "Classifier loss: 0.7813752293586731\n",
            "Classifier loss: 1.8432897329330444\n",
            "Generator loss: 1.931199733462563e-07\n",
            "Classifier loss: 0.7062752842903137\n",
            "Classifier loss: 1.843213438987732\n",
            "Generator loss: 0.04555031657218933\n",
            "Classifier loss: 0.7487090826034546\n",
            "Classifier loss: 1.8629461526870728\n",
            "Generator loss: 0.0\n",
            "Running epoch 230 out of 1900\n",
            "Classifier loss: 0.8201223015785217\n",
            "Classifier loss: 1.8416966199874878\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7512678503990173\n",
            "Classifier loss: 1.8829915523529053\n",
            "Generator loss: 0.04531782865524292\n",
            "Classifier loss: 0.7922137379646301\n",
            "Classifier loss: 1.8559917211532593\n",
            "Generator loss: 0.045240480452775955\n",
            "Classifier loss: 0.8134700655937195\n",
            "Classifier loss: 1.8442907333374023\n",
            "Generator loss: 0.034340258687734604\n",
            "Classifier loss: 0.8017719984054565\n",
            "Classifier loss: 1.8782501220703125\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7458050847053528\n",
            "Classifier loss: 1.3823930025100708\n",
            "Generator loss: 0.04500872641801834\n",
            "Classifier loss: 0.7459368705749512\n",
            "Classifier loss: 1.8757563829421997\n",
            "Generator loss: 0.04493165388703346\n",
            "Classifier loss: 0.788489580154419\n",
            "Classifier loss: 1.8611010313034058\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.7409706115722656\n",
            "Classifier loss: 1.8735697269439697\n",
            "Generator loss: 0.01618911884725094\n",
            "Classifier loss: 0.7865318059921265\n",
            "Classifier loss: 1.890547275543213\n",
            "Generator loss: 0.0894019678235054\n",
            "Running epoch 231 out of 1900\n",
            "Classifier loss: 0.826714277267456\n",
            "Classifier loss: 2.4159693717956543\n",
            "Generator loss: 0.06380493938922882\n",
            "Classifier loss: 0.7889701724052429\n",
            "Classifier loss: 2.4065942764282227\n",
            "Generator loss: 0.05800185725092888\n",
            "Classifier loss: 0.8143905401229858\n",
            "Classifier loss: 2.401150941848755\n",
            "Generator loss: 0.09912662953138351\n",
            "Classifier loss: 0.894311785697937\n",
            "Classifier loss: 2.378929615020752\n",
            "Generator loss: 0.08879362791776657\n",
            "Classifier loss: 0.8094265460968018\n",
            "Classifier loss: 2.3814921379089355\n",
            "Generator loss: 0.08863504230976105\n",
            "Classifier loss: 0.817881166934967\n",
            "Classifier loss: 2.3940229415893555\n",
            "Generator loss: 0.13272252678871155\n",
            "Classifier loss: 0.8043091297149658\n",
            "Classifier loss: 2.430562734603882\n",
            "Generator loss: 0.0004950687871314585\n",
            "Classifier loss: 0.7742007374763489\n",
            "Classifier loss: 2.4268798828125\n",
            "Generator loss: 0.0881752073764801\n",
            "Classifier loss: 0.7301514744758606\n",
            "Classifier loss: 2.4319984912872314\n",
            "Generator loss: 0.08802227675914764\n",
            "Classifier loss: 0.68979811668396\n",
            "Classifier loss: 2.480100631713867\n",
            "Generator loss: 0.043934810906648636\n",
            "Running epoch 232 out of 1900\n",
            "Classifier loss: 0.6224249601364136\n",
            "Classifier loss: 1.9636183977127075\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6286234259605408\n",
            "Classifier loss: 1.9945248365402222\n",
            "Generator loss: 0.0875658392906189\n",
            "Classifier loss: 0.5497422218322754\n",
            "Classifier loss: 1.96840500831604\n",
            "Generator loss: 0.0\n",
            "Classifier loss: 0.6236951947212219\n",
            "Classifier loss: 2.9513957500457764\n",
            "Generator loss: 0.043632205575704575\n",
            "Classifier loss: 0.6491238474845886\n",
            "Classifier loss: 2.879673957824707\n",
            "Generator loss: 5.0067963996980325e-08\n",
            "Classifier loss: 0.6621124148368835\n",
            "Classifier loss: 2.4554836750030518\n",
            "Generator loss: 0.08696494251489639\n",
            "Classifier loss: 0.7133642435073853\n",
            "Classifier loss: 1.9486865997314453\n",
            "Generator loss: 0.0434078648686409\n",
            "Classifier loss: 0.711208164691925\n",
            "Classifier loss: 2.342923641204834\n",
            "Generator loss: 1.1205704453232102e-07\n",
            "Classifier loss: 0.7304737567901611\n",
            "Classifier loss: 2.8329989910125732\n",
            "Generator loss: 0.08651795983314514\n",
            "Classifier loss: 0.7417254447937012\n",
            "Classifier loss: 2.801543712615967\n",
            "Generator loss: 1.144412422604546e-07\n",
            "Running epoch 233 out of 1900\n",
            "Classifier loss: 0.8472321033477783\n",
            "Classifier loss: 4.378315448760986\n",
            "Generator loss: 0.11874061077833176\n",
            "Classifier loss: 0.8648754954338074\n",
            "Classifier loss: 4.337327480316162\n",
            "Generator loss: 0.05358581244945526\n",
            "Classifier loss: 0.8748529553413391\n",
            "Classifier loss: 3.363316535949707\n",
            "Generator loss: 0.10204240679740906\n",
            "Classifier loss: 0.8470505475997925\n",
            "Classifier loss: 3.371147632598877\n",
            "Generator loss: 0.05503949150443077\n",
            "Classifier loss: 0.7929757237434387\n",
            "Classifier loss: 4.317027568817139\n",
            "Generator loss: 0.05337657779455185\n",
            "Classifier loss: 0.8046166300773621\n",
            "Classifier loss: 4.360748291015625\n",
            "Generator loss: 0.04566316679120064\n",
            "Classifier loss: 0.8251925706863403\n",
            "Classifier loss: 3.3989055156707764\n",
            "Generator loss: 0.09895570576190948\n",
            "Classifier loss: 0.8121115565299988\n",
            "Classifier loss: 3.8887815475463867\n",
            "Generator loss: 0.05166704207658768\n",
            "Classifier loss: 0.7850205302238464\n",
            "Classifier loss: 4.414008140563965\n",
            "Generator loss: 0.06086401268839836\n",
            "Classifier loss: 0.7061729431152344\n",
            "Classifier loss: 3.432422161102295\n",
            "Generator loss: 0.08487863093614578\n",
            "Running epoch 234 out of 1900\n",
            "Classifier loss: 0.7958435416221619\n",
            "Classifier loss: 3.028374671936035\n",
            "Generator loss: 0.029128044843673706\n",
            "Classifier loss: 0.7658639550209045\n",
            "Classifier loss: 2.5552895069122314\n",
            "Generator loss: 0.03158777207136154\n",
            "Classifier loss: 0.7684555053710938\n",
            "Classifier loss: 1.9986122846603394\n",
            "Generator loss: 0.06563295423984528\n",
            "Classifier loss: 0.7152243852615356\n",
            "Classifier loss: 2.096909999847412\n",
            "Generator loss: 0.01541727501899004\n",
            "Classifier loss: 0.7367455363273621\n",
            "Classifier loss: 3.02117919921875\n",
            "Generator loss: 0.024058453738689423\n",
            "Classifier loss: 0.7040187120437622\n",
            "Classifier loss: 2.59566593170166\n",
            "Generator loss: 0.013787876814603806\n",
            "Classifier loss: 0.6586088538169861\n",
            "Classifier loss: 2.5265591144561768\n",
            "Generator loss: 0.07794446498155594\n",
            "Classifier loss: 0.7098731994628906\n",
            "Classifier loss: 1.9773139953613281\n",
            "Generator loss: 0.06405903398990631\n",
            "Classifier loss: 0.7301376461982727\n",
            "Classifier loss: 1.9727375507354736\n",
            "Generator loss: 0.019988855347037315\n",
            "Classifier loss: 0.738947868347168\n",
            "Classifier loss: 2.4296693801879883\n",
            "Generator loss: 0.03148408979177475\n",
            "Running epoch 235 out of 1900\n",
            "Classifier loss: 0.682414710521698\n",
            "Classifier loss: 3.4603700637817383\n",
            "Generator loss: 0.04163116216659546\n",
            "Classifier loss: 0.716964066028595\n",
            "Classifier loss: 3.4555883407592773\n",
            "Generator loss: 3.126799128949642e-05\n",
            "Classifier loss: 0.7041569352149963\n",
            "Classifier loss: 3.4259119033813477\n",
            "Generator loss: 0.04148651659488678\n",
            "Classifier loss: 0.7495329976081848\n",
            "Classifier loss: 3.390080451965332\n",
            "Generator loss: 0.04141440615057945\n",
            "Classifier loss: 0.7456603646278381\n",
            "Classifier loss: 3.3865303993225098\n",
            "Generator loss: 0.04134240001440048\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}